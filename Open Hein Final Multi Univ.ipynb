{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import nltk\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://proxy.its.virginia.edu/login?url=http://heinonline.org/HOL/Welcome\")\n",
    "g_driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this part to automatically login, but DUO two step authentication is still required. You will have to enter that manually. After entering the DUO code, you will be given a warning that the information you enter could be sent over an insecure connection. Click continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'meb2fv'\n",
    "password = '0ver In 2018!'\n",
    "driver.find_element_by_id(\"user\").send_keys(username);\n",
    "driver.find_element_by_id(\"pass\").send_keys(password);\n",
    "driver.find_element_by_xpath(\"/html/body/main/div[2]/fieldset/form/input\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have logged in, Selenium is able to navigate to any webpage. We will navigate to the pages on the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_names(mid_first_name, last_name, school_url):\n",
    "    link = 'https://heinonline-org.proxy01.its.virginia.edu/HOL/LuceneSearch?typea=title&termsa=&operator=AND&typeb=creator&termsb=' + last_name + '+' + mid_first_name + '&operatorb=AND&typec=text&termsc=&operatorc=AND&typed=title&termsd=&operatord=AND&typee=title&termse=&operatore=AND&typef=title&termsf=&yearlo=&yearhi=&tabfrom=&searchtype=field&collection=all&submit=Go'\n",
    "    driver.get(link)\n",
    "    try:\n",
    "        webpage_wait('//*[@id=\"heinlogo\"]/a/img')\n",
    "        driver.find_element_by_xpath('//*[@id=\"search_modify\"]/form/div/div/div/div/a[4]/i').click()\n",
    "    except:\n",
    "        driver.find_element_by_xpath('//*[@id=\"search_modify\"]/div')\n",
    "    element = driver.find_elements_by_tag_name('a')\n",
    "    full_name = mid_first_name + ' ' +  last_name\n",
    "    alt_fm_names = []\n",
    "    err_fm_names = []\n",
    "    if ' ' in mid_first_name.lower():\n",
    "        first_name = mid_first_name.split(' ')[0]\n",
    "    else: \n",
    "        first_name = mid_first_name\n",
    "    page = 1\n",
    "    \n",
    "    while element:\n",
    "        for link in element:\n",
    "            link_text = link.text.lower()\n",
    "            if first_name.lower() in link_text.lower() and last_name.lower() in link_text.lower() and '[' not in link_text:\n",
    "                try:\n",
    "                    new_last = link_text.split(', ')[0]\n",
    "                    new_first_mid = link_text.split(', ')[1]\n",
    "                    if first_name.lower() in new_first_mid and last_name.lower() == new_last:\n",
    "                        new_fm = link.text.split(', ')[1]\n",
    "                        if not new_fm in alt_fm_names and not new_fm in err_fm_names:\n",
    "                            faculty = check_google(new_fm, last_name, school_url)\n",
    "                            if faculty: \n",
    "                                alt_fm_names.append(new_fm)\n",
    "                            else: \n",
    "                                err_fm_names.append(new_fm)\n",
    "                except:\n",
    "                    continue\n",
    "        if page < 2:\n",
    "            try:\n",
    "                driver.find_element_by_xpath('//*[@id=\"thenext\"]/span').click()\n",
    "                time.sleep(3)\n",
    "                element = driver.find_elements_by_tag_name('a') \n",
    "                page += 1\n",
    "            except:\n",
    "                element = []\n",
    "        else: \n",
    "            element = []\n",
    "    return alt_fm_names, err_fm_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_names(alt_name_list, err_fm_names, mid_first_name, last_name):\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[2]/div/b/a').click()\n",
    "        element = driver.find_element_by_xpath('//*[@id=\"simlist\"]/ul[1]')\n",
    "        similar_name_list = [a.strip() for a in element.text.split('\\n')]\n",
    "        middle_name = ''\n",
    "        if ' ' in mid_first_name.lower():\n",
    "            first_name = mid_first_name.split(' ')[0]\n",
    "            middle_name = mid_first_name.split(' ')[1]\n",
    "        else: \n",
    "            first_name = mid_first_name\n",
    "        for name in similar_name_list:\n",
    "            if first_name.lower() in name.lower() and last_name.lower() in name.lower() and ', ' in name.lower():\n",
    "                new_fm = name.split(', ', 1)[1]            \n",
    "                new_last = name.split(', ', 1)[0]\n",
    "                print(new_fm + ' ' + new_last)\n",
    "                if new_fm not in alt_name_list and last_name.lower() == new_last.lower() and not new_fm in err_fm_names:\n",
    "                    if ' ' in new_fm.lower() and middle_name != '':\n",
    "                        new_mi = new_fm.split(' ')[1][0].lower()\n",
    "                        if new_mi == middle_name[0].lower():\n",
    "                            alt_name_list.append(new_fm)\n",
    "                            continue\n",
    "                    faculty = check_google(new_fm, last_name, school_url)\n",
    "                    if faculty: \n",
    "                        alt_name_list.append(new_fm)\n",
    "                    else: \n",
    "                        err_fm_names.append(new_fm)\n",
    "    except:\n",
    "        print('No similar names found.')\n",
    "    return alt_name_list, err_fm_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_google(mid_first_name, last_name, school_url):\n",
    "    faculty = False\n",
    "    for url in school_url:\n",
    "        if faculty == True:\n",
    "            break\n",
    "        g_driver.get(\"http://google.com\")\n",
    "        search = g_driver.find_element_by_name('q')\n",
    "        if not ' ' in mid_first_name:\n",
    "            search.send_keys(mid_first_name + ' ' + last_name + ' ' + url)\n",
    "        else: \n",
    "            search.send_keys(mid_first_name + ' ' + last_name + ' ')\n",
    "        search.send_keys(Keys.RETURN)\n",
    "        elems = g_driver.find_elements_by_xpath(\"//a[@href]\")\n",
    "\n",
    "        for elem in elems:\n",
    "            if url in elem.text:\n",
    "                print(url + ' in: ' + elem.text)\n",
    "                faculty = True\n",
    "                break\n",
    "    return faculty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asu in: Aaron Fellmeth | iSearch - ASU Faculty and Staff Search - Arizona ...\n",
      "https://isearch.asu.edu/profile/730670\n",
      "asu in: Aaron Fellmeth | iSearch\n",
      "https://isearch.asu.edu/profile/730670\n",
      "asu in: Aaron Fellmeth | iSearch\n",
      "https://isearch.asu.edu/profile/730670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Aaron', 'Aaron Xavier', 'Aaron X.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_name = 'Aaron'\n",
    "last_name = 'Fellmeth'\n",
    "alt_names, err_names = search_names(fm_name, last_name, ['asu'])\n",
    "# alt_names, err_names = similar_names(alt_names, err_names, fm_name, last_name)\n",
    "alt_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no middle name, a more famous person with the same first and last name will\n",
    "    be at the top of the search results, so we need to add the school name\n",
    "    In this case it will be ambiguous is another professor with the same first and last name \n",
    "    is in Hein anyway, so there is really no good way to tell if we are getting the wrong one.\n",
    "    If they have a middle initial, I assume there is not another professor using the same exact name\n",
    "    at a different school. Therefore, to avoid conflict with more famous people, I use the school name \n",
    "    in the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(*args):\n",
    "    cur_path = os.getcwd()\n",
    "    for value in args:\n",
    "        cur_path  = os.path.join(cur_path, value)\n",
    "    return cur_path\n",
    "\n",
    "def to_float_or_int(input_list):\n",
    "    new_list = []\n",
    "    for x in input_list:\n",
    "        x = x.replace(',','')\n",
    "        try:\n",
    "            value = int(x)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                value = float(x)\n",
    "            except:\n",
    "                value = ''\n",
    "        new_list.append(value)\n",
    "    return new_list\n",
    "\n",
    "def create_dataframe_dict(my_list):#, person, school, data_type):\n",
    "#     my_dict = {'Person': person, \n",
    "#               'School': school, \n",
    "#               'Type': data_type}\n",
    "    my_dict = {}\n",
    "    for stat in stats:\n",
    "        my_dict[stat] = ''\n",
    "        for item in my_list:   \n",
    "            if item[0] == stat:\n",
    "                my_dict[stat] = item[1]  \n",
    "    return my_dict\n",
    "\n",
    "def webpage_wait(xpath):\n",
    "    element = []\n",
    "    while not element:\n",
    "        try:\n",
    "            element = driver.find_element_by_xpath(xpath)\n",
    "        except:\n",
    "            print('Page has not loaded, sleeping for 3 seconds')\n",
    "            time.sleep(3)\n",
    "\n",
    "def remove_commas(df1):\n",
    "    for col in df1.columns:\n",
    "        df1[col] = df1[col].str.replace(',', '')\n",
    "    return df1\n",
    "\n",
    "def check_files(fm_name, last_name, current_files):\n",
    "    done = False\n",
    "    for cur_file in current_files:\n",
    "        if fm_name.lower() in cur_file.lower() and last_name.lower() in cur_file.lower():\n",
    "            done = True\n",
    "            break\n",
    "    return done\n",
    "\n",
    "def check_df(current_stats, school_name):\n",
    "    file = ''\n",
    "    for cur_stat in current_stats:\n",
    "        if school_name in cur_stat.lower():\n",
    "            file = cur_stat\n",
    "            break\n",
    "    return file\n",
    "\n",
    "def short_url(data):\n",
    "    url_list = []\n",
    "    for url in data:\n",
    "        if 'https://www.' in url:\n",
    "            new_url = url.split('https://www.')[1].split('.edu')[0]\n",
    "        elif 'http://www.' in url:\n",
    "            new_url = url.split('http://www.')[1].split('.edu')[0]\n",
    "        elif 'www.' in url:\n",
    "            new_url = url.split('www.')[1].split('.edu')[0]\n",
    "        elif 'https://' in url:\n",
    "            new_url = url.split('https://')[1].split('.edu')[0]\n",
    "        elif 'http://' in url:\n",
    "            new_url = url.split('http://')[1].split('.edu')[0]\n",
    "        url_list.append(new_url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(create_path('Professor Names.xlsx'))\n",
    "urls = pd.read_csv(create_path('University and College Websites update.csv'))\n",
    "urls.head()\n",
    "\n",
    "name_tuple = list(zip(data.First, data.Middle, data.Last))\n",
    "fm_name = [x[0] + ' ' +  x[1]  if isinstance(x[1], str)  else x[0] for x in name_tuple ]\n",
    "last_name = [x[2] for x in name_tuple ]\n",
    "title = ['NA']*len(last_name)\n",
    "new_data = pd.DataFrame({'First Name': fm_name, 'Last Name': last_name, 'Title': title, 'School': data.Former, 'New School': data.Current})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school_urls(urls_df, school_list):\n",
    "    url_list = []\n",
    "    for school_name in school_list:\n",
    "        school_name = school_name.replace(',', '')\n",
    "        try: \n",
    "            index = urls_df[urls_df['School Name'] == school_name].index[0]\n",
    "            print(school_name)\n",
    "            url_name = urls_df['URL'][index]\n",
    "            print(url_name)\n",
    "            url_list.append(url_name)\n",
    "        except:\n",
    "            g_driver.get(\"http://google.com\")\n",
    "            search = g_driver.find_element_by_name('q')\n",
    "            search.send_keys(school_name)\n",
    "            search.send_keys(Keys.RETURN)\n",
    "            element = g_driver.find_elements_by_xpath('//*[@id=\"rso\"]/div[1]/div/div[1]/div/div/div[1]/a/div/cite')\n",
    "            for elm in element:\n",
    "                print(school_name)\n",
    "                url_name = elm.text\n",
    "                print(url_name)\n",
    "            url_list.append(url_name)\n",
    "            urls_df = urls.append(pd.DataFrame({'School Name': [school_name], 'URL': [url_name]}), ignore_index=True, sort = False)\n",
    "            g_driver.get(\"http://amazon.com\")\n",
    "            time.sleep(3)\n",
    "            g_driver.get(\"http://facebook.com\")    \n",
    "    urls.to_csv(create_path('University and College Websites update.csv'))\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston College\n",
      "http://bc.edu\n",
      "Suffolk University\n",
      "http://suffolk.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of Detroit Mercy School of Law\n",
      "www.law.udmercy.edu/\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Whittier Law School\n",
      "https://www.law.whittier.edu/\n",
      "University of Minnesota\n",
      "http://umn.edu\n",
      "Suffolk University\n",
      "http://suffolk.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of Washington Seattle\n",
      "https://www.washington.edu/\n",
      "West Virginia University\n",
      "http://wvu.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of San Francisco\n",
      "http://usfca.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "DePaul University\n",
      "http://depaul.edu\n",
      "Louisiana State University\n",
      "http://lsu.edu\n",
      "University of Missouri Kansas City\n",
      "http://umkc.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Connecticut\n",
      "http://uconn.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "Emory University\n",
      "http://emory.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Baylor University\n",
      "http://baylor.edu\n",
      "Catholic University\n",
      "https://www.catholic.edu/index.html\n",
      "University of Arizona\n",
      "http://arizona.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "Barry University\n",
      "http://barry.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Miami\n",
      "http://miami.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Florida Coastal Law School\n",
      "https://www.fcsl.edu/index.php\n",
      "Washington University St. Louis\n",
      "https://wustl.edu/\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Universities of Helsinki & Eastern Finland\n",
      "www.uef.fi/en/etusivu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "University of Kentucky\n",
      "www.uky.edu/\n",
      "Drexel University\n",
      "http://drexel.edu\n",
      "Case Western Reserve University\n",
      "http://case.edu\n",
      "University of Nebraska Lincoln\n",
      "https://www.unl.edu/\n",
      "Boston College\n",
      "http://bc.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Washington University St. Louis\n",
      "https://wustl.edu/\n",
      "University of Hawaii\n",
      "https://wustl.edu/\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of North Carolina Chapel Hill \n",
      "https://www.unc.edu/\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "Widener University Commonwealth\n",
      "https://commonwealthlaw.widener.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "Fordham University\n",
      "http://fordham.edu\n",
      "Cardozo Law School/Yeshiva University\n",
      "https://cardozo.yu.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "University of Idaho\n",
      "http://uidaho.edu\n",
      "University of Tulsa\n",
      "http://utulsa.edu\n",
      "Cumberland School of Law Samford University\n",
      "https://www.samford.edu/cumberlandlaw/\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Temple University\n",
      "http://temple.edu\n",
      "Southern Illinois University\n",
      "http://siu.edu\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "Louisiana State University\n",
      "http://lsu.edu\n",
      "Cleveland-Marshall College of Law\n",
      "https://www.law.csuohio.edu/\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "McGill University\n",
      "https://www.mcgill.ca/\n",
      "Creighton University\n",
      "http://creighton.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "Loyola Law School Los Angeles\n",
      "https://www.lls.edu/\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "University of Minnesota\n",
      "http://umn.edu\n",
      "Indiana University Indianapolis\n",
      "https://www.iupui.edu/\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "Universities of Helsinki & Eastern Finland\n",
      "www.uef.fi/en/etusivu\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "Emory University\n",
      "http://emory.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Pennsylvania State University Dickinson School of Law (Carlysle)\n",
      "https://dickinsonlaw.psu.edu/\n",
      "Valparaiso University\n",
      "http://valpo.edu\n",
      "Ava Maria School of Law\n",
      "https://www.avemarialaw.edu/\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "Brigham Young University\n",
      "http://byu.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of Minnesota\n",
      "http://umn.edu\n",
      "Southwestern Law School\n",
      "https://www.swlaw.edu/\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "Hofstra University\n",
      "http://hofstra.edu\n",
      "Hofstra University\n",
      "http://hofstra.edu\n",
      "University of Utah\n",
      "http://utah.edu\n",
      "University of Utah\n",
      "http://utah.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Marquette University\n",
      "http://marquette.edu\n",
      "Michigan State University\n",
      "http://msu.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Pace University\n",
      "http://pace.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "Harvard University \n",
      "https://www.harvard.edu/\n",
      "Cardozo Law School\n",
      "https://cardozo.yu.edu/\n",
      "Suffolk University\n",
      "http://suffolk.edu\n",
      "American University\n",
      "http://american.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Cardozo Law School\n",
      "https://cardozo.yu.edu/\n",
      "University of Oklahoma Norman\n",
      "www.ou.edu/\n",
      "Pace University\n",
      "http://pace.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Chicago-Kent College of Law\n",
      "www.uh.edu/\n",
      "Marquette University\n",
      "http://marquette.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "Hofstra University\n",
      "http://hofstra.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "Fordham University\n",
      "http://fordham.edu\n",
      "Michigan State University\n",
      "http://msu.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "Albany Law School\n",
      "https://www.albanylaw.edu/\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Indiana University Bloomington\n",
      "http://iub.edu\n",
      "University of Georgia\n",
      "http://uga.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of Maine\n",
      "http://umaine.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "Northwestern University \n",
      "https://www.northwestern.edu/\n",
      "Regent University\n",
      "http://regent.edu\n",
      "University of Oklahoma Norman\n",
      "www.ou.edu/\n",
      "Lewis & Clark College\n",
      "https://www.lclark.edu/\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Chicago-Kent College of Law\n",
      "www.uh.edu/\n",
      "Suffolk University\n",
      "http://suffolk.edu\n",
      "Boston University\n",
      "http://bu.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "American University\n",
      "http://american.edu\n",
      "Drake University\n",
      "http://drake.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Emory University\n",
      "http://emory.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "University of Kentucky\n",
      "www.uky.edu/\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "American University\n",
      "http://american.edu\n",
      "Ohio State University\n",
      "http://osu.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Rutgers University Camden\n",
      "https://www.camden.rutgers.edu/\n",
      "University of Minnesota Twin Cities\n",
      "https://twin-cities.umn.edu/\n",
      "University of Connecticut\n",
      "http://uconn.edu\n",
      "Wake Forest University\n",
      "http://wfu.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Santa Clara University\n",
      "http://scu.edu\n",
      "Texas Tech University\n",
      "http://ttu.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "University of Pittsburgh\n",
      "http://pitt.edu\n",
      "University of Notre Dame\n",
      "http://nd.edu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston University\n",
      "http://bu.edu\n",
      "University of the Pacific McGeorge School of Law\n",
      "https://www.mcgeorge.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Connecticut\n",
      "http://uconn.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Columbia University \n",
      "https://www.columbia.edu/\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "Rutgers University Camden\n",
      "https://www.camden.rutgers.edu/\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "University of Missouri\n",
      "https://missouri.edu/\n",
      "University of Minnesota Twin Cities\n",
      "https://twin-cities.umn.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Melbourne\n",
      "https://www.unimelb.edu.au/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "DePaul University\n",
      "http://depaul.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Saint Louis University\n",
      "http://slu.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Yale University\n",
      "http://yale.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "College of William and Mary\n",
      "http://sandiego.edu\n",
      "University of Missouri Kansas City\n",
      "http://umkc.edu\n",
      "University of Cincinnati\n",
      "http://uc.edu\n",
      "University of Louisville\n",
      "louisville.edu/\n",
      "Creighton Universitiy\n",
      "https://www.creighton.edu/\n",
      "Pace University\n",
      "http://pace.edu\n",
      "University of Denver Sturm College of Law\n",
      "https://www.law.du.edu/\n",
      "Syracuse University\n",
      "http://syr.edu\n",
      "Vermont Law School\n",
      "http://vermontlaw.edu\n",
      "Ohio State University\n",
      "http://osu.edu\n",
      "Seattle University\n",
      "http://seattleu.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "Fordham University\n",
      "http://fordham.edu\n",
      "New York Law School\n",
      "http://fordham.edu\n",
      "Albany Law School\n",
      "https://www.albanylaw.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "American University\n",
      "http://american.edu\n",
      "John Marshall Law School (Atlanta) \n",
      "http://american.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of Richmond\n",
      "http://richmond.edu\n",
      "University of Connecticut\n",
      "http://uconn.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "University of Cincinnati\n",
      "http://uc.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "Loyola Law School Los Angeles\n",
      "https://www.lls.edu/\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Amsterdam\n",
      "https://www.uva.nl/en\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "Seattle University\n",
      "http://seattleu.edu\n",
      "Ohio State University\n",
      "http://osu.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Rutgers University at Newark\n",
      "https://www.newark.rutgers.edu/\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "University of Mississippi\n",
      "https://olemiss.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "University of Wisconsin at Madison\n",
      "https://www.wisc.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "Southwestern Law School\n",
      "https://www.swlaw.edu/\n",
      "Albany Law School\n",
      "https://www.albanylaw.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "University of Tennessee\n",
      "https://www.utk.edu/\n",
      "University of Michigan\n",
      "http://umich.edu\n",
      "University of British Columbia\n",
      "https://www.ubc.ca/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Chapman University\n",
      "http://chapman.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "Case Western Reserve University\n",
      "http://case.edu\n",
      "McGeorge School of Law University of the Pacific\n",
      "https://www.mcgeorge.edu/\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Villanova University\n",
      "http://villanova.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "University of Washington at Seattle\n",
      "https://www.washington.edu/\n",
      "University of Michigan\n",
      "http://umich.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "American University\n",
      "http://american.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "University of California at Los Angeles\n",
      "www.ucla.edu/\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Howard University\n",
      "http://howard.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "St. Thomas University (Florida) \n",
      "https://www.stu.edu/\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "First half complete\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "American University\n",
      "http://american.edu\n",
      "Temple University\n",
      "http://temple.edu\n",
      "University of Arkansas Fayetteville\n",
      "https://www.uark.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "University of Notre Dame\n",
      "http://nd.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Georgia\n",
      "http://uga.edu\n",
      "Marquette University\n",
      "http://marquette.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Golden Gate University\n",
      "https://www.ggu.edu/\n",
      "George Mason University\n",
      "http://gmu.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "University of Pittsburgh\n",
      "http://pitt.edu\n",
      "Drake University\n",
      "http://drake.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "George Mason University\n",
      "http://gmu.edu\n",
      "Fordham University\n",
      "http://fordham.edu\n",
      "University of Arkansas Fayetteville\n",
      "https://www.uark.edu/\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Indiana University Indianapolis\n",
      "https://www.iupui.edu/\n",
      "New York University\n",
      "http://nyu.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Dayton\n",
      "http://udayton.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "Rutgers University\n",
      "http://rutgers.edu\n",
      "University of Arizona\n",
      "http://arizona.edu\n",
      "University of Richmond\n",
      "http://richmond.edu\n",
      "Saint Louis University\n",
      "http://slu.edu\n",
      "University of Montana\n",
      "http://umt.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Rutgers University\n",
      "http://rutgers.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Northeastern University\n",
      "http://northeastern.edu\n",
      "Arizona State University\n",
      "http://asu.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "University of Georgia\n",
      "http://uga.edu\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Villanova University\n",
      "http://villanova.edu\n",
      "Indiana University Bloomington\n",
      "http://iub.edu\n",
      "Rutgers University\n",
      "http://rutgers.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University of Missouri Columbia\n",
      "https://missouri.edu/\n",
      "Northeastern University\n",
      "http://northeastern.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "University of Richmond\n",
      "http://richmond.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of Notre Dame\n",
      "http://nd.edu\n",
      "University of Hawaii\n",
      "https://wustl.edu/\n",
      "Yale University\n",
      "http://yale.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Yale University\n",
      "http://yale.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Arizona State University\n",
      "http://asu.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Rutgers University\n",
      "http://rutgers.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Missouri Kansas City\n",
      "http://umkc.edu\n",
      "Georgia State University\n",
      "http://gsu.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Utah\n",
      "http://utah.edu\n",
      "Emory University\n",
      "http://emory.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "American University\n",
      "http://american.edu\n",
      "Syracuse University\n",
      "http://syr.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Chapman University\n",
      "http://chapman.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Villanova University\n",
      "http://villanova.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Loyola University Chicago\n",
      "http://luc.edu\n",
      "University of Georgia\n",
      "http://uga.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Missouri Columbia\n",
      "https://missouri.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Hofstra University\n",
      "http://hofstra.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "Cardozo Law School\n",
      "https://cardozo.yu.edu/\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Missouri Columbia\n",
      "https://missouri.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Chicago-Kent College of Law\n",
      "www.uh.edu/\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Arizona State University\n",
      "http://asu.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Georgia State University\n",
      "http://gsu.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Campbell University\n",
      "http://campbell.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Northeastern University\n",
      "http://northeastern.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Boston University\n",
      "http://bu.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "University of Arkansas Fayetteville\n",
      "https://www.uark.edu/\n",
      "University of Arizona\n",
      "http://arizona.edu\n",
      "University of Utah\n",
      "http://utah.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Washington University St. Louis\n",
      "https://wustl.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of Washington Seattle\n",
      "https://www.washington.edu/\n",
      "Brigham Young University\n",
      "http://byu.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "Florida International University\n",
      "http://fiu.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Drexel University\n",
      "http://drexel.edu\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "Indiana University Indianapolis\n",
      "https://www.iupui.edu/\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Florida International University\n",
      "http://fiu.edu\n",
      "Arizona State University\n",
      "http://asu.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "Brigham Young University\n",
      "http://byu.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Tennessee\n",
      "https://www.utk.edu/\n",
      "McGill University\n",
      "https://www.mcgill.ca/\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "Chapman University\n",
      "http://chapman.edu\n",
      "University of Minnesota Minneapolis-St. Paul\n",
      "https://twin-cities.umn.edu/\n",
      "Pepperdine University\n",
      "http://pepperdine.edu\n",
      "Michigan State University\n",
      "http://msu.edu\n",
      "Texas Tech University\n",
      "http://ttu.edu\n",
      "State University of New York Buffalo\n",
      "www.buffalo.edu/\n",
      "Vermont Law School\n",
      "http://vermontlaw.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "Pace University\n",
      "http://pace.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "Howard University\n",
      "http://howard.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "University of Tennessee\n",
      "https://www.utk.edu/\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "University of North Texas\n",
      "http://unt.edu\n",
      "Yale University\n",
      "http://yale.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "Georgia Institute of Technology\n",
      "http://gatech.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wayne State University\n",
      "https://wayne.edu/\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "McGill University\n",
      "https://www.mcgill.ca/\n",
      "University of Notre Dame\n",
      "http://nd.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "Emory University\n",
      "http://emory.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Loyola University Chicago\n",
      "http://luc.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "Temple University\n",
      "http://temple.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Emory University\n",
      "http://emory.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Drexel University\n",
      "http://drexel.edu\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "American University\n",
      "http://american.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "Yale University\n",
      "http://yale.edu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>School</th>\n",
       "      <th>School URL</th>\n",
       "      <th>School URL short</th>\n",
       "      <th>New School</th>\n",
       "      <th>New School URL</th>\n",
       "      <th>New School URL short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Albert</td>\n",
       "      <td>NA</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>http://bc.edu</td>\n",
       "      <td>bc</td>\n",
       "      <td>University of Texas, Austin</td>\n",
       "      <td>https://www.utexas.edu/</td>\n",
       "      <td>utexas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hilary</td>\n",
       "      <td>Allen</td>\n",
       "      <td>NA</td>\n",
       "      <td>Suffolk University</td>\n",
       "      <td>http://suffolk.edu</td>\n",
       "      <td>suffolk</td>\n",
       "      <td>American University</td>\n",
       "      <td>http://american.edu</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Olufunmilayo</td>\n",
       "      <td>Arewa</td>\n",
       "      <td>NA</td>\n",
       "      <td>University of California, Irvine</td>\n",
       "      <td>http://uci.edu</td>\n",
       "      <td>uci</td>\n",
       "      <td>Temple University</td>\n",
       "      <td>http://temple.edu</td>\n",
       "      <td>temple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khaled A.</td>\n",
       "      <td>Beydoun</td>\n",
       "      <td>NA</td>\n",
       "      <td>University of Detroit Mercy School of Law</td>\n",
       "      <td>www.law.udmercy.edu/</td>\n",
       "      <td>law.udmercy</td>\n",
       "      <td>University of Arkansas, Fayetteville</td>\n",
       "      <td>https://www.uark.edu/</td>\n",
       "      <td>uark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joshua</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NA</td>\n",
       "      <td>New York University</td>\n",
       "      <td>http://nyu.edu</td>\n",
       "      <td>nyu</td>\n",
       "      <td>University of California, Irvine</td>\n",
       "      <td>http://uci.edu</td>\n",
       "      <td>uci</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     First Name Last Name Title                                     School  \\\n",
       "0       Richard    Albert    NA                             Boston College   \n",
       "1        Hilary     Allen    NA                         Suffolk University   \n",
       "2  Olufunmilayo     Arewa    NA           University of California, Irvine   \n",
       "3     Khaled A.   Beydoun    NA  University of Detroit Mercy School of Law   \n",
       "4        Joshua     Blank    NA                        New York University   \n",
       "\n",
       "             School URL School URL short  \\\n",
       "0         http://bc.edu               bc   \n",
       "1    http://suffolk.edu          suffolk   \n",
       "2        http://uci.edu              uci   \n",
       "3  www.law.udmercy.edu/      law.udmercy   \n",
       "4        http://nyu.edu              nyu   \n",
       "\n",
       "                             New School           New School URL  \\\n",
       "0           University of Texas, Austin  https://www.utexas.edu/   \n",
       "1                   American University      http://american.edu   \n",
       "2                     Temple University        http://temple.edu   \n",
       "3  University of Arkansas, Fayetteville    https://www.uark.edu/   \n",
       "4      University of California, Irvine           http://uci.edu   \n",
       "\n",
       "  New School URL short  \n",
       "0               utexas  \n",
       "1             american  \n",
       "2               temple  \n",
       "3                 uark  \n",
       "4                  uci  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list = get_school_urls(urls, new_data['School'])\n",
    "new_data.insert(4, \"School URL\", url_list) \n",
    "url_list = short_url(new_data['School URL'])\n",
    "new_data.insert(5, \"School URL short\", url_list)\n",
    "print('First half complete')\n",
    "url_list = get_school_urls(urls, new_data['New School'])\n",
    "new_data.insert(7, \"New School URL\", url_list) \n",
    "url_list = short_url(new_data['New School URL'])\n",
    "new_data.insert(8, \"New School URL short\", url_list) \n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>School</th>\n",
       "      <th>School URL</th>\n",
       "      <th>School URL short</th>\n",
       "      <th>New School</th>\n",
       "      <th>New School URL</th>\n",
       "      <th>New School URL short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Schmitz</td>\n",
       "      <td>NA</td>\n",
       "      <td>University of Colorado, Boulder</td>\n",
       "      <td>http://colorado.edu</td>\n",
       "      <td>colorado</td>\n",
       "      <td>University of Missouri, Columbia</td>\n",
       "      <td>https://missouri.edu/</td>\n",
       "      <td>nyu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Landers</td>\n",
       "      <td>NA</td>\n",
       "      <td>University of the Pacific, McGeorge School of Law</td>\n",
       "      <td>https://www.mcgeorge.edu/</td>\n",
       "      <td>mcgeorge</td>\n",
       "      <td>Drexel University</td>\n",
       "      <td>http://drexel.edu</td>\n",
       "      <td>drexel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    First Name Last Name Title  \\\n",
       "128        Amy   Schmitz    NA   \n",
       "199        Amy   Landers    NA   \n",
       "\n",
       "                                                School  \\\n",
       "128                    University of Colorado, Boulder   \n",
       "199  University of the Pacific, McGeorge School of Law   \n",
       "\n",
       "                    School URL School URL short  \\\n",
       "128        http://colorado.edu         colorado   \n",
       "199  https://www.mcgeorge.edu/         mcgeorge   \n",
       "\n",
       "                           New School         New School URL  \\\n",
       "128  University of Missouri, Columbia  https://missouri.edu/   \n",
       "199                 Drexel University      http://drexel.edu   \n",
       "\n",
       "    New School URL short  \n",
       "128                  nyu  \n",
       "199               drexel  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.to_csv(create_path('multi_school_data', 'new_professor_name_data.csv'))\n",
    "# if 'american' in 'https://www.wcl.american.edu/community/faculty/profile/hjallen/':\n",
    "#     print('True')\n",
    "new_data[new_data['First Name'] == 'Amy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-07f26e354853>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Cited by Cases'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Cited by Articles'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Accessed (Past 12 Months)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Cited by Articles (Past 10 Years)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cited by Articles (Past 1-2 years)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ScholarCheck Rank'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Average Citations per Article'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Average Citations per Document'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Self-Citations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multi_school_data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mschool_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'multi_school'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "stats = ['Cited by Cases','Cited by Articles','Accessed (Past 12 Months)','Cited by Articles (Past 10 Years)', 'Cited by Articles (Past 1-2 years)', 'ScholarCheck Rank', 'Average Citations per Article', 'Average Citations per Document', 'Self-Citations']\n",
    "path = create_path('multi_school_data')\n",
    "files = os.listdir(path)\n",
    "school_name = 'multi_school'\n",
    "delay = 5\n",
    "current_papers = os.listdir(create_path('author_papers'))\n",
    "current_stats = os.listdir(create_path('school_stats'))\n",
    "current_skip = os.listdir(create_path('skipped_names'))\n",
    "for file in files:\n",
    "    print(file)\n",
    "    main_df = pd.DataFrame()\n",
    "    file1 = check_df(current_stats, school_name)\n",
    "    if file1 != '':\n",
    "        main_df = pd.read_csv(create_path('school_stats', file1))\n",
    "    skip_df = pd.DataFrame(columns = ['Full Name', 'School'])\n",
    "    file2 = check_df(current_skip, school_name)\n",
    "    if file2 != '':\n",
    "        skip_df = pd.read_csv(create_path('skipped_names', file2))\n",
    "    data = pd.read_csv(create_path('multi_school_data', file))   \n",
    "    for i in range(len(data)):\n",
    "        #Get name and information from the database\n",
    "        mid_first_name = data['First Name'][i]\n",
    "        last_name = data['Last Name'][i]\n",
    "        full_name = mid_first_name + ' ' +  last_name\n",
    "        done = check_files(mid_first_name, last_name, current_papers)\n",
    "        #old url\n",
    "        school_url = [data['School URL short'][i], data['New School URL short'][i]]\n",
    "        if done:\n",
    "            print('File for ' + full_name + ' has already been created.')\n",
    "            continue\n",
    "        school = data['New School'][i]\n",
    "        title = data['Title'][i]\n",
    "        page_name = []\n",
    "        err_fm_names = []\n",
    "        df_sub = pd.DataFrame()\n",
    "        #Search by author to find potential alternative first and middle names:\n",
    "        fm_names, err_fm_names = search_names(mid_first_name, last_name, school_url)\n",
    "        print(fm_names)\n",
    "        if not fm_names:\n",
    "            print('Name ' + full_name + ' was not found')\n",
    "            skip_df = skip_df.append(pd.DataFrame([[full_name, school, title]], columns = ['Full Name', 'School', 'Title']))\n",
    "            \n",
    "        for fm_name in fm_names:\n",
    "            link = 'https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=' + last_name +  '%2C ' + fm_name + '&collection=journals'\n",
    "            driver.get(link)\n",
    "            soup=bs.BeautifulSoup(driver.page_source, 'lxml')\n",
    "            table_rows = soup.findAll('td', {'style': 'text-align:right;'})\n",
    "            full_name = fm_name + ' ' +  last_name\n",
    "            webpage_wait('//*[@id=\"page_content\"]/div[1]/div/div[1]/div[1]')\n",
    "            fm_names, err_fm_names = similar_names(fm_names, err_fm_names, fm_name, last_name)\n",
    "            cur_page = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[1]/div[1]').text\n",
    "            if not table_rows:\n",
    "                got_page = False\n",
    "                new_names = False\n",
    "                link_index = 1\n",
    "                while new_names == False:\n",
    "                    try:\n",
    "                        if link_index == 1:\n",
    "                            element =driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[2]/div/ul/li/a')\n",
    "                        else: \n",
    "                            element =driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[2]/div/ul/li[' + str(link_index) + ']/a')            \n",
    "                        new_fm_name = element.text.split(', ')[1]\n",
    "                        new_last_name = element.text.split(', ')[0]\n",
    "                        if last_name == new_last_name and mid_first_name in new_fm_name:\n",
    "                            if not new_fm_name in fm_names:\n",
    "                                check_google(new_fm_name, last_name, school_url)\n",
    "                                fm_names.append(new_fm_name)\n",
    "                            \n",
    "                    except: \n",
    "                        new_names = True\n",
    "                        got_page = True\n",
    "                        if not scraped_papers:\n",
    "                            print('Name ' + full_name + ' is not in the database. You may be missing a middle initial.')\n",
    "                            skip_df = skip_df.append(pd.DataFrame([[full_name, school, title]], columns = ['Full Name', 'School', 'Title']))\n",
    "                        else:\n",
    "                            print('No remaining pages to scrape from {}.'.format(full_name))\n",
    "                    link_index += 1\n",
    "                    \n",
    "            elif table_rows and cur_page not in page_name: \n",
    "                element = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[2]')\n",
    "                table_element = element.text.split('\\n')\n",
    "                number_list = []\n",
    "                rank_list = []\n",
    "                stat_list = []\n",
    "                for stat in stats:\n",
    "                    find_index = [table_element.index(s) for s in table_element if stat == s]\n",
    "                    if find_index:\n",
    "                        my_list = table_element[find_index[0]+1].split(' ')\n",
    "                        number_list.append(my_list[0])\n",
    "                        stat_list.append(stat)\n",
    "                        if len(my_list) > 1:\n",
    "                            rank_list.append(my_list[-1])\n",
    "                    if stat == 'Self-Citations':\n",
    "                        find_index = [table_element.index(s) for s in table_element if stat in s]\n",
    "                        if find_index:\n",
    "                            stat_list.append(stat)\n",
    "                            number_list.append(table_element[find_index[0]].split(' ')[1])\n",
    "                zip_number_list = list(zip(stat_list, number_list))\n",
    "                zip_rank_list = list(zip(stat_list, rank_list))\n",
    "                number_dict = create_dataframe_dict(zip_number_list)\n",
    "                rank_dict = create_dataframe_dict(zip_rank_list)\n",
    "                df_number = pd.DataFrame.from_dict(number_dict, orient='index').transpose()\n",
    "                df_rank = pd.DataFrame.from_dict(rank_dict, orient='index').transpose()\n",
    "                df_number = df_number.replace('na', '0')\n",
    "                df_number = df_number.replace('', '0')\n",
    "                df_number = df_number.replace(' ', '0')\n",
    "                df_number = remove_commas(df_number)\n",
    "                df_number = df_number.astype(float)\n",
    "                if df_sub.empty:\n",
    "                    df_sub = df_number\n",
    "                else: \n",
    "                    df_sub = df_sub.add(df_number)\n",
    "                \n",
    "                title_index = 3\n",
    "                stats_index = 4\n",
    "                topic_index = 0\n",
    "                topic_div_index = 0\n",
    "                topic_array = soup.findAll('div', {'class': 'topics'})\n",
    "                element = title_index\n",
    "                df = pd.DataFrame(columns = ['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics'])\n",
    "                while element:\n",
    "                    data_stream = []\n",
    "                    x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                    element = driver.find_elements_by_xpath(x_path_title)\n",
    "                    #Get title:\n",
    "                    if element:\n",
    "                        scraped_papers = True\n",
    "                        for elm in element:\n",
    "                            data_stream.append(elm.text)\n",
    "                        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]')\n",
    "                        for elm in element:\n",
    "                            my_list = elm.text\n",
    "                        if [a for a in my_list.split('\\n') if last_name in a]:   \n",
    "                            data_stream.append([a for a in my_list.split('\\n') if last_name in a][0])\n",
    "                        else:\n",
    "                            data_stream.append('na')\n",
    "                        if [a for a in my_list.split('\\n') if 'Vol.' in a]:\n",
    "                            data_stream.append([a for a in my_list.split('\\n') if 'Vol.' in a][0])\n",
    "                        else:\n",
    "                            data_stream.append('na')\n",
    "                        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(stats_index) + ']/div[2]/div')\n",
    "                        for elm in element:\n",
    "                            cited_text = elm.text\n",
    "                        article_citations = 'na'\n",
    "                        case_citations = 'na'\n",
    "                        accessed = 'na'\n",
    "                        if not isinstance(cited_text, list):\n",
    "                            cited_text = cited_text.split('\\n')\n",
    "                            cited_text\n",
    "                            for stat in cited_text:\n",
    "                                if 'Article' in stat:\n",
    "                                    article_citations = int(re.search(r'\\d+', stat).group())\n",
    "                                if 'Case' in stat:\n",
    "                                    case_citations = int(re.search(r'\\d+', stat).group())\n",
    "                                if 'Accessed' in stat:\n",
    "                                    accessed = int(re.search(r'\\d+', stat).group())\n",
    "                        data_stream.append(article_citations)\n",
    "                        data_stream.append(case_citations)\n",
    "                        data_stream.append(accessed)\n",
    "                        if 'Topics:' in my_list:\n",
    "                            data_stream.append(topic_array[topic_div_index].text.split(':')[1])\n",
    "                            topic_div_index +=1\n",
    "                        else:\n",
    "                            data_stream.append('na')\n",
    "                        df = df.append(pd.DataFrame([data_stream], columns = ['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']))\n",
    "                        stats_index +=4\n",
    "                        title_index += 4\n",
    "                        page_name.append(cur_page)\n",
    "                        #Check that next paper exists:\n",
    "                        x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                        element = driver.find_elements_by_xpath(x_path_title)\n",
    "                df.to_csv(create_path('author_papers', '{}_{}_papers.csv'.format(full_name, school)))\n",
    "                time.sleep(3)\n",
    "            print('No remaining pages to scrape for {}.'.format(fm_name + ' ' + last_name))  \n",
    "        if not df_sub.empty:\n",
    "            my_dict = {'Person': [full_name], 'School': [school], 'Type': ['number']}\n",
    "            name_data = pd.DataFrame(my_dict)\n",
    "            df_sub = pd.concat([name_data, df_sub], sort = False, axis = 1)\n",
    "            main_df = pd.concat([main_df, df_sub], sort = False)\n",
    "            main_df.replace(0, 'na')\n",
    "            main_df.to_csv(create_path('school_stats', '{}_stats.csv'.format(school_name)))                \n",
    "        skip_df.to_csv(create_path('skipped_names', '{}_skipped.csv'.format(school_name)))\n",
    "                    \n",
    "skip_df.to_csv(create_path('skipped_names', '{}_skipped.csv'.format(school_name)))\n",
    "main_df.replace(0, 'na')\n",
    "main_df.to_csv(create_path('school_stats', '{}_stats.csv'.format(school_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'missed_names.csv'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4df7a0f99806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtopic_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtopic_div_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtopic_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'topics'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Author(s)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Journal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cited (articles)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cited (cases)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Accessed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Topics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "last_name = 'Cohen'\n",
    "title_index = 3\n",
    "stats_index = 4\n",
    "topic_index = 0\n",
    "topic_div_index = 0\n",
    "topic_array = soup.findAll('div', {'class': 'topics'})\n",
    "element = title_index\n",
    "df = pd.DataFrame(columns = ['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics'])\n",
    "while element:\n",
    "    data_stream = []\n",
    "    x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "    element = driver.find_elements_by_xpath(x_path_title)\n",
    "    #Get title:\n",
    "    if element:\n",
    "        scraped_papers = True\n",
    "        for elm in element:\n",
    "            data_stream.append(elm.text)\n",
    "        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]')\n",
    "        for elm in element:\n",
    "            my_list = elm.text\n",
    "        if [a for a in my_list.split('\\n') if last_name in a]:   \n",
    "            data_stream.append([a for a in my_list.split('\\n') if last_name in a][0])\n",
    "        else:\n",
    "            data_stream.append('na')\n",
    "        if [a for a in my_list.split('\\n') if 'Vol.' in a]:\n",
    "            data_stream.append([a for a in my_list.split('\\n') if 'Vol.' in a][0])\n",
    "        else:\n",
    "            data_stream.append('na')\n",
    "        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(stats_index) + ']/div[2]/div')\n",
    "        for elm in element:\n",
    "            cited_text = elm.text\n",
    "        article_citations = 'na'\n",
    "        case_citations = 'na'\n",
    "        accessed = 'na'\n",
    "        if not isinstance(cited_text, list):\n",
    "            cited_text = cited_text.split('\\n')\n",
    "            cited_text\n",
    "            for stat in cited_text:\n",
    "                if 'Article' in stat:\n",
    "                    article_citations = int(re.search(r'\\d+', stat).group())\n",
    "                if 'Case' in stat:\n",
    "                    case_citations = int(re.search(r'\\d+', stat).group())\n",
    "                if 'Accessed' in stat:\n",
    "                    accessed = int(re.search(r'\\d+', stat).group())\n",
    "        data_stream.append(article_citations)\n",
    "        data_stream.append(case_citations)\n",
    "        data_stream.append(accessed)\n",
    "        if 'Topics:' in my_list:\n",
    "            data_stream.append(topic_array[topic_div_index].text.split(':')[1])\n",
    "            topic_div_index +=1\n",
    "        else:\n",
    "            data_stream.append('na')\n",
    "        df = df.append(pd.DataFrame([data_stream], columns = ['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']))\n",
    "        stats_index +=4\n",
    "        title_index += 4\n",
    "        page_name.append(cur_page)\n",
    "        #Check that next paper exists:\n",
    "        x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "        element = driver.find_elements_by_xpath(x_path_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub = pd.DataFrame()\n",
    "# main_df = pd.DataFrame()\n",
    "stats = ['Cited by Cases','Cited by Articles','Accessed (Past 12 Months)','Cited by Articles (Past 10 Years)', 'Cited by Articles (Past 1-2 years)', 'ScholarCheck Rank', 'Average Citations per Article', 'Average Citations per Document', 'Self-Citations']\n",
    "last_name = 'Dauber'\n",
    "mid_first_name = 'Michele Landis'\n",
    "full_name = mid_first_name + ' ' + last_name\n",
    "school = 'Arizona'\n",
    "link = 'https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=' + last_name +  '%2C ' + mid_first_name + '&collection=journals'\n",
    "driver.get(link)\n",
    "element = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[2]/div[1]')\n",
    "table_element = element.text.split('\\n')\n",
    "number_list = []\n",
    "rank_list = []\n",
    "stat_list = []\n",
    "for stat in stats:\n",
    "#     print(stat)\n",
    "    find_index = [table_element.index(s) for s in table_element if stat == s]\n",
    "    if find_index:\n",
    "        my_list = table_element[find_index[0]+1].split(' ')\n",
    "        number_list.append(my_list[0])\n",
    "        stat_list.append(stat)\n",
    "        if len(my_list) > 1:\n",
    "            rank_list.append(my_list[-1])\n",
    "    if stat == 'Self-Citations':\n",
    "        find_index = [table_element.index(s) for s in table_element if stat in s]\n",
    "        if find_index:\n",
    "            stat_list.append(stat)\n",
    "            number_list.append(table_element[find_index[0]].split(' ')[1])\n",
    "zip_number_list = list(zip(stat_list, number_list))\n",
    "zip_rank_list = list(zip(stat_list, rank_list))\n",
    "number_dict = create_dataframe_dict(zip_number_list)\n",
    "rank_dict = create_dataframe_dict(zip_rank_list)\n",
    "df_number = pd.DataFrame.from_dict(number_dict, orient='index').transpose()\n",
    "df_rank = pd.DataFrame.from_dict(rank_dict, orient='index').transpose()\n",
    "df_number = df_number.replace('na', '0')\n",
    "df_number = df_number.replace('', '0')\n",
    "df_number = df_number.replace(' ', '0')\n",
    "df_number = df_number.astype(float)\n",
    "if df_sub.empty:\n",
    "    df_sub = df_number\n",
    "else: \n",
    "    df_sub = df_sub.add(df_number)\n",
    "df_sub\n",
    "my_dict = {'Person': [full_name], 'School': [school], 'Type': ['number']}\n",
    "name_data = pd.DataFrame(my_dict)\n",
    "df_sub = pd.concat([name_data, df_sub], sort = False, axis = 1)\n",
    "main_df = pd.concat([main_df, df_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>School</th>\n",
       "      <th>Type</th>\n",
       "      <th>Cited by Cases</th>\n",
       "      <th>Cited by Articles</th>\n",
       "      <th>Accessed (Past 12 Months)</th>\n",
       "      <th>Cited by Articles (Past 10 Years)</th>\n",
       "      <th>Cited by Articles (Past 1-2 years)</th>\n",
       "      <th>ScholarCheck Rank</th>\n",
       "      <th>Average Citations per Article</th>\n",
       "      <th>Average Citations per Document</th>\n",
       "      <th>Self-Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michele Landis Dauber</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>number</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>24.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Person   School    Type  Cited by Cases  Cited by Articles  \\\n",
       "0  Michele Landis Dauber  Arizona  number             0.0               97.0   \n",
       "\n",
       "   Accessed (Past 12 Months)  Cited by Articles (Past 10 Years)  \\\n",
       "0                       38.0                               45.0   \n",
       "\n",
       "   Cited by Articles (Past 1-2 years)  ScholarCheck Rank  \\\n",
       "0                                 2.0                0.0   \n",
       "\n",
       "   Average Citations per Article  Average Citations per Document  \\\n",
       "0                           97.0                           24.25   \n",
       "\n",
       "   Self-Citations  \n",
       "0             0.0  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_number = df_number.replace('na', '0')\n",
    "df_number = df_number.replace(' ', '0')\n",
    "df_number = df_number.astype(float)\n",
    "df_number.add(df_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>School</th>\n",
       "      <th>Type</th>\n",
       "      <th>Cited by Cases</th>\n",
       "      <th>Cited by Articles</th>\n",
       "      <th>Accessed (Past 12 Months)</th>\n",
       "      <th>Cited by Articles (Past 10 Years)</th>\n",
       "      <th>Cited by Articles (Past 1-2 years)</th>\n",
       "      <th>ScholarCheck Rank</th>\n",
       "      <th>Average Citations per Article</th>\n",
       "      <th>Average Citations per Document</th>\n",
       "      <th>Self-Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adsfdsa</td>\n",
       "      <td>dsafdsa</td>\n",
       "      <td>sdafdsaf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.41</td>\n",
       "      <td>15.9</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Person   School      Type  Cited by Cases  Cited by Articles  \\\n",
       "0  adsfdsa  dsafdsa  sdafdsaf             3.0              493.0   \n",
       "\n",
       "   Accessed (Past 12 Months)  Cited by Articles (Past 10 Years)  \\\n",
       "0                      645.0                              296.0   \n",
       "\n",
       "   Cited by Articles (Past 1-2 years)  ScholarCheck Rank  \\\n",
       "0                                36.0                0.0   \n",
       "\n",
       "   Average Citations per Article  Average Citations per Document  \\\n",
       "0                          22.41                            15.9   \n",
       "\n",
       "   Self-Citations  \n",
       "0            80.0  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {'Person': ['adsfdsa'], 'School': ['dsafdsa'], 'Type': ['sdafdsaf']}\n",
    "name_data = pd.DataFrame(my_dict)\n",
    "pd.concat([name_data, df_number], sort = False, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cited by Articles', 'Accessed (Past 12 Months)', 'Cited by Articles (Past 10 Years)', 'Cited by Articles (Past 1-2 years)', 'ScholarCheck Rank', 'Average Citations per Article', 'Average Citations per Document', 'Self-Citations']\n",
      "['99', '212', '99', '18', '', '9.90', '9.00', '6']\n",
      "['10,679', '8,754', '4,126', '1,898', '7,876']\n"
     ]
    }
   ],
   "source": [
    "element = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[2]/div[1]')\n",
    "stats = ['Cited by Cases','Cited by Articles','Accessed (Past 12 Months)','Cited by Articles (Past 10 Years)', 'Cited by Articles (Past 1-2 years)', 'ScholarCheck Rank', 'Average Citations per Article', 'Average Citations per Document', 'Self-Citations']\n",
    "table_element = element.text.split('\\n')\n",
    "number_list = []\n",
    "rank_list = []\n",
    "stat_list = []\n",
    "for stat in stats:\n",
    "#     print(stat)\n",
    "    find_index = [table_element.index(s) for s in table_element if stat == s]\n",
    "    if find_index:\n",
    "        my_list = table_element[find_index[0]+1].split(' ')\n",
    "        number_list.append(my_list[0])\n",
    "        stat_list.append(stat)\n",
    "        if len(my_list) > 1:\n",
    "            rank_list.append(my_list[-1])\n",
    "    if stat == 'Self-Citations':\n",
    "        find_index = [table_element.index(s) for s in table_element if stat in s]\n",
    "        stat_list.append(stat)\n",
    "        number_list.append(table_element[find_index[0]].split(' ')[1])\n",
    "\n",
    "print(stat_list)\n",
    "print(number_list)\n",
    "print(rank_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': ['1342'], 'b':['na'], 'c':['2']})\n",
    "df1 = df1.replace('na', '0')\n",
    "df1 = df1.astype(float)\n",
    "df2 = pd.DataFrame({'a': ['1'], 'b': ['2'], 'd':['na']})\n",
    "df2 = df2.replace('na', '0')\n",
    "df2 = df2.astype(float)\n",
    "df_out = df1.add(df2, fill_value=0)\n",
    "# # df_out.replace(0, 'na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1343.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a    b    c    d\n",
       "0  1343.0  2.0  2.0  0.0"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a  b  c\n",
       "0  1342  0  2"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1342'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1,342'.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraping",
   "language": "python",
   "name": "webscraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
