{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('selenium_env': conda)"
  },
  "interpreter": {
   "hash": "a6b47012f14d21a47a116f37ec44e00a94b21aded5509aefe8b70d4e685c6dab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import pathlib \n",
    "from fake_useragent import UserAgent\n",
    "from piapy import PiaVpn\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import modules.hein_scraping_functions\n",
    "from modules.create_path import create_path\n",
    "from modules.hein_scraping_functions import create_browser, webpage_wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the paths for the data directories\n",
    "input_path, work_path, intr_path, out_path, selenium_driver_path = create_path()\n",
    "\n",
    "# Create the paths for the Chrome binary and selenium driver\n",
    "chrome_binary_path = pathlib.Path(\"C:\\\\Program Files (x86)\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\")\n",
    "selenium_driver_full_path = selenium_driver_path / \"chromedriver.exe\"\n",
    "\n",
    "# Initalize the browsers that we are going to use\n",
    "driver = create_browser(chrome_binary_path, selenium_driver_full_path)\n",
    "\n",
    "driver.get(\"https://scholar.google.com/scholar?hl=en&as_sdt=5%2C36&sciodt=0%2C36&cites=17432944610365151854&scipsc=&q=%22Australian+Coastal+and+Marine+Law%22&oq=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the input directory\n",
    "google_scholar_df = pd.read_excel(input_path / \"google_scholar_paper_list.xlsx\", sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data already exists. Names that have already been scraped will be skipped\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     google1  FirstName   LastName  \\\n",
       "0          4    Richard    Delgado   \n",
       "1          4     Bryant      Garth   \n",
       "2          4    Herbert  Hovenkamp   \n",
       "3          4     Samuel       Moyn   \n",
       "4          4       Mary    Dudziak   \n",
       "..       ...        ...        ...   \n",
       "192        4   Cathleen     Kaveny   \n",
       "193        4     Lolita     Inniss   \n",
       "194        4    Wendell  Pritchett   \n",
       "195        4     Gideon      Yaffe   \n",
       "196        4  Elizabeth   Trujillo   \n",
       "\n",
       "                                                 Title  \\\n",
       "0               Critical Race Theory: The Cutting Edge   \n",
       "1    Dealing In Virtue: International Commercial Ar...   \n",
       "2              Enterprise And American Law: 1836-1937    \n",
       "3             The Last Utopia: Human Rights In History   \n",
       "4    Cold War Civil Rights: Race And The Image Of A...   \n",
       "..                                                 ...   \n",
       "192  Prophecy Without Contempt: Religious Rhetoric ...   \n",
       "193  The Princeton Fugitive Slave:  James Collins J...   \n",
       "194  Robert Clifton Weaver And The American City: T...   \n",
       "195  Manifest Activity: Thomas Reid’S Theory Of Action   \n",
       "196  Reframing The Trade And Environment Linkage Fo...   \n",
       "\n",
       "                                 google scholar search   ID PaperType Authors  \\\n",
       "0       Delgado Critical Race Theory: The Cutting Edge   59                     \n",
       "1    Garth Dealing In Virtue: International Commerc...   89                     \n",
       "2    Hovenkamp Enterprise And American Law: 1836-1937   122                     \n",
       "3        Moyn The Last Utopia: Human Rights In History  190                     \n",
       "4    Dudziak Cold War Civil Rights: Race And The Im...   65                     \n",
       "..                                                 ...  ...       ...     ...   \n",
       "192  Kaveny Prophecy Without Contempt: Religious Rh...  141                     \n",
       "193  Inniss The Princeton Fugitive Slave:  James Co...  129                     \n",
       "194  Pritchett Robert Clifton Weaver And The Americ...  217                     \n",
       "195  Yaffe Manifest Activity: Thomas Reid’S Theory ...  282                     \n",
       "196  Trujillo Reframing The Trade And Environment L...  266                     \n",
       "\n",
       "     NumCoauthors BBCite  ... Journal VolFirst  Year Pages Lateral NumPages  \\\n",
       "0               2         ...                   1995             1            \n",
       "1               2         ...                   1998             1            \n",
       "2               1         ...                   1991             1            \n",
       "3               1         ...                   2010             1            \n",
       "4               1         ...                   2000             1            \n",
       "..            ...    ...  ...     ...      ...   ...   ...     ...      ...   \n",
       "192             1         ...                   2016             1            \n",
       "193             1         ...                   2019             1            \n",
       "194             1         ...                   2008             1            \n",
       "195             1         ...                   2004             1            \n",
       "196             1         ...                   2020             1            \n",
       "\n",
       "    BookCites  LateralYear google scholar cite count  \\\n",
       "0       514.0       2013.0                       NaN   \n",
       "1       468.0       2012.0                       NaN   \n",
       "2       445.0       2017.0                       NaN   \n",
       "3       432.0       2017.0                       NaN   \n",
       "4       423.0       2012.0                       NaN   \n",
       "..        ...          ...                       ...   \n",
       "192       0.0       2014.0                       NaN   \n",
       "193       0.0       2017.0                       NaN   \n",
       "194       0.0       2014.0                       NaN   \n",
       "195       0.0       2012.0                       NaN   \n",
       "196       0.0       2016.0                       NaN   \n",
       "\n",
       "     google scholar article name  \n",
       "0                                 \n",
       "1                                 \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "..                           ...  \n",
       "192                               \n",
       "193                               \n",
       "194                               \n",
       "195                               \n",
       "196                               \n",
       "\n",
       "[197 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>google1</th>\n      <th>FirstName</th>\n      <th>LastName</th>\n      <th>Title</th>\n      <th>google scholar search</th>\n      <th>ID</th>\n      <th>PaperType</th>\n      <th>Authors</th>\n      <th>NumCoauthors</th>\n      <th>BBCite</th>\n      <th>...</th>\n      <th>Journal</th>\n      <th>VolFirst</th>\n      <th>Year</th>\n      <th>Pages</th>\n      <th>Lateral</th>\n      <th>NumPages</th>\n      <th>BookCites</th>\n      <th>LateralYear</th>\n      <th>google scholar cite count</th>\n      <th>google scholar article name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>Richard</td>\n      <td>Delgado</td>\n      <td>Critical Race Theory: The Cutting Edge</td>\n      <td>Delgado Critical Race Theory: The Cutting Edge</td>\n      <td>59</td>\n      <td></td>\n      <td></td>\n      <td>2</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>1995</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>514.0</td>\n      <td>2013.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Bryant</td>\n      <td>Garth</td>\n      <td>Dealing In Virtue: International Commercial Ar...</td>\n      <td>Garth Dealing In Virtue: International Commerc...</td>\n      <td>89</td>\n      <td></td>\n      <td></td>\n      <td>2</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>1998</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>468.0</td>\n      <td>2012.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>Herbert</td>\n      <td>Hovenkamp</td>\n      <td>Enterprise And American Law: 1836-1937</td>\n      <td>Hovenkamp Enterprise And American Law: 1836-1937</td>\n      <td>122</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>1991</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>445.0</td>\n      <td>2017.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Samuel</td>\n      <td>Moyn</td>\n      <td>The Last Utopia: Human Rights In History</td>\n      <td>Moyn The Last Utopia: Human Rights In History</td>\n      <td>190</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2010</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>432.0</td>\n      <td>2017.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Mary</td>\n      <td>Dudziak</td>\n      <td>Cold War Civil Rights: Race And The Image Of A...</td>\n      <td>Dudziak Cold War Civil Rights: Race And The Im...</td>\n      <td>65</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2000</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>423.0</td>\n      <td>2012.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>4</td>\n      <td>Cathleen</td>\n      <td>Kaveny</td>\n      <td>Prophecy Without Contempt: Religious Rhetoric ...</td>\n      <td>Kaveny Prophecy Without Contempt: Religious Rh...</td>\n      <td>141</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2016</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>0.0</td>\n      <td>2014.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>4</td>\n      <td>Lolita</td>\n      <td>Inniss</td>\n      <td>The Princeton Fugitive Slave:  James Collins J...</td>\n      <td>Inniss The Princeton Fugitive Slave:  James Co...</td>\n      <td>129</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2019</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>0.0</td>\n      <td>2017.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>4</td>\n      <td>Wendell</td>\n      <td>Pritchett</td>\n      <td>Robert Clifton Weaver And The American City: T...</td>\n      <td>Pritchett Robert Clifton Weaver And The Americ...</td>\n      <td>217</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2008</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>0.0</td>\n      <td>2014.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>4</td>\n      <td>Gideon</td>\n      <td>Yaffe</td>\n      <td>Manifest Activity: Thomas Reid’S Theory Of Action</td>\n      <td>Yaffe Manifest Activity: Thomas Reid’S Theory ...</td>\n      <td>282</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2004</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>0.0</td>\n      <td>2012.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>4</td>\n      <td>Elizabeth</td>\n      <td>Trujillo</td>\n      <td>Reframing The Trade And Environment Linkage Fo...</td>\n      <td>Trujillo Reframing The Trade And Environment L...</td>\n      <td>266</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2020</td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td>0.0</td>\n      <td>2016.0</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>197 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Check to see if the file for the alternate names data already exists.\n",
    "# If it does, we only want to look for the missing observations\n",
    "df_cur = intr_path / \"_google_scholar_cites_df.xlsx\"\n",
    "if df_cur.exists():\n",
    "    print(\"Data already exists. Names that have already been scraped will be skipped\")\n",
    "    # Set the append flag to 1\n",
    "    append = 1\n",
    "    # Create the dataset of existing alt names.\n",
    "    df_existing_data = pd.read_excel(df_cur)\n",
    "    # df_existing_data['ID'] = df_existing_data['ID'].apply(lambda x: '{0:0>4}'.format(x))\n",
    "    # Complete a left outer join of the existing alt names and the lateral/control data to get \n",
    "    # a list of the names that we still need to scrape alt names for.\n",
    "    data = pd.merge(google_scholar_df, df_existing_data[[\"ID\", \"Title\", \"google1\"]], how = \"outer\", left_on = [\"ID\", \"Title\", \"google1\"], right_on = [\"ID\", \"Title\", \"google1\"], indicator=True)\n",
    "    data = data[data['_merge'] == 'left_only']\n",
    "    data = data.drop([\"_merge\"], axis = 1)\n",
    "    append_df = df_existing_data\n",
    "else:\n",
    "    # Set the append flag to zero because we won't have any data to append\n",
    "    append = 0\n",
    "    data = google_scholar_df\n",
    "    append_df = pd.DataFrame().reindex(columns=list(google_scholar_df.columns) + [\"google scholar cite count\"])\n",
    "\n",
    "data = data[data[\"google1\"] == 4]\n",
    "data = data[data[\"ID\"] != \"\"]\n",
    "data.replace(np.nan, '', regex=True, inplace = True)\n",
    "data[\"google scholar cite count\"] = np.nan\n",
    "data[\"google scholar article name\"] = \"\"\n",
    "data.reset_index(drop=True, inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_google_scholar(search_text, driver, chrome_binary_path, selenium_driver_path):    \n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": userAgent})\n",
    "    \n",
    "    # Look for the number of results pannel\n",
    "    element = []\n",
    "    while not element:\n",
    "        try:\n",
    "            driver.get(f\"https://scholar.google.com/scholar?hl=en&as_sdt=5%2C36&sciodt=0%2C36&cites=17432944610365151854&scipsc=&q={search_text}\")\n",
    "            # If page contains \"did not match any articles\", move to the next name. If we hit the automated queries page, quit.\n",
    "            page_text = driver.find_element_by_tag_name('body')\n",
    "            if \"did not match any articles\" in page_text.text:\n",
    "                return np.nan, \"\", driver\n",
    "            elif \"but your computer or network may be sending automated queries. To protect our users, we can't process\" in page_text.text:\n",
    "                driver.quit()\n",
    "                driver = create_browser(chrome_binary_path, selenium_driver_path)\n",
    "            element = driver.find_element_by_xpath('//*[@id=\"gs_res_ccl_mid\"]/div/div/div[3]/a[3]')\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                element = driver.find_element_by_xpath('//*[@id=\"gs_res_ccl_mid\"]/div/div/div[2]/a[3]')\n",
    "            except NoSuchElementException:\n",
    "                print('Page has not loaded, switching user agent and VPN')\n",
    "                # Switch User Agent to new random value\n",
    "                ua = UserAgent()\n",
    "                userAgent = ua.random\n",
    "                driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": userAgent})\n",
    "                # Switch VPN to new random value\n",
    "                vpn = PiaVpn()\n",
    "                vpn.set_region(server='random')\n",
    "                vpn.connect(verbose=True, timeout=20)\n",
    "                time.sleep(3)\n",
    "\n",
    "    results_count_text = element.text\n",
    "\n",
    "    # This only matches integers up to 999,999, but I doubt that will be a problem.\n",
    "    match = re.search(r\"^Cited by (0|[1-9]\\d{0,2},?\\d*)\", results_count_text)\n",
    "    if match == None:\n",
    "        result_count = 0\n",
    "    else:\n",
    "        result_count = match.group(1)\n",
    "    \n",
    "    # Get the article name\n",
    "    try:\n",
    "        element = driver.find_element_by_xpath('//*[@id=\"gs_res_ccl_mid\"]/div[1]/div/h3')\n",
    "        article_name = element.text\n",
    "    except NoSuchElementException:\n",
    "        article_name = \"\"\n",
    "        \n",
    "    time.sleep(5*np.random.random() + 5) \n",
    "    return result_count, article_name, driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Page has not loaded, switching user agent and VPN\n",
      "VPN connected to: \"mongolia\"\n",
      "Page has not loaded, switching user agent and VPN\n",
      "VPN connected to: \"austria\"\n",
      "Page has not loaded, switching user agent and VPN\n",
      "VPN connected to: \"cambodia\"\n",
      "Page has not loaded, switching user agent and VPN\n",
      "VPN connected to: \"bangladesh\"\n",
      "Page has not loaded, switching user agent and VPN\n",
      "VPN connected to: \"bulgaria\"\n",
      "Page has not loaded, switching user agent and VPN\n",
      "VPN connected to: \"liechtenstein\"\n",
      "Page has not loaded, switching user agent and VPN\n",
      "VPN connected to: \"macedonia\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    # Read the current row of the df into a dictionary\n",
    "    dict = data.to_dict('records')[i]\n",
    "    # Update the cite count variable\n",
    "    dict[\"google scholar cite count\"], dict[\"google scholar article name\"], driver = search_google_scholar(data.iloc[i, 4], driver, chrome_binary_path, selenium_driver_full_path)   \n",
    "    append_df = append_df.append(dict, ignore_index = True)\n",
    "    append_df.to_excel(intr_path / \"_google_scholar_cites_df.xlsx\", index = False)\n",
    "    groupd_df = append_df[append_df[\"google1\"] == 4]\n",
    "    groupd_df.to_excel(intr_path / \"_google_scholar_cites_group_4.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\marti\\anaconda3\\envs\\selenium_env\\lib\\site-packages\\pandas\\core\\frame.py:4379: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().replace(\n<ipython-input-12-479db271acf4>:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  groupd_df[\"Name Dist Ratio\"] = groupd_df.apply(lambda x: fuzz.ratio(x[\"Title\"].lower(), x[\"google scholar article name\"].lower()), axis = 1)\n"
     ]
    }
   ],
   "source": [
    "groupd_df.replace(np.nan, '', regex=True, inplace = True)\n",
    "groupd_df[\"Name Dist Ratio\"] = groupd_df.apply(lambda x: fuzz.ratio(x[\"Title\"].lower(), x[\"google scholar article name\"].lower()), axis = 1)\n",
    "groupd_df = groupd_df[['google1', 'FirstName', 'LastName', 'Title', 'google scholar article name', 'Name Dist Ratio', 'google scholar search', 'ID', 'PaperType', 'Authors', 'NumCoauthors', 'BBCite', 'BBCiteYear', 'BBCiteYearFirst', 'ArticleCites', 'CaseCites', 'Accessed', 'Journal','VolFirst', 'Year', 'Pages', 'Lateral', 'NumPages', 'BookCites', 'LateralYear', 'google scholar cite count']]\n",
    "groupd_df.to_excel(intr_path / \"_google_scholar_cites_group_4.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}