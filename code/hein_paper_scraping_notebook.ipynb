{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "web_scraping",
   "display_name": "web_scraping",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import nltk\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import pathlib \n",
    "import modules.hein_scraping_functions\n",
    "\n",
    "from modules.create_path import create_path\n",
    "from modules.hein_scraping_functions import create_browser, webpage_wait, get_paper_data, mod_names, check_bing, search_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the paths for the data directories\n",
    "input_path, work_path, intr_path, out_path, selenium_driver_path = create_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the paths for the Chrome binary and selenium driver\n",
    "chrome_binary_path = pathlib.Path(\"C:\\\\Program Files (x86)\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\")\n",
    "selenium_driver_full_path = selenium_driver_path / \"chromedriver.exe\"\n",
    "\n",
    "# Initalize the browsers that we are going to use\n",
    "driver = create_browser(chrome_binary_path, selenium_driver_full_path)\n",
    "\n",
    "driver.get(\"http://proxy.its.virginia.edu/login?url=http://heinonline.org/HOL/Welcome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets from the working directory\n",
    "# The datasets in the working directory have already \n",
    "# been cleaned.\n",
    "input_data = pd.read_excel(intr_path / \"hein_scraping_input_data.xlsx\")\n",
    "data = input_data\n",
    "data_type = \"control\"\n",
    "\n",
    "# Create the list of scraped pages columns\n",
    "scraped_pages_columns = [\"links\", \"file_names\", \"professor_names\", \"id\"]\n",
    "# Load the list of scraped pages if it exists\n",
    "scraped_pages_file = out_path / \"_scraped_pages.xlsx\"\n",
    "if scraped_pages_file.exists():\n",
    "    print(\"Data already exists. Names that have already been scraped will be skipped\")\n",
    "    # Create the dataset of existing alt names.\n",
    "    df_scraped_pages = pd.read_excel(scraped_pages_file)\n",
    "else:\n",
    "    df_scraped_pages = pd.DataFrame(columns = scraped_pages_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ID FirstName   LastName  multi_obs  Short URL Destination  \\\n",
       "0    1001    Andrew      Moore        0.0                    NaN   \n",
       "1    1002     Bryan    Adamson        0.0                    NaN   \n",
       "2    1003  Nicholas     Allard        0.0                    NaN   \n",
       "3    1004     Scott     Altman        0.0                    NaN   \n",
       "4    1005   Michael   Ambrosio        0.0                    NaN   \n",
       "..    ...       ...        ...        ...                    ...   \n",
       "289  1276    Jarrod       Wong        0.0                    NaN   \n",
       "290  1277        Mo      Zhang        0.0                    NaN   \n",
       "291  1278    Donald    Zillman        0.0                    NaN   \n",
       "292  1279      Adam  Zimmerman        0.0                    NaN   \n",
       "293  1280    Julian    Velasco        NaN                    NaN   \n",
       "\n",
       "    Short URL Origin  Lateral  LateralYear          Origin School  \\\n",
       "0                NaN      NaN          NaN                    NaN   \n",
       "1                NaN      NaN          NaN                    NaN   \n",
       "2                NaN      NaN          NaN                    NaN   \n",
       "3                NaN      NaN          NaN                    NaN   \n",
       "4                NaN      NaN          NaN                    NaN   \n",
       "..               ...      ...          ...                    ...   \n",
       "289              NaN      NaN          NaN                    NaN   \n",
       "290              NaN      NaN          NaN                    NaN   \n",
       "291              NaN      NaN          NaN                    NaN   \n",
       "292              NaN      NaN          NaN                    NaN   \n",
       "293           nd.edu      0.0          NaN  Notre Dame Law School   \n",
       "\n",
       "     Destination School  multi_obs_x  multi_obs_y  alt_url  \\\n",
       "0                   NaN          NaN          NaN        0   \n",
       "1                   NaN          NaN          NaN        0   \n",
       "2                   NaN          NaN          NaN        0   \n",
       "3                   NaN          NaN          NaN        0   \n",
       "4                   NaN          NaN          NaN        0   \n",
       "..                  ...          ...          ...      ...   \n",
       "289                 NaN          NaN          NaN        0   \n",
       "290                 NaN          NaN          NaN        0   \n",
       "291                 NaN          NaN          NaN        0   \n",
       "292                 NaN          NaN          NaN        0   \n",
       "293                 NaN          0.0          0.0        0   \n",
       "\n",
       "                fm_names  ID_counts unusual_name_flag  \n",
       "0      Andrew, Andrew F.          1               NaN  \n",
       "1        Bryan, Bryan L.          1               NaN  \n",
       "2            Nicholas W.          1               NaN  \n",
       "3                  Scott          1               NaN  \n",
       "4    Michael P., Michael          1               NaN  \n",
       "..                   ...        ...               ...  \n",
       "289               Jarrod          1               NaN  \n",
       "290                   Mo          1               NaN  \n",
       "291    Donald, Donald N.          1               NaN  \n",
       "292              Adam S.          1               NaN  \n",
       "293               Julian          1               NaN  \n",
       "\n",
       "[294 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>FirstName</th>\n      <th>LastName</th>\n      <th>multi_obs</th>\n      <th>Short URL Destination</th>\n      <th>Short URL Origin</th>\n      <th>Lateral</th>\n      <th>LateralYear</th>\n      <th>Origin School</th>\n      <th>Destination School</th>\n      <th>multi_obs_x</th>\n      <th>multi_obs_y</th>\n      <th>alt_url</th>\n      <th>fm_names</th>\n      <th>ID_counts</th>\n      <th>unusual_name_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1001</td>\n      <td>Andrew</td>\n      <td>Moore</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Andrew, Andrew F.</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>Bryan</td>\n      <td>Adamson</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Bryan, Bryan L.</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1003</td>\n      <td>Nicholas</td>\n      <td>Allard</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Nicholas W.</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1004</td>\n      <td>Scott</td>\n      <td>Altman</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Scott</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>Michael</td>\n      <td>Ambrosio</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Michael P., Michael</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>1276</td>\n      <td>Jarrod</td>\n      <td>Wong</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Jarrod</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>1277</td>\n      <td>Mo</td>\n      <td>Zhang</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Mo</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>1278</td>\n      <td>Donald</td>\n      <td>Zillman</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Donald, Donald N.</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>1279</td>\n      <td>Adam</td>\n      <td>Zimmerman</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Adam S.</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>293</th>\n      <td>1280</td>\n      <td>Julian</td>\n      <td>Velasco</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nd.edu</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>Notre Dame Law School</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>Julian</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>294 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rcus.\n",
      "Jonathan Masur\n",
      "Name list: ['Jonathan S.', 'Jonathan']\n",
      "Looking for Jonathan S. Masur\n",
      "Scraping the page\n",
      "Done scraping for Jonathan S. Masur.\n",
      "Looking for Jonathan Masur\n",
      "A file for Jonathan Masur already exists. Moving to the next name.\n",
      "Linda McClain\n",
      "Name list: ['Linda', 'Linda C.']\n",
      "Looking for Linda McClain\n",
      "Scraping the page\n",
      "Done scraping for Linda McClain.\n",
      "Looking for Linda C. McClain\n",
      "A file for Linda C. McClain already exists. Moving to the next name.\n",
      "David McCord\n",
      "Name list: ['David']\n",
      "Looking for David McCord\n",
      "Scraping the page\n",
      "Done scraping for David McCord.\n",
      "Thomas McDonnell\n",
      "Name list: ['Thomas M.']\n",
      "Looking for Thomas M. McDonnell\n",
      "Scraping the page\n",
      "Done scraping for Thomas M. McDonnell.\n",
      "Denis McLaughlin\n",
      "Name list: ['Denis F.']\n",
      "Looking for Denis F. McLaughlin\n",
      "Scraping the page\n",
      "Done scraping for Denis F. McLaughlin.\n",
      "Peter Menell\n",
      "Name list: ['Peter S.']\n",
      "Looking for Peter S. Menell\n",
      "Scraping the page\n",
      "Done scraping for Peter S. Menell.\n",
      "Douglas Michael\n",
      "Name list: ['Douglas', 'Douglas C.']\n",
      "Looking for Douglas Michael\n",
      "Scraping the page\n",
      "Done scraping for Douglas Michael.\n",
      "Looking for Douglas C. Michael\n",
      "A file for Douglas C. Michael already exists. Moving to the next name.\n",
      "Richard Seamon\n",
      "Name list: ['Richard Henry', 'Richard H.', 'Richard']\n",
      "Looking for Richard Henry Seamon\n",
      "Scraping the page\n",
      "Done scraping for Richard Henry Seamon.\n",
      "Looking for Richard H. Seamon\n",
      "A file for Richard H. Seamon already exists. Moving to the next name.\n",
      "Looking for Richard Seamon\n",
      "A file for Richard Seamon already exists. Moving to the next name.\n",
      "David Millon\n",
      "Name list: ['David']\n",
      "Looking for David Millon\n",
      "Scraping the page\n",
      "Done scraping for David Millon.\n",
      "Dalia Mitchell\n",
      "Name list: ['Dalia Tsuk']\n",
      "Looking for Dalia Tsuk Mitchell\n",
      "Scraping the page\n",
      "Done scraping for Dalia Tsuk Mitchell.\n",
      "Dalia Tsuk\n",
      "Name list: ['Dalia']\n",
      "Looking for Dalia Tsuk\n",
      "Scraping the page\n",
      "Done scraping for Dalia Tsuk.\n",
      "Mark Moller\n",
      "Name list: ['Mark']\n",
      "Looking for Mark Moller\n",
      "Scraping the page\n",
      "Done scraping for Mark Moller.\n",
      "Stephen Morse\n",
      "Name list: ['Stephen J.']\n",
      "Looking for Stephen J. Morse\n",
      "Scraping the page\n",
      "Done scraping for Stephen J. Morse.\n",
      "Seymour Moskowitz\n",
      "Name list: ['Seymour H.', 'Seymour']\n",
      "Looking for Seymour H. Moskowitz\n",
      "Scraping the page\n",
      "Done scraping for Seymour H. Moskowitz.\n",
      "Looking for Seymour Moskowitz\n",
      "Scraping the page\n",
      "Done scraping for Seymour Moskowitz.\n",
      "Eric Muller\n",
      "Name list: ['Eric L.', 'Eric']\n",
      "Looking for Eric L. Muller\n",
      "Scraping the page\n",
      "Done scraping for Eric L. Muller.\n",
      "Looking for Eric Muller\n",
      "A file for Eric Muller already exists. Moving to the next name.\n",
      "Timothy Mulvaney\n",
      "Name list: ['Timothy M.']\n",
      "Looking for Timothy M. Mulvaney\n",
      "Scraping the page\n",
      "Done scraping for Timothy M. Mulvaney.\n",
      "Brian Murchison\n",
      "Name list: ['Brian C.', 'Brian']\n",
      "Looking for Brian C. Murchison\n",
      "Scraping the page\n",
      "Done scraping for Brian C. Murchison.\n",
      "Looking for Brian Murchison\n",
      "A file for Brian Murchison already exists. Moving to the next name.\n",
      "Colleen Murphy\n",
      "Name list: ['Colleen', 'Colleen (I)']\n",
      "Looking for Colleen Murphy\n",
      "Scraping the page\n",
      "Done scraping for Colleen Murphy.\n",
      "Looking for Colleen (I) Murphy\n",
      "A file for Colleen (I) Murphy already exists. Moving to the next name.\n",
      "William Nelson\n",
      "Name list: ['William E.']\n",
      "Looking for William E. Nelson\n",
      "Scraping the page\n",
      "Done scraping for William E. Nelson.\n",
      "Joseph Norton\n",
      "Name list: ['Joseph J.']\n",
      "Looking for Joseph J. Norton\n",
      "Scraping the page\n",
      "Done scraping for Joseph J. Norton.\n",
      "Kimberly Norwood\n",
      "Name list: ['Kimberly Jade']\n",
      "Looking for Kimberly Jade Norwood\n",
      "Scraping the page\n",
      "Done scraping for Kimberly Jade Norwood.\n",
      "Barbara O'Brien\n",
      "Name list: ['Barbara']\n",
      "Looking for Barbara O'Brien\n",
      "Scraping the page\n",
      "Done scraping for Barbara O'Brien.\n",
      "Catherine O'Grady\n",
      "Name list: ['Catherine']\n",
      "Looking for Catherine O'Grady\n",
      "Scraping the page\n",
      "Done scraping for Catherine O'Grady.\n",
      "Christiana Ochoa\n",
      "Name list: ['Christiana']\n",
      "Looking for Christiana Ochoa\n",
      "Scraping the page\n",
      "Done scraping for Christiana Ochoa.\n",
      "J. Oldham\n",
      "Name list: ['J.', 'J. Thomas']\n",
      "Looking for J. Oldham\n",
      "No data was found for J. Oldham. Moving to the next name.\n",
      "Looking for J. Thomas Oldham\n",
      "Scraping the page\n",
      "Done scraping for J. Thomas Oldham.\n",
      "David Opderbeck\n",
      "Name list: ['David W.']\n",
      "Looking for David W. Opderbeck\n",
      "Scraping the page\n",
      "Done scraping for David W. Opderbeck.\n",
      "Myron Orfield\n",
      "Name list: ['Myron', 'Myron W. Jr.']\n",
      "Looking for Myron Orfield\n",
      "Scraping the page\n",
      "Done scraping for Myron Orfield.\n",
      "Looking for Myron W. Jr. Orfield\n",
      "A file for Myron W. Jr. Orfield already exists. Moving to the next name.\n",
      "Spencer Overton\n",
      "Name list: ['Spencer', 'Spencer A.']\n",
      "Looking for Spencer Overton\n",
      "Scraping the page\n",
      "Done scraping for Spencer Overton.\n",
      "Looking for Spencer A. Overton\n",
      "A file for Spencer A. Overton already exists. Moving to the next name.\n",
      "Stefan Padfield\n",
      "Name list: ['Stefan J.']\n",
      "Looking for Stefan J. Padfield\n",
      "Scraping the page\n",
      "Done scraping for Stefan J. Padfield.\n",
      "William Patton\n",
      "Name list: ['William Wesley']\n",
      "Looking for William Wesley Patton\n",
      "Scraping the page\n",
      "Done scraping for William Wesley Patton.\n",
      "Stephen Pepper\n",
      "Name list: ['Stephen', 'Stephen L.']\n",
      "Looking for Stephen Pepper\n",
      "Scraping the page\n",
      "Done scraping for Stephen Pepper.\n",
      "Looking for Stephen L. Pepper\n",
      "A file for Stephen L. Pepper already exists. Moving to the next name.\n",
      "Huyen Pham\n",
      "Name list: ['Huyen']\n",
      "Looking for Huyen Pham\n",
      "Scraping the page\n",
      "Done scraping for Huyen Pham.\n",
      "Bruce Price\n",
      "Name list: ['Bruce M.']\n",
      "Looking for Bruce M. Price\n",
      "Scraping the page\n",
      "Done scraping for Bruce M. Price.\n",
      "Nicholson Price\n",
      "Name list: ['W. Nicholson II']\n",
      "Looking for W. Nicholson II Price\n",
      "Scraping the page\n",
      "Done scraping for W. Nicholson II Price.\n",
      "Asifa Quraishi\n",
      "Name list: ['Asifa']\n",
      "Looking for Asifa Quraishi\n",
      "Scraping the page\n",
      "Done scraping for Asifa Quraishi.\n",
      "Asifa Quraishi-Landes\n",
      "Name list: ['Asifa']\n",
      "Looking for Asifa Quraishi-Landes\n",
      "Scraping the page\n",
      "Done scraping for Asifa Quraishi-Landes.\n",
      "Robert Ragazzo\n",
      "Name list: ['Robert A.']\n",
      "Looking for Robert A. Ragazzo\n",
      "Scraping the page\n",
      "Done scraping for Robert A. Ragazzo.\n",
      "Carolyn Ramsey\n",
      "Name list: ['Carolyn B.']\n",
      "Looking for Carolyn B. Ramsey\n",
      "Scraping the page\n",
      "Done scraping for Carolyn B. Ramsey.\n",
      "Jason Rantanen\n",
      "Name list: ['Jason', 'Jason A.']\n",
      "Looking for Jason Rantanen\n",
      "Scraping the page\n",
      "Done scraping for Jason Rantanen.\n",
      "Looking for Jason A. Rantanen\n",
      "A file for Jason A. Rantanen already exists. Moving to the next name.\n",
      "Aaron Rappaport\n",
      "Name list: ['Aaron']\n",
      "Looking for Aaron Rappaport\n",
      "Scraping the page\n",
      "Done scraping for Aaron Rappaport.\n",
      "Alan Rau\n",
      "Name list: ['Alan Scott', 'Alan']\n",
      "Looking for Alan Scott Rau\n",
      "Scraping the page\n",
      "Done scraping for Alan Scott Rau.\n",
      "Looking for Alan Rau\n",
      "A file for Alan Rau already exists. Moving to the next name.\n",
      "Kal Raustiala\n",
      "Name list: ['Kal']\n",
      "Looking for Kal Raustiala\n",
      "Scraping the page\n",
      "Done scraping for Kal Raustiala.\n",
      "R. Anthony Reese\n",
      "Name list: ['R. Anthony']\n",
      "Looking for R. Anthony Reese\n",
      "Scraping the page\n",
      "Done scraping for R. Anthony Reese.\n",
      "Dana Brakman Reiser\n",
      "Name list: ['Dana Brakman']\n",
      "Looking for Dana Brakman Reiser\n",
      "Scraping the page\n",
      "Done scraping for Dana Brakman Reiser.\n",
      "Jesse Richardson\n",
      "Name list: ['Jesse J. Jr.']\n",
      "Looking for Jesse J. Jr. Richardson\n",
      "Scraping the page\n",
      "Done scraping for Jesse J. Jr. Richardson.\n",
      "Kimberly Jenkins\n",
      "Name list: ['Kimberly J.']\n",
      "Looking for Kimberly J. Jenkins\n",
      "Scraping the page\n",
      "Done scraping for Kimberly J. Jenkins.\n",
      "Kimberly Robinson\n",
      "Name list: ['Kimberly', 'Kimberly Jenkins', 'Kimberly J.']\n",
      "Looking for Kimberly Robinson\n",
      "Scraping the page\n",
      "Done scraping for Kimberly Robinson.\n",
      "Looking for Kimberly Jenkins Robinson\n",
      "Scraping the page\n",
      "Done scraping for Kimberly Jenkins Robinson.\n",
      "Looking for Kimberly J. Robinson\n",
      "Scraping the page\n",
      "Done scraping for Kimberly J. Robinson.\n",
      "Peter Rofes\n",
      "Name list: ['Peter K.']\n",
      "Looking for Peter K. Rofes\n",
      "Scraping the page\n",
      "Done scraping for Peter K. Rofes.\n",
      "Audrey Rogers\n",
      "Name list: ['Audrey']\n",
      "Looking for Audrey Rogers\n",
      "Scraping the page\n",
      "Done scraping for Audrey Rogers.\n",
      "Joel Rogers\n",
      "Name list: ['Joel']\n",
      "Looking for Joel Rogers\n",
      "Scraping the page\n",
      "Done scraping for Joel Rogers.\n",
      "Clifford Rosky\n",
      "Name list: ['Clifford J.', 'Clifford']\n",
      "Looking for Clifford J. Rosky\n",
      "Scraping the page\n",
      "Done scraping for Clifford J. Rosky.\n",
      "Looking for Clifford Rosky\n",
      "A file for Clifford Rosky already exists. Moving to the next name.\n",
      "Andrea Roth\n",
      "Name list: ['Andrea', 'Andrea L.']\n",
      "Looking for Andrea Roth\n",
      "Scraping the page\n",
      "Done scraping for Andrea Roth.\n",
      "Looking for Andrea L. Roth\n",
      "A file for Andrea L. Roth already exists. Moving to the next name.\n",
      "Laura Rothstein\n",
      "Name list: ['Laura']\n",
      "Looking for Laura Rothstein\n",
      "Scraping the page\n",
      "Done scraping for Laura Rothstein.\n",
      "George Rutherglen\n",
      "Name list: ['George']\n",
      "Looking for George Rutherglen\n",
      "Scraping the page\n",
      "Done scraping for George Rutherglen.\n",
      "Ronald Rychlak\n",
      "Name list: ['Ronald J.']\n",
      "Looking for Ronald J. Rychlak\n",
      "Scraping the page\n",
      "Done scraping for Ronald J. Rychlak.\n",
      "William Sage\n",
      "Name list: ['William M.']\n",
      "Looking for William M. Sage\n",
      "Scraping the page\n",
      "Done scraping for William M. Sage.\n",
      "Richard Saver\n",
      "Name list: ['Richard S.']\n",
      "Looking for Richard S. Saver\n",
      "Scraping the page\n",
      "Done scraping for Richard S. Saver.\n",
      "Susan Schmeiser\n",
      "Name list: ['Susan R.']\n",
      "Looking for Susan R. Schmeiser\n",
      "Scraping the page\n",
      "Done scraping for Susan R. Schmeiser.\n",
      "Ronna Schneider\n",
      "Name list: ['Ronna Greff']\n",
      "Looking for Ronna Greff Schneider\n",
      "Scraping the page\n",
      "Done scraping for Ronna Greff Schneider.\n",
      "Maimon Schwarzchild\n",
      "Name list: ['Maimon']\n",
      "Looking for Maimon Schwarzchild\n",
      "Scraping the page\n",
      "Done scraping for Maimon Schwarzchild.\n",
      "Maimon Schwarzschild\n",
      "Name list: ['Maimon']\n",
      "Looking for Maimon Schwarzschild\n",
      "Scraping the page\n",
      "Done scraping for Maimon Schwarzschild.\n",
      "Elizabeth Scott\n",
      "Name list: ['Elizabeth S', 'Elizabeth S.']\n",
      "Looking for Elizabeth S Scott\n",
      "No data was found for Elizabeth S Scott. Moving to the next name.\n",
      "Looking for Elizabeth S. Scott\n",
      "Scraping the page\n",
      "Done scraping for Elizabeth S. Scott.\n",
      "Helen Scott\n",
      "Name list: ['Helen']\n",
      "Looking for Helen Scott\n",
      "Scraping the page\n",
      "Done scraping for Helen Scott.\n",
      "Robert Scott\n",
      "Name list: ['Robert E.']\n",
      "Looking for Robert E. Scott\n",
      "Scraping the page\n",
      "Done scraping for Robert E. Scott.\n",
      "Benjamin  Priester\n",
      "Name list: ['Benjamin J.']\n",
      "Looking for Benjamin J. Priester\n",
      "Scraping the page\n",
      "Done scraping for Benjamin J. Priester.\n",
      "Mitra Sharafi\n",
      "Name list: ['Mitra']\n",
      "Looking for Mitra Sharafi\n",
      "Scraping the page\n",
      "Done scraping for Mitra Sharafi.\n",
      "Joan Shaughnessy\n",
      "Name list: ['Joan M.']\n",
      "Looking for Joan M. Shaughnessy\n",
      "Scraping the page\n",
      "Done scraping for Joan M. Shaughnessy.\n",
      "Joanna Bailey\n",
      "Name list: ['Joanna', 'Joanna M.', 'Joanna Shepherd']\n",
      "Looking for Joanna Bailey\n",
      "No data was found for Joanna Bailey. Moving to the next name.\n",
      "Looking for Joanna M. Bailey\n",
      "No data was found for Joanna M. Bailey. Moving to the next name.\n",
      "Looking for Joanna Shepherd Bailey\n",
      "Scraping the page\n",
      "Done scraping for Joanna Shepherd Bailey.\n",
      "Joanna Shepherd\n",
      "Name list: ['Joanna', 'Joanna Shepherd', 'Joanna M.']\n",
      "Looking for Joanna Shepherd\n",
      "Scraping the page\n",
      "Done scraping for Joanna Shepherd.\n",
      "Looking for Joanna Shepherd Shepherd\n",
      "No data was found for Joanna Shepherd Shepherd. Moving to the next name.\n",
      "Looking for Joanna M. Shepherd\n",
      "Scraping the page\n",
      "Done scraping for Joanna M. Shepherd.\n",
      "Nadav Shoked\n",
      "Name list: ['Nadav']\n",
      "Looking for Nadav Shoked\n",
      "Scraping the page\n",
      "Done scraping for Nadav Shoked.\n",
      "Mark Sidel\n",
      "Name list: ['Mark']\n",
      "Looking for Mark Sidel\n",
      "Scraping the page\n",
      "Done scraping for Mark Sidel.\n",
      "Peter Siegelman\n",
      "Name list: ['Peter']\n",
      "Looking for Peter Siegelman\n",
      "Scraping the page\n",
      "Done scraping for Peter Siegelman.\n",
      "Daniel Simmons\n",
      "Name list: ['Daniel L.']\n",
      "Looking for Daniel L. Simmons\n",
      "Scraping the page\n",
      "Done scraping for Daniel L. Simmons.\n",
      "Robert Sitkoff\n",
      "Name list: ['Robert', 'Robert H.']\n",
      "Looking for Robert Sitkoff\n",
      "Scraping the page\n",
      "Done scraping for Robert Sitkoff.\n",
      "Looking for Robert H. Sitkoff\n",
      "A file for Robert H. Sitkoff already exists. Moving to the next name.\n",
      "David Skover\n",
      "Name list: ['David M.', 'David']\n",
      "Looking for David M. Skover\n",
      "Scraping the page\n",
      "Done scraping for David M. Skover.\n",
      "Looking for David Skover\n",
      "A file for David Skover already exists. Moving to the next name.\n",
      "Lawrence Solum\n",
      "Name list: ['Lawrence Byard']\n",
      "Looking for Lawrence Byard Solum\n",
      "Scraping the page\n",
      "Done scraping for Lawrence Byard Solum.\n",
      "Sarah Song\n",
      "Name list: ['Sarah']\n",
      "Looking for Sarah Song\n",
      "Scraping the page\n",
      "Done scraping for Sarah Song.\n",
      "Nancy Soonpaa\n",
      "Name list: ['Nancy', 'Nancy J.']\n",
      "Looking for Nancy Soonpaa\n",
      "Scraping the page\n",
      "Done scraping for Nancy Soonpaa.\n",
      "Looking for Nancy J. Soonpaa\n",
      "A file for Nancy J. Soonpaa already exists. Moving to the next name.\n",
      "Ann Southworth\n",
      "Name list: ['Ann']\n",
      "Looking for Ann Southworth\n",
      "Scraping the page\n",
      "Done scraping for Ann Southworth.\n",
      "Mark Spiegel\n",
      "Name list: ['Mark']\n",
      "Looking for Mark Spiegel\n",
      "Scraping the page\n",
      "Done scraping for Mark Spiegel.\n",
      "John Sprankling\n",
      "Name list: ['John G.']\n",
      "Looking for John G. Sprankling\n",
      "Scraping the page\n",
      "Done scraping for John G. Sprankling.\n",
      "Richard Squire\n",
      "Name list: ['Richard']\n",
      "Looking for Richard Squire\n",
      "Scraping the page\n",
      "Done scraping for Richard Squire.\n",
      "Barbara Stark\n",
      "Name list: ['Barbara']\n",
      "Looking for Barbara Stark\n",
      "Scraping the page\n",
      "Done scraping for Barbara Stark.\n",
      "Craig Stern\n",
      "Name list: ['Craig', 'Craig A.']\n",
      "Looking for Craig Stern\n",
      "Scraping the page\n",
      "Done scraping for Craig Stern.\n",
      "Looking for Craig A. Stern\n",
      "A file for Craig A. Stern already exists. Moving to the next name.\n",
      "Robert Strassfeld\n",
      "Name list: ['Robert N.', 'Robert']\n",
      "Looking for Robert N. Strassfeld\n",
      "Scraping the page\n",
      "Done scraping for Robert N. Strassfeld.\n",
      "Looking for Robert Strassfeld\n",
      "A file for Robert Strassfeld already exists. Moving to the next name.\n",
      "Charles Sullivan\n",
      "Name list: ['Charles A.', 'Charles']\n",
      "Looking for Charles A. Sullivan\n",
      "Scraping the page\n",
      "Done scraping for Charles A. Sullivan.\n",
      "Looking for Charles Sullivan\n",
      "A file for Charles Sullivan already exists. Moving to the next name.\n",
      "William Tabb\n",
      "Name list: ['William M.', 'William Murray']\n",
      "Looking for William M. Tabb\n",
      "Scraping the page\n",
      "Done scraping for William M. Tabb.\n",
      "Looking for William Murray Tabb\n",
      "A file for William Murray Tabb already exists. Moving to the next name.\n",
      "Shauhin Talesh\n",
      "Name list: ['Shauhin A.', 'Shauhin']\n",
      "Looking for Shauhin A. Talesh\n",
      "Scraping the page\n",
      "Done scraping for Shauhin A. Talesh.\n",
      "Looking for Shauhin Talesh\n",
      "A file for Shauhin Talesh already exists. Moving to the next name.\n",
      "David Thronson\n",
      "Name list: ['David B.', 'David']\n",
      "Looking for David B. Thronson\n",
      "Scraping the page\n",
      "Done scraping for David B. Thronson.\n",
      "Looking for David Thronson\n",
      "A file for David Thronson already exists. Moving to the next name.\n",
      "Emerson Tiller\n",
      "Name list: ['Emerson H.', 'Emerson']\n",
      "Looking for Emerson H. Tiller\n",
      "Scraping the page\n",
      "Done scraping for Emerson H. Tiller.\n",
      "Looking for Emerson Tiller\n",
      "A file for Emerson Tiller already exists. Moving to the next name.\n",
      "Lisa Tripp\n",
      "Name list: ['Lisa']\n",
      "Looking for Lisa Tripp\n",
      "Scraping the page\n",
      "Done scraping for Lisa Tripp.\n",
      "Kevin Tu\n",
      "Name list: ['Kevin V.']\n",
      "Looking for Kevin V. Tu\n",
      "Scraping the page\n",
      "Done scraping for Kevin V. Tu.\n",
      "Christian Turner\n",
      "Name list: ['Christian']\n",
      "Looking for Christian Turner\n",
      "Scraping the page\n",
      "Done scraping for Christian Turner.\n",
      "Aaron Twerski\n",
      "Name list: ['Aaron D.']\n",
      "Looking for Aaron D. Twerski\n",
      "Scraping the page\n",
      "Done scraping for Aaron D. Twerski.\n",
      "Manuel Utset\n",
      "Name list: ['Manuel A.']\n",
      "Looking for Manuel A. Utset\n",
      "Scraping the page\n",
      "Done scraping for Manuel A. Utset.\n",
      "Stephen Utz\n",
      "Name list: ['Stephen', 'Stephen G.']\n",
      "Looking for Stephen Utz\n",
      "Scraping the page\n",
      "Done scraping for Stephen Utz.\n",
      "Looking for Stephen G. Utz\n",
      "A file for Stephen G. Utz already exists. Moving to the next name.\n",
      "Rachel VanLandingham\n",
      "Name list: ['Rachel E.', 'Rachel']\n",
      "Looking for Rachel E. VanLandingham\n",
      "Scraping the page\n",
      "Done scraping for Rachel E. VanLandingham.\n",
      "Looking for Rachel VanLandingham\n",
      "A file for Rachel VanLandingham already exists. Moving to the next name.\n",
      "David Walker\n",
      "Name list: ['David I.']\n",
      "Looking for David I. Walker\n",
      "Scraping the page\n",
      "Done scraping for David I. Walker.\n",
      "Cynthia Ward\n",
      "Name list: ['Cynthia V.', 'Cynthia']\n",
      "Looking for Cynthia V. Ward\n",
      "Scraping the page\n",
      "Done scraping for Cynthia V. Ward.\n",
      "Looking for Cynthia Ward\n",
      "A file for Cynthia Ward already exists. Moving to the next name.\n",
      "Kathryn Tongue\n",
      "Name list: ['', 'Kathryn Tongue', 'Kathryn A', 'Kathryn A.', 'Kathryn']\n",
      "Looking for  Tongue\n",
      "No data was found for  Tongue. Moving to the next name.\n",
      "Looking for Kathryn Tongue Tongue\n",
      "No data was found for Kathryn Tongue Tongue. Moving to the next name.\n",
      "Looking for Kathryn A Tongue\n",
      "No data was found for Kathryn A Tongue. Moving to the next name.\n",
      "Looking for Kathryn A. Tongue\n",
      "Scraping the page\n",
      "Done scraping for Kathryn A. Tongue.\n",
      "Looking for Kathryn Tongue\n",
      "Scraping the page\n",
      "Done scraping for Kathryn Tongue.\n",
      "Kathryn Watts\n",
      "Name list: ['Kathryn A.', 'Kathryn Tongue', 'Kathryn']\n",
      "Looking for Kathryn A. Watts\n",
      "Scraping the page\n",
      "Done scraping for Kathryn A. Watts.\n",
      "Looking for Kathryn Tongue Watts\n",
      "Scraping the page\n",
      "Done scraping for Kathryn Tongue Watts.\n",
      "Looking for Kathryn Watts\n",
      "Scraping the page\n",
      "Done scraping for Kathryn Watts.\n",
      "Louise Weinberg\n",
      "Name list: ['Louise']\n",
      "Looking for Louise Weinberg\n",
      "Scraping the page\n",
      "Done scraping for Louise Weinberg.\n",
      "Richard Weisberg\n",
      "Name list: ['Richard']\n",
      "Looking for Richard Weisberg\n",
      "Scraping the page\n",
      "Done scraping for Richard Weisberg.\n",
      "Deborah Weissman\n",
      "Name list: ['Deborah', 'Deborah M.']\n",
      "Looking for Deborah Weissman\n",
      "Scraping the page\n",
      "Done scraping for Deborah Weissman.\n",
      "Looking for Deborah M. Weissman\n",
      "A file for Deborah M. Weissman already exists. Moving to the next name.\n",
      "Bret Wells\n",
      "Name list: ['Bret']\n",
      "Looking for Bret Wells\n",
      "Scraping the page\n",
      "Done scraping for Bret Wells.\n",
      "Keith Werhan\n",
      "Name list: ['Keith M.', 'Keith']\n",
      "Looking for Keith M. Werhan\n",
      "Scraping the page\n",
      "Done scraping for Keith M. Werhan.\n",
      "Looking for Keith Werhan\n",
      "A file for Keith Werhan already exists. Moving to the next name.\n",
      "Ahmed White\n",
      "Name list: ['Ahmed A.', 'Ahmed']\n",
      "Looking for Ahmed A. White\n",
      "Scraping the page\n",
      "Done scraping for Ahmed A. White.\n",
      "Looking for Ahmed White\n",
      "A file for Ahmed White already exists. Moving to the next name.\n",
      "Michaela White\n",
      "Name list: ['Michaela', 'Michaela M.']\n",
      "Looking for Michaela White\n",
      "Scraping the page\n",
      "Done scraping for Michaela White.\n",
      "Looking for Michaela M. White\n",
      "A file for Michaela M. White already exists. Moving to the next name.\n",
      "Kelli Alces\n",
      "Name list: ['Kelli A.', 'Kelli Alces']\n",
      "Looking for Kelli A. Alces\n",
      "Scraping the page\n",
      "Done scraping for Kelli A. Alces.\n",
      "Looking for Kelli Alces Alces\n",
      "No data was found for Kelli Alces Alces. Moving to the next name.\n",
      "Kelli Alces\n",
      "Name list: ['Kelli A.']\n",
      "Looking for Kelli A. Alces\n",
      "Scraping the page\n",
      "Done scraping for Kelli A. Alces.\n",
      "Kelli Williams\n",
      "Name list: ['Kelli A.', 'Kelli Alces']\n",
      "Looking for Kelli A. Williams\n",
      "No data was found for Kelli A. Williams. Moving to the next name.\n",
      "Looking for Kelli Alces Williams\n",
      "Scraping the page\n",
      "Done scraping for Kelli Alces Williams.\n",
      "Kelli Williams\n",
      "Name list: ['Kelli Alces']\n",
      "Looking for Kelli Alces Williams\n",
      "Scraping the page\n",
      "Done scraping for Kelli Alces Williams.\n",
      "Sean Williams\n",
      "Name list: ['Sean Hannon']\n",
      "Looking for Sean Hannon Williams\n",
      "Scraping the page\n",
      "Done scraping for Sean Hannon Williams.\n",
      "Arthur Wilmarth\n",
      "Name list: ['Arthur E. Jr.']\n",
      "Looking for Arthur E. Jr. Wilmarth\n",
      "Scraping the page\n",
      "Done scraping for Arthur E. Jr. Wilmarth.\n",
      "Patricia Wilson\n",
      "Name list: ['Patricia', 'Patricia A.']\n",
      "Looking for Patricia Wilson\n",
      "Scraping the page\n",
      "Done scraping for Patricia Wilson.\n",
      "Looking for Patricia A. Wilson\n",
      "Scraping the page\n",
      "Done scraping for Patricia A. Wilson.\n",
      "Jarrod Wong\n",
      "Name list: ['Jarrod']\n",
      "Looking for Jarrod Wong\n",
      "Scraping the page\n",
      "Done scraping for Jarrod Wong.\n",
      "Mo Zhang\n",
      "Name list: ['Mo']\n",
      "Looking for Mo Zhang\n",
      "Scraping the page\n",
      "Done scraping for Mo Zhang.\n",
      "Donald Zillman\n",
      "Name list: ['Donald', 'Donald N.']\n",
      "Looking for Donald Zillman\n",
      "Scraping the page\n",
      "Done scraping for Donald Zillman.\n",
      "Looking for Donald N. Zillman\n",
      "A file for Donald N. Zillman already exists. Moving to the next name.\n",
      "Adam Zimmerman\n",
      "Name list: ['Adam S.']\n",
      "Looking for Adam S. Zimmerman\n",
      "Scraping the page\n",
      "Done scraping for Adam S. Zimmerman.\n",
      "Julian Velasco\n",
      "Name list: ['Julian']\n",
      "Looking for Julian Velasco\n",
      "Scraping the page\n",
      "Done scraping for Julian Velasco.\n"
     ]
    }
   ],
   "source": [
    "# Initilization\n",
    "# Page name is a list of the name for all of the pages that we have scraped.\n",
    "# This is the name that actually appears on the webpage. This helps prevent\n",
    "# us from having to rescrape pages multiple times.\n",
    "err_fm_names = []\n",
    "skip_df = pd.DataFrame()\n",
    "\n",
    "#This loop goes through each name\n",
    "for i in range(len(data)):\n",
    "    # Export the updated dataframe of skipped names and scraped pages\n",
    "    skip_df.to_excel(out_path / \"_skip_output.xlsx\", index = False)\n",
    "    df_scraped_pages.to_excel(scraped_pages_file, index = False)\n",
    "    #This section gets the professor's information from the dataframe \n",
    "    # Get variable values from the dataframe\n",
    "    prof_id = data['ID'][i]\n",
    "    mid_first_name = data['FirstName'][i]\n",
    "    last_name = data['LastName'][i]\n",
    "    full_name = mid_first_name + ' ' +  last_name\n",
    "    # Create the multiple observation variable\n",
    "    multi_obs = data[\"multi_obs\"][i]\n",
    "    # Create the index variable for the name. This is used to distinguish \n",
    "    # the file names if we have mutliple last names.\n",
    "    last_name_index = data[\"ID_counts\"][i]\n",
    "    # Get the alt url value\n",
    "    alt_url = data[\"alt_url\"][i]\n",
    "\n",
    "    # Print the name that we are considering\n",
    "    print(full_name)\n",
    "\n",
    "    # If there were no matching names, the value is nan. This means that the value does not equal itself.\n",
    "    #  The name is added to the skipped names list and the loop moves onto the next name. \n",
    "    fm_names_str = data['fm_names'][i]\n",
    "    if fm_names_str != fm_names_str:\n",
    "        print('Name ' + full_name + ' was not found. Adding to the skipped names dataset.')\n",
    "        skip_df = pd.concat([skip_df, data.iloc[[i]]])\n",
    "        continue\n",
    "\n",
    "    fm_names = fm_names_str.split(\", \")\n",
    "    print(\"Name list: {}\".format(fm_names))   \n",
    "        \n",
    "    #This section loops through the list of alternative names and goes directly to their pages on Hein\n",
    "    for first_name_index, fm_name in enumerate(fm_names):\n",
    "        # Create the full name\n",
    "        full_name = fm_name + ' ' +  last_name      \n",
    "\n",
    "        #Link to Hein page\n",
    "        if alt_url == 0:\n",
    "            links = ['https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=' + last_name +  '%2C ' + fm_name + '&collection=journals']\n",
    "        elif alt_url == 1:\n",
    "            links = ['https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=' + last_name +  '%2C ' + fm_name + '&collection=journals', 'https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=' + last_name +  '%20 ' + fm_name + '&collection=journals']  \n",
    "\n",
    "        for link_index, link in enumerate(links):\n",
    "\n",
    "            print(\"Looking for {}\".format(full_name))\n",
    "            if alt_url == 1:\n",
    "                # Check if the file exists\n",
    "                file_name = '{}_{}_{}_{}_{}_papers.xlsx'.format(full_name, prof_id, first_name_index, last_name_index, link_index)  \n",
    "            elif alt_url == 0:\n",
    "                # Check if the file exists\n",
    "                file_name = '{}_{}_{}_papers.xlsx'.format(full_name, prof_id, last_name_index)  \n",
    "\n",
    "            # CHECK DATA: This is the first spot where we check the data. We want to see if the link that we are\n",
    "            # going to scrape has already been added to the list of scraped pages. This is helpful when \n",
    "            # rerunning the code.\n",
    "            if not df_scraped_pages.query('@link == links').empty and not multi_obs:\n",
    "                print(\"The link {} has already been scraped. Moving to the next name.\".format(link))\n",
    "                continue\n",
    "            #Direct the webdriver to the page\n",
    "            driver.get(link)\n",
    "            #This function waits for the webpage to load\n",
    "            webpage_wait('//*[@id=\"page_content\"]/div[1]/div/div[1]/div[1]', driver)\n",
    "            \n",
    "            # Make sure that the data exists on the page. Otherwise, we will skip the page.\n",
    "            try:\n",
    "                no_data_text = driver.find_element_by_xpath('//*[@id=\"luceneres\"]/b').text\n",
    "                if no_data_text == \"No matching results found\":\n",
    "                    data_exists = False\n",
    "            except NoSuchElementException:\n",
    "                data_exists = True\n",
    "\n",
    "            # This is the name for the professor that is used on the page.\n",
    "            cur_page = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[1]/div[1]').text\n",
    "\n",
    "            # CHECK DATA: This is the second spot where we check the data to see if the page has\n",
    "            # already been scraped. In order to check to see if the link has already been scraped, \n",
    "            # we look for the professor name on the page (which may be different from the name in our list) \n",
    "            # and the professor ID. This is helpful when two names point to the same page.\n",
    "            if not df_scraped_pages.query('@cur_page == professor_names and @prof_id == id').empty and not multi_obs: \n",
    "                print(\"A file for {} already exists. Moving to the next name.\".format(full_name))\n",
    "                # Add the link to the data so that we know to skip it in future runs\n",
    "                values_scraped_pages = [link, file_name, cur_page, prof_id]\n",
    "                dict_values_scraped_pages = dict(zip(scraped_pages_columns, values_scraped_pages))\n",
    "                df_scraped_pages = df_scraped_pages.append([dict_values_scraped_pages])\n",
    "                continue\n",
    "            #If there is a table on the page and the page name has not already appeared in the scraped list.\n",
    "            if data_exists: \n",
    "                element = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[2]')\n",
    "                table_element = element.text.split('\\n')\n",
    "                #If the table is empty, there is no data to scrape\n",
    "                if len(table_element) < 5:\n",
    "                    print('No data available on Hein for {} {}'.format(fm_name, last_name))\n",
    "                    continue\n",
    "                #If the table is full, this section rearranges the data into a better format\n",
    "                print(\"Scraping the page\")                \n",
    "                #This section scrapes the paper data. The index values are based on the way the xpaths are incremented\n",
    "                #The scroll number tracks the number of times the page has scrolled. This is for pages with a large number of \n",
    "                #papers. The xpaths change when the page scrolls.\n",
    "                title_index = 3\n",
    "                stats_index = 4\n",
    "                topic_index = 0\n",
    "                scroll_num = 0\n",
    "                #This gets the page source\n",
    "                soup=bs.BeautifulSoup(driver.page_source, 'lxml')\n",
    "                #This section gets the paper topics\n",
    "                topic_array = soup.findAll('div', {'class': 'topics'})\n",
    "                element = title_index\n",
    "                df = pd.DataFrame(columns = ['Title', 'Author(s)', 'ID', 'Journal', 'BBCite', 'Topics', 'Subjects', 'Type', 'Cited (articles)', 'Cited (cases)', 'Accessed'])\n",
    "                #This while loop will continue until there are no more papers on the page\n",
    "                while element:\n",
    "                    #Data stream is a list of the data in the paper data box (for example, authors, topics, journal)\n",
    "                    data_stream = []\n",
    "                    #This funciton returns a dictionary with various fields for each variable in the data box\n",
    "                    #Sometimes some of the variables are missing (for example, there are papers without a journal listed)\n",
    "                    #In this case, the dictionary returns an empty value for these variables\n",
    "                    data_dict = get_paper_data(last_name, prof_id, title_index, scroll_num, driver)\n",
    "                    #This section gets the paper stats box. This is the box that says how many citations the paper\n",
    "                    #has received\n",
    "                    if scroll_num == 0:\n",
    "                        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(stats_index) + ']/div[2]/div')\n",
    "                    elif scroll_num > 0:\n",
    "                        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div[' + str(stats_index) + ']/div[2]/div')\n",
    "                    #This section extracts the data from the paper stats box\n",
    "                    for elm in element:\n",
    "                        cited_text = elm.text\n",
    "                    article_citations = 'na'\n",
    "                    case_citations = 'na'\n",
    "                    accessed = 'na'\n",
    "                    if not isinstance(cited_text, list):\n",
    "                        cited_text = cited_text.split('\\n')\n",
    "                        #This section finds the value for each paper stat\n",
    "                        for stat in cited_text:\n",
    "                            if 'Article' in stat:\n",
    "                                article_citations = int(re.search(r'\\d+', stat).group())\n",
    "                            if 'Case' in stat:\n",
    "                                case_citations = int(re.search(r'\\d+', stat).group())\n",
    "                            if 'Accessed' in stat:\n",
    "                                accessed = int(re.search(r'\\d+', stat).group())\n",
    "                    #The values are appended to the data_stream list\n",
    "                    data_stream.append(article_citations)\n",
    "                    data_stream.append(case_citations)\n",
    "                    data_stream.append(accessed)\n",
    "                    #This line adds the output from the function get_paper_data to the data_stream list\n",
    "                    data_stream = list(data_dict.values()) + data_stream\n",
    "                    #The data_stream list is used to add a line of data to the overall paper dataframe for this author\n",
    "                    df = df.append(pd.DataFrame([data_stream], columns = ['Title', 'Author(s)', 'ID', 'Journal', 'BBCite', 'Topics', 'Subjects', 'Type', 'Cited (articles)', 'Cited (cases)', 'Accessed']), sort=False)\n",
    "                    #The indices are augmented to get the next paper\n",
    "                    stats_index +=4\n",
    "                    title_index += 4\n",
    "                    #Check that next paper exists:\n",
    "                    if scroll_num == 0:\n",
    "                        x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                    #If the page has scrolled, the xpath we need to check has changed\n",
    "                    if scroll_num > 0:\n",
    "                        x_path_title = '//*[@id=\"save_results\"]/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                    element = driver.find_elements_by_xpath(x_path_title)\n",
    "                    #If we can't find a next paper, it could be because we need to scroll again\n",
    "                    #This section attempts to scroll the page. \n",
    "                    if not element:\n",
    "                        scroll_num +=1\n",
    "                        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                        box_element = driver.find_elements_by_xpath('//*[@id=\"results_total\"]')\n",
    "                        num_papers = int(box_element[0].text.split(' ')[0])\n",
    "                        #If there are more than 100 papers, we know there are still paper left to scrape\n",
    "                        if num_papers > 100*scroll_num:\n",
    "                            time.sleep(15)\n",
    "                            title_index = 3\n",
    "                            stats_index = 4\n",
    "                            topic_index = 0\n",
    "                            x_path_title = '//*[@id=\"save_results\"]/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                            element = driver.find_elements_by_xpath(x_path_title)\n",
    "                #This line saves the Excel file of papers\n",
    "                df.to_excel(out_path / file_name, index=False)\n",
    "                # We have created a file, so we need to append the link and the file name to the list of scraped pages\n",
    "                values_scraped_pages = [link, file_name, cur_page, prof_id]\n",
    "                dict_values_scraped_pages = dict(zip(scraped_pages_columns, values_scraped_pages))\n",
    "                df_scraped_pages = df_scraped_pages.append([dict_values_scraped_pages])\n",
    "                time.sleep(3)\n",
    "                #If we reach this point, all the pages for that author have been scraped\n",
    "                print('Done scraping for {}.'.format(fm_name + ' ' + last_name))\n",
    "            else:\n",
    "                print(\"No data was found for {}. Moving to the next name.\".format(full_name))\n",
    "# Export the updated dataframe of skipped names and scraped pages\n",
    "skip_df.to_excel(out_path / \"_skip_output.xlsx\", index = False)\n",
    "df_scraped_pages.to_excel(scraped_pages_file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}