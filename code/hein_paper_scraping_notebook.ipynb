{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "web_scraping",
   "display_name": "web_scraping",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import nltk\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import pathlib \n",
    "\n",
    "from modules.create_path import create_path\n",
    "from modules.hein_scraping_functions import create_browser, webpage_wait, get_paper_data, mod_names, check_google, similar_names, search_names\n",
    "from modules.data_manipulation_functions import remove_commas, check_files, concat_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the paths for the data directories\n",
    "input_path, work_path, intr_path, out_path, selenium_driver_path = create_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the paths for the Chrome binary and selenium driver\n",
    "chrome_binary_path = pathlib.Path(\"C:\\\\Program Files (x86)\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\")\n",
    "selenium_driver_full_path = selenium_driver_path / \"chromedriver.exe\"\n",
    "\n",
    "# Initalize the browsers that we are going to use\n",
    "driver = create_browser(chrome_binary_path, selenium_driver_full_path)\n",
    "\n",
    "driver.get(\"http://proxy.its.virginia.edu/login?url=http://heinonline.org/HOL/Welcome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data already exists. Names that have already been scraped will be skipped\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets from the working directory\n",
    "# The datasets in the working directory have already \n",
    "# been cleaned.\n",
    "input_data = pd.read_excel(intr_path / \"hein_scraping_input_data.xlsx\")\n",
    "data = input_data\n",
    "data_type = \"lateral\"\n",
    "\n",
    "# Create the list of scraped pages columns\n",
    "scraped_pages_columns = [\"links\", \"file_names\", \"professor_names\", \"id\"]\n",
    "# Load the list of scraped pages if it exists\n",
    "scraped_pages_file = out_path / \"_scraped_pages.xlsx\"\n",
    "if scraped_pages_file.exists():\n",
    "    print(\"Data already exists. Names that have already been scraped will be skipped\")\n",
    "    # Create the dataset of existing alt names.\n",
    "    df_scraped_pages = pd.read_excel(scraped_pages_file)\n",
    "else:\n",
    "    df_scraped_pages = pd.DataFrame(columns = scraped_pages_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                links  \\\n",
       "0   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "1   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "2   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "3   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "4   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "5   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "6   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "7   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "8   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "9   https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "10  https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "11  https://heinonline-org.proxy01.its.virginia.ed...   \n",
       "\n",
       "                             file_names      professor_names  id  \n",
       "0           Matthew Adler_1_papers.xlsx    Adler, Matthew D.   1  \n",
       "1        Matthew D. Adler_1_papers.xlsx    Adler, Matthew D.   1  \n",
       "2        W. Edward Afield_2_papers.xlsx    Afield, W. Edward   2  \n",
       "3          Richard Albert_3_papers.xlsx      Albert, Richard   3  \n",
       "4       Lisa T. Alexander_4_papers.xlsx   Alexander, Lisa T.   4  \n",
       "5         Hilary J. Allen_5_papers.xlsx     Allen, Hilary J.   5  \n",
       "6        Owen L. Anderson_6_papers.xlsx    Anderson, Owen L.   6  \n",
       "7   Olufunmilayo B. Arewa_7_papers.xlsx  Arewa, Olufunmilayo   7  \n",
       "8          Kenneth Ayotte_8_papers.xlsx   Ayotte, Kenneth M.   8  \n",
       "9       Kenneth M. Ayotte_8_papers.xlsx   Ayotte, Kenneth M.   8  \n",
       "10             Sahar Aziz_9_papers.xlsx          Aziz, Sahar   9  \n",
       "11          Sahar F. Aziz_9_papers.xlsx          Aziz, Sahar   9  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>links</th>\n      <th>file_names</th>\n      <th>professor_names</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Matthew Adler_1_papers.xlsx</td>\n      <td>Adler, Matthew D.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Matthew D. Adler_1_papers.xlsx</td>\n      <td>Adler, Matthew D.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>W. Edward Afield_2_papers.xlsx</td>\n      <td>Afield, W. Edward</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Richard Albert_3_papers.xlsx</td>\n      <td>Albert, Richard</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Lisa T. Alexander_4_papers.xlsx</td>\n      <td>Alexander, Lisa T.</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Hilary J. Allen_5_papers.xlsx</td>\n      <td>Allen, Hilary J.</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Owen L. Anderson_6_papers.xlsx</td>\n      <td>Anderson, Owen L.</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Olufunmilayo B. Arewa_7_papers.xlsx</td>\n      <td>Arewa, Olufunmilayo</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Kenneth Ayotte_8_papers.xlsx</td>\n      <td>Ayotte, Kenneth M.</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Kenneth M. Ayotte_8_papers.xlsx</td>\n      <td>Ayotte, Kenneth M.</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Sahar Aziz_9_papers.xlsx</td>\n      <td>Aziz, Sahar</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>https://heinonline-org.proxy01.its.virginia.ed...</td>\n      <td>Sahar F. Aziz_9_papers.xlsx</td>\n      <td>Aziz, Sahar</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "df_scraped_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ame.\n",
      "Ruth Mason\n",
      "Name list: ['Ruth']\n",
      "Looking for Ruth Mason\n",
      "Scraping the page\n",
      "Done scraping for Ruth Mason.\n",
      "Dayna Matthew\n",
      "Name list: ['Dayna Bowen', 'Dayna B.']\n",
      "Looking for Dayna Bowen Matthew\n",
      "Scraping the page\n",
      "Done scraping for Dayna Bowen Matthew.\n",
      "Looking for Dayna B. Matthew\n",
      "A file for Dayna B. Matthew already exists. Moving to the next name.\n",
      "Jason Mazzone\n",
      "Name list: ['Jason']\n",
      "Looking for Jason Mazzone\n",
      "Scraping the page\n",
      "Done scraping for Jason Mazzone.\n",
      "Grayson McCouch\n",
      "Name list: ['Grayson', 'Grayson M.P.', 'Grayson M. P.', 'Grayson M-P']\n",
      "Looking for Grayson McCouch\n",
      "Scraping the page\n",
      "Done scraping for Grayson McCouch.\n",
      "Looking for Grayson M.P. McCouch\n",
      "A file for Grayson M.P. McCouch already exists. Moving to the next name.\n",
      "Looking for Grayson M. P. McCouch\n",
      "A file for Grayson M. P. McCouch already exists. Moving to the next name.\n",
      "Looking for Grayson M-P McCouch\n",
      "A file for Grayson M-P McCouch already exists. Moving to the next name.\n",
      "Patricia McCoy\n",
      "Name list: ['Patricia A.']\n",
      "Looking for Patricia A. McCoy\n",
      "Scraping the page\n",
      "Done scraping for Patricia A. McCoy.\n",
      "Justin McCrary\n",
      "Name list: ['Justin']\n",
      "Looking for Justin McCrary\n",
      "Scraping the page\n",
      "Done scraping for Justin McCrary.\n",
      "Mathew McCubbins\n",
      "Name list: ['Mathew D.']\n",
      "Looking for Mathew D. McCubbins\n",
      "Scraping the page\n",
      "Done scraping for Mathew D. McCubbins.\n",
      "Ajay Mehrotra\n",
      "Name list: ['Ajay K.']\n",
      "Looking for Ajay K. Mehrotra\n",
      "Scraping the page\n",
      "Done scraping for Ajay K. Mehrotra.\n",
      "Pamela Metzger\n",
      "Name list: ['Pamela R.', 'Pamela']\n",
      "Looking for Pamela R. Metzger\n",
      "Scraping the page\n",
      "Done scraping for Pamela R. Metzger.\n",
      "Looking for Pamela Metzger\n",
      "A file for Pamela Metzger already exists. Moving to the next name.\n",
      "Tim Meyer\n",
      "Name list: ['Timothy', 'Timothy L.']\n",
      "Looking for Timothy Meyer\n",
      "Scraping the page\n",
      "Done scraping for Timothy Meyer.\n",
      "Looking for Timothy L. Meyer\n",
      "Scraping the page\n",
      "Done scraping for Timothy L. Meyer.\n",
      "Bernadette Meyler\n",
      "Name list: ['Bernadette']\n",
      "Looking for Bernadette Meyler\n",
      "Scraping the page\n",
      "Done scraping for Bernadette Meyler.\n",
      "Curtis Milhaupt\n",
      "Name list: ['Curtis J.']\n",
      "Looking for Curtis J. Milhaupt\n",
      "Scraping the page\n",
      "Done scraping for Curtis J. Milhaupt.\n",
      "Darrell Miller\n",
      "Name list: ['Darrell A. H.', 'Darrell A.H.']\n",
      "Looking for Darrell A. H. Miller\n",
      "Scraping the page\n",
      "Done scraping for Darrell A. H. Miller.\n",
      "Looking for Darrell A.H. Miller\n",
      "A file for Darrell A.H. Miller already exists. Moving to the next name.\n",
      "Paul Miller\n",
      "Name list: ['Paul B.']\n",
      "Looking for Paul B. Miller\n",
      "Scraping the page\n",
      "Done scraping for Paul B. Miller.\n",
      "Robert Miller\n",
      "Name list: ['Robert']\n",
      "Looking for Robert Miller\n",
      "Scraping the page\n",
      "Done scraping for Robert Miller.\n",
      "Nicholas Mirkay\n",
      "Name list: ['Nicholas A.']\n",
      "Looking for Nicholas A. Mirkay\n",
      "Scraping the page\n",
      "Done scraping for Nicholas A. Mirkay.\n",
      "Thomas Mitchell\n",
      "Name list: ['Thomas W.', 'Thomas']\n",
      "Looking for Thomas W. Mitchell\n",
      "Scraping the page\n",
      "Done scraping for Thomas W. Mitchell.\n",
      "Looking for Thomas Mitchell\n",
      "Scraping the page\n",
      "Done scraping for Thomas Mitchell.\n",
      "Seema Mohapatra\n",
      "Name list: ['Seema']\n",
      "Looking for Seema Mohapatra\n",
      "Scraping the page\n",
      "Done scraping for Seema Mohapatra.\n",
      "Edward Morrison\n",
      "Name list: ['Edward R.', 'Edward']\n",
      "Looking for Edward R. Morrison\n",
      "Scraping the page\n",
      "Done scraping for Edward R. Morrison.\n",
      "Looking for Edward Morrison\n",
      "A file for Edward Morrison already exists. Moving to the next name.\n",
      "Susan Morse\n",
      "Name list: ['Susan', 'Susan C.']\n",
      "Looking for Susan Morse\n",
      "Scraping the page\n",
      "Done scraping for Susan Morse.\n",
      "Looking for Susan C. Morse\n",
      "A file for Susan C. Morse already exists. Moving to the next name.\n",
      "Samuel Moyn\n",
      "Name list: ['Samuel']\n",
      "Looking for Samuel Moyn\n",
      "Scraping the page\n",
      "Done scraping for Samuel Moyn.\n",
      "Melissa Murray\n",
      "Name list: ['Melissa']\n",
      "Looking for Melissa Murray\n",
      "Scraping the page\n",
      "Done scraping for Melissa Murray.\n",
      "Alexandra Natapoff\n",
      "Name list: ['Alexandra']\n",
      "Looking for Alexandra Natapoff\n",
      "Scraping the page\n",
      "Done scraping for Alexandra Natapoff.\n",
      "Douglas NeJaime\n",
      "Name list: ['Douglas']\n",
      "Looking for Douglas NeJaime\n",
      "Scraping the page\n",
      "Done scraping for Douglas NeJaime.\n",
      "Xuan-Thao Nguyen\n",
      "Name list: ['Xuan-Thao']\n",
      "Looking for Xuan-Thao Nguyen\n",
      "Scraping the page\n",
      "Done scraping for Xuan-Thao Nguyen.\n",
      "Victoria Nourse\n",
      "Name list: ['Victoria', 'Victoria F.']\n",
      "Looking for Victoria Nourse\n",
      "Scraping the page\n",
      "Done scraping for Victoria Nourse.\n",
      "Looking for Victoria F. Nourse\n",
      "A file for Victoria F. Nourse already exists. Moving to the next name.\n",
      "Anne O'Connell\n",
      "Name list: ['Anne', 'Anne Joseph', 'Anne Joseph;']\n",
      "Looking for Anne O'Connell\n",
      "Scraping the page\n",
      "Done scraping for Anne O'Connell.\n",
      "Looking for Anne Joseph O'Connell\n",
      "A file for Anne Joseph O'Connell already exists. Moving to the next name.\n",
      "Looking for Anne Joseph; O'Connell\n",
      "A file for Anne Joseph; O'Connell already exists. Moving to the next name.\n",
      "Shu-Yi Oei\n",
      "Name list: ['Shu-Yi']\n",
      "Looking for Shu-Yi Oei\n",
      "Scraping the page\n",
      "Done scraping for Shu-Yi Oei.\n",
      "Paul Ohm\n",
      "Name list: ['Paul']\n",
      "Looking for Paul Ohm\n",
      "Scraping the page\n",
      "Done scraping for Paul Ohm.\n",
      "Ruth Okediji\n",
      "Name list: ['Ruth', 'Ruth Gana', 'Ruth L.']\n",
      "Looking for Ruth Okediji\n",
      "Scraping the page\n",
      "Done scraping for Ruth Okediji.\n",
      "Looking for Ruth Gana Okediji\n",
      "A file for Ruth Gana Okediji already exists. Moving to the next name.\n",
      "Looking for Ruth L. Okediji\n",
      "A file for Ruth L. Okediji already exists. Moving to the next name.\n",
      "Saule Omarova\n",
      "Name list: ['Saule T.', 'Saule T.', 'Saule']\n",
      "Looking for Saule T. Omarova\n",
      "Scraping the page\n",
      "Done scraping for Saule T. Omarova.\n",
      "Looking for Saule T. Omarova\n",
      "The link https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=Omarova%2C Saule T.&collection=journals has already been scraped. Moving to the next name.\n",
      "Looking for Saule Omarova\n",
      "A file for Saule Omarova already exists. Moving to the next name.\n",
      "Angela Onwuachi-Willig\n",
      "Name list: ['Angela']\n",
      "Looking for Angela Onwuachi-Willig\n",
      "Scraping the page\n",
      "Done scraping for Angela Onwuachi-Willig.\n",
      "David Orentlicher\n",
      "Name list: ['David']\n",
      "Looking for David Orentlicher\n",
      "Scraping the page\n",
      "Done scraping for David Orentlicher.\n",
      "Leigh Osofsky\n",
      "Name list: ['Leigh']\n",
      "Looking for Leigh Osofsky\n",
      "Scraping the page\n",
      "Done scraping for Leigh Osofsky.\n",
      "Dave Owen\n",
      "Name list: ['Dave']\n",
      "Looking for Dave Owen\n",
      "Scraping the page\n",
      "Done scraping for Dave Owen.\n",
      "Mary-Rose Papandrea\n",
      "Name list: ['Mary-Rose']\n",
      "Looking for Mary-Rose Papandrea\n",
      "Scraping the page\n",
      "Done scraping for Mary-Rose Papandrea.\n",
      "Jordan Paradise\n",
      "Name list: ['Jordan', 'Jordan K.']\n",
      "Looking for Jordan Paradise\n",
      "Scraping the page\n",
      "Done scraping for Jordan Paradise.\n",
      "Looking for Jordan K. Paradise\n",
      "A file for Jordan K. Paradise already exists. Moving to the next name.\n",
      "Rafael Pardo\n",
      "Name list: ['Rafael I.', 'Rafael (I)']\n",
      "Looking for Rafael I. Pardo\n",
      "Scraping the page\n",
      "Done scraping for Rafael I. Pardo.\n",
      "Looking for Rafael (I) Pardo\n",
      "Scraping the page\n",
      "Done scraping for Rafael (I) Pardo.\n",
      "James Park\n",
      "Name list: ['James']\n",
      "Looking for James Park\n",
      "Scraping the page\n",
      "Done scraping for James Park.\n",
      "Ed Parson\n",
      "Name list: ['Edward A.']\n",
      "Looking for Edward A. Parson\n",
      "Scraping the page\n",
      "Done scraping for Edward A. Parson.\n",
      "Frank Partnoy\n",
      "Name list: ['Frank']\n",
      "Looking for Frank Partnoy\n",
      "Scraping the page\n",
      "Done scraping for Frank Partnoy.\n",
      "Frank Pasquale\n",
      "Name list: ['Frank']\n",
      "Looking for Frank Pasquale\n",
      "Scraping the page\n",
      "Done scraping for Frank Pasquale.\n",
      "Eduardo Penalver\n",
      "Name list: ['Eduardo', 'Eduardo M.']\n",
      "Looking for Eduardo Penalver\n",
      "Scraping the page\n",
      "Done scraping for Eduardo Penalver.\n",
      "Looking for Eduardo M. Penalver\n",
      "A file for Eduardo M. Penalver already exists. Moving to the next name.\n",
      "Dylan Penningroth\n",
      "Name list: ['Dylan C.']\n",
      "Looking for Dylan C. Penningroth\n",
      "Scraping the page\n",
      "Done scraping for Dylan C. Penningroth.\n",
      "Nathaniel Persily\n",
      "Name list: ['Nathaniel']\n",
      "Looking for Nathaniel Persily\n",
      "Scraping the page\n",
      "Done scraping for Nathaniel Persily.\n",
      "Gregg Polsky\n",
      "Name list: ['Gregg', 'Gregg D.']\n",
      "Looking for Gregg Polsky\n",
      "Scraping the page\n",
      "Done scraping for Gregg Polsky.\n",
      "Looking for Gregg D. Polsky\n",
      "A file for Gregg D. Polsky already exists. Moving to the next name.\n",
      "H. Powell\n",
      "Name list: ['H.']\n",
      "Looking for H. Powell\n",
      "Scraping the page\n",
      "Done scraping for H. Powell.\n",
      "Wendell Pritchett\n",
      "Name list: ['Wendell E.', 'Wendell']\n",
      "Looking for Wendell E. Pritchett\n",
      "Scraping the page\n",
      "Done scraping for Wendell E. Pritchett.\n",
      "Looking for Wendell Pritchett\n",
      "A file for Wendell Pritchett already exists. Moving to the next name.\n",
      "Ellen Pryor\n",
      "Name list: ['Ellen', 'Ellen S.', 'Ellen Smith']\n",
      "Looking for Ellen Pryor\n",
      "Scraping the page\n",
      "Done scraping for Ellen Pryor.\n",
      "Looking for Ellen S. Pryor\n",
      "A file for Ellen S. Pryor already exists. Moving to the next name.\n",
      "Looking for Ellen Smith Pryor\n",
      "A file for Ellen Smith Pryor already exists. Moving to the next name.\n",
      "Scott Pryor\n",
      "Name list: ['Scott']\n",
      "Looking for Scott Pryor\n",
      "Scraping the page\n",
      "Done scraping for Scott Pryor.\n",
      "Jedediah Purdy\n",
      "Name list: ['Jedediah']\n",
      "Looking for Jedediah Purdy\n",
      "Scraping the page\n",
      "Done scraping for Jedediah Purdy.\n",
      "Intisar Rabb\n",
      "Name list: ['Intisar', 'Intisar A.']\n",
      "Looking for Intisar Rabb\n",
      "Scraping the page\n",
      "Done scraping for Intisar Rabb.\n",
      "Looking for Intisar A. Rabb\n",
      "A file for Intisar A. Rabb already exists. Moving to the next name.\n",
      "Srividhya Ragavan\n",
      "Name list: ['Srividhya']\n",
      "Looking for Srividhya Ragavan\n",
      "Scraping the page\n",
      "Done scraping for Srividhya Ragavan.\n",
      "Robert Rhee\n",
      "Name list: ['Robert J.']\n",
      "Looking for Robert J. Rhee\n",
      "Scraping the page\n",
      "Done scraping for Robert J. Rhee.\n",
      "L. Richardson\n",
      "Name list: ['L. Song']\n",
      "Looking for L. Song Richardson\n",
      "Scraping the page\n",
      "Done scraping for L. Song Richardson.\n",
      "Alice Ristroph\n",
      "Name list: ['Alice']\n",
      "Looking for Alice Ristroph\n",
      "Scraping the page\n",
      "Done scraping for Alice Ristroph.\n",
      "Kalyani Robbins\n",
      "Name list: ['Kalyani']\n",
      "Looking for Kalyani Robbins\n",
      "Scraping the page\n",
      "Done scraping for Kalyani Robbins.\n",
      "Dorothy Roberts\n",
      "Name list: ['Dorothy', 'Dorothy E.']\n",
      "Looking for Dorothy Roberts\n",
      "Scraping the page\n",
      "Done scraping for Dorothy Roberts.\n",
      "Looking for Dorothy E. Roberts\n",
      "A file for Dorothy E. Roberts already exists. Moving to the next name.\n",
      "Edward Rock\n",
      "Name list: ['Edward', 'Edward B.']\n",
      "Looking for Edward Rock\n",
      "Scraping the page\n",
      "Done scraping for Edward Rock.\n",
      "Looking for Edward B. Rock\n",
      "A file for Edward B. Rock already exists. Moving to the next name.\n",
      "Cristina Rodriguez\n",
      "Name list: ['Cristina', 'Cristina M.']\n",
      "Looking for Cristina Rodriguez\n",
      "Scraping the page\n",
      "Done scraping for Cristina Rodriguez.\n",
      "Looking for Cristina M. Rodriguez\n",
      "A file for Cristina M. Rodriguez already exists. Moving to the next name.\n",
      "Christopher Roederer\n",
      "Name list: ['Christopher', 'Christopher J.']\n",
      "Looking for Christopher Roederer\n",
      "Scraping the page\n",
      "Done scraping for Christopher Roederer.\n",
      "Looking for Christopher J. Roederer\n",
      "A file for Christopher J. Roederer already exists. Moving to the next name.\n",
      "Benjamin van Rooij\n",
      "Name list: ['Benjamin', 'Benjamin']\n",
      "Looking for Benjamin van Rooij\n",
      "Scraping the page\n",
      "Done scraping for Benjamin van Rooij.\n",
      "Looking for Benjamin van Rooij\n",
      "The link https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=van Rooij%2C Benjamin&collection=journals has already been scraped. Moving to the next name.\n",
      "Jim Rossi\n",
      "Name list: ['Jim']\n",
      "Looking for Jim Rossi\n",
      "Scraping the page\n",
      "Done scraping for Jim Rossi.\n",
      "Troy Rule\n",
      "Name list: ['Troy', 'Troy A.']\n",
      "Looking for Troy Rule\n",
      "Scraping the page\n",
      "Done scraping for Troy Rule.\n",
      "Looking for Troy A. Rule\n",
      "A file for Troy A. Rule already exists. Moving to the next name.\n",
      "Erin Ryan\n",
      "Name list: ['Erin']\n",
      "Looking for Erin Ryan\n",
      "Scraping the page\n",
      "Done scraping for Erin Ryan.\n",
      "Victoria Sahani\n",
      "Name list: ['Victoria Shannon']\n",
      "Looking for Victoria Shannon Sahani\n",
      "Scraping the page\n",
      "Done scraping for Victoria Shannon Sahani.\n",
      "Hillary Sale\n",
      "Name list: ['Hillary A.']\n",
      "Looking for Hillary A. Sale\n",
      "Scraping the page\n",
      "Done scraping for Hillary A. Sale.\n",
      "James Salzman\n",
      "Name list: ['James']\n",
      "Looking for James Salzman\n",
      "Scraping the page\n",
      "Done scraping for James Salzman.\n",
      "Adam Samaha\n",
      "Name list: ['Adam M.']\n",
      "Looking for Adam M. Samaha\n",
      "Scraping the page\n",
      "Done scraping for Adam M. Samaha.\n",
      "Amy Schmitz\n",
      "Name list: ['Amy J.']\n",
      "Looking for Amy J. Schmitz\n",
      "Scraping the page\n",
      "Done scraping for Amy J. Schmitz.\n",
      "David Schwartz\n",
      "Name list: ['David', 'David L.']\n",
      "Looking for David Schwartz\n",
      "Scraping the page\n",
      "Done scraping for David Schwartz.\n",
      "Looking for David L. Schwartz\n",
      "Scraping the page\n",
      "Done scraping for David L. Schwartz.\n",
      "Christopher Serkin\n",
      "Name list: ['Christopher']\n",
      "Looking for Christopher Serkin\n",
      "Scraping the page\n",
      "Done scraping for Christopher Serkin.\n",
      "Gregory Shaffer\n",
      "Name list: ['Gregory']\n",
      "Looking for Gregory Shaffer\n",
      "Scraping the page\n",
      "Done scraping for Gregory Shaffer.\n",
      "Darien Shanske\n",
      "Name list: ['Darien']\n",
      "Looking for Darien Shanske\n",
      "Scraping the page\n",
      "Done scraping for Darien Shanske.\n",
      "Jessica Silbey\n",
      "Name list: ['Jessica']\n",
      "Looking for Jessica Silbey\n",
      "Scraping the page\n",
      "Done scraping for Jessica Silbey.\n",
      "Michael Simkovic\n",
      "Name list: ['Michael', 'Michael N.']\n",
      "Looking for Michael Simkovic\n",
      "Scraping the page\n",
      "Done scraping for Michael Simkovic.\n",
      "Looking for Michael N. Simkovic\n",
      "A file for Michael N. Simkovic already exists. Moving to the next name.\n",
      "Beth Simmons\n",
      "Name list: ['Beth', 'Beth A.']\n",
      "Looking for Beth Simmons\n",
      "Scraping the page\n",
      "Done scraping for Beth Simmons.\n",
      "Looking for Beth A. Simmons\n",
      "A file for Beth A. Simmons already exists. Moving to the next name.\n",
      "Kenneth Simons\n",
      "Name list: ['Kenneth W.']\n",
      "Looking for Kenneth W. Simons\n",
      "Scraping the page\n",
      "Done scraping for Kenneth W. Simons.\n",
      "David Sklansky\n",
      "Name list: ['David Alan', 'David A.']\n",
      "Looking for David Alan Sklansky\n",
      "Scraping the page\n",
      "Done scraping for David Alan Sklansky.\n",
      "Looking for David A. Sklansky\n",
      "A file for David A. Sklansky already exists. Moving to the next name.\n",
      "Brad Snyder\n",
      "Name list: ['Brad']\n",
      "Looking for Brad Snyder\n",
      "Scraping the page\n",
      "Done scraping for Brad Snyder.\n",
      "A. Spencer\n",
      "Name list: ['A. Benjamin']\n",
      "Looking for A. Benjamin Spencer\n",
      "Scraping the page\n",
      "Done scraping for A. Benjamin Spencer.\n",
      "Matthew Spitzer\n",
      "Name list: ['Matthew', 'Matthew L.']\n",
      "Looking for Matthew Spitzer\n",
      "Scraping the page\n",
      "Done scraping for Matthew Spitzer.\n",
      "Looking for Matthew L. Spitzer\n",
      "A file for Matthew L. Spitzer already exists. Moving to the next name.\n",
      "Christopher Sprigman\n",
      "Name list: ['Christopher', 'Christopher Jon']\n",
      "Looking for Christopher Sprigman\n",
      "Scraping the page\n",
      "Done scraping for Christopher Sprigman.\n",
      "Looking for Christopher Jon Sprigman\n",
      "A file for Christopher Jon Sprigman already exists. Moving to the next name.\n",
      "Paul Stancil\n",
      "Name list: ['Paul']\n",
      "Looking for Paul Stancil\n",
      "Scraping the page\n",
      "Done scraping for Paul Stancil.\n",
      "Jean Stefancic\n",
      "Name list: ['Jean']\n",
      "Looking for Jean Stefancic\n",
      "Scraping the page\n",
      "Done scraping for Jean Stefancic.\n",
      "Alex Stein\n",
      "Name list: ['Alex']\n",
      "Looking for Alex Stein\n",
      "Scraping the page\n",
      "Done scraping for Alex Stein.\n",
      "Adam Steinman\n",
      "Name list: ['Adam', 'Adam N.']\n",
      "Looking for Adam Steinman\n",
      "Scraping the page\n",
      "Done scraping for Adam Steinman.\n",
      "Looking for Adam N. Steinman\n",
      "A file for Adam N. Steinman already exists. Moving to the next name.\n",
      "Kristen Stilt\n",
      "Name list: ['Kristen', 'Kristen A.']\n",
      "Looking for Kristen Stilt\n",
      "Scraping the page\n",
      "Done scraping for Kristen Stilt.\n",
      "Looking for Kristen A. Stilt\n",
      "A file for Kristen A. Stilt already exists. Moving to the next name.\n",
      "David Studdert\n",
      "Name list: ['David M.', 'David']\n",
      "Looking for David M. Studdert\n",
      "Scraping the page\n",
      "Done scraping for David M. Studdert.\n",
      "Looking for David Studdert\n",
      "A file for David Studdert already exists. Moving to the next name.\n",
      "Madhavi Sunder\n",
      "Name list: ['Madhavi']\n",
      "Looking for Madhavi Sunder\n",
      "Scraping the page\n",
      "Done scraping for Madhavi Sunder.\n",
      "Alan Sykes\n",
      "Name list: ['Alan', 'Alan O.']\n",
      "Looking for Alan Sykes\n",
      "Scraping the page\n",
      "Done scraping for Alan Sykes.\n",
      "Looking for Alan O. Sykes\n",
      "A file for Alan O. Sykes already exists. Moving to the next name.\n",
      "Eric Talley\n",
      "Name list: ['Eric', 'Eric L.']\n",
      "Looking for Eric Talley\n",
      "Scraping the page\n",
      "Done scraping for Eric Talley.\n",
      "Looking for Eric L. Talley\n",
      "A file for Eric L. Talley already exists. Moving to the next name.\n",
      "Kim Talus\n",
      "Name list: ['Kim']\n",
      "Looking for Kim Talus\n",
      "Scraping the page\n",
      "Done scraping for Kim Talus.\n",
      "Franita Tolson\n",
      "Name list: ['Franita']\n",
      "Looking for Franita Tolson\n",
      "Scraping the page\n",
      "Done scraping for Franita Tolson.\n",
      "Christopher Tomlins\n",
      "Name list: ['Christopher', 'Christopher L.']\n",
      "Looking for Christopher Tomlins\n",
      "Scraping the page\n",
      "Done scraping for Christopher Tomlins.\n",
      "Looking for Christopher L. Tomlins\n",
      "A file for Christopher L. Tomlins already exists. Moving to the next name.\n",
      "Gerald Torres\n",
      "Name list: ['Gerald']\n",
      "Looking for Gerald Torres\n",
      "Scraping the page\n",
      "Done scraping for Gerald Torres.\n",
      "Elizabeth Trujillo\n",
      "Name list: ['Elizabeth']\n",
      "Looking for Elizabeth Trujillo\n",
      "Scraping the page\n",
      "Done scraping for Elizabeth Trujillo.\n",
      "Deborah Tuerkheimer\n",
      "Name list: ['Deborah']\n",
      "Looking for Deborah Tuerkheimer\n",
      "Scraping the page\n",
      "Done scraping for Deborah Tuerkheimer.\n",
      "Rebecca Tushnet\n",
      "Name list: ['Rebecca']\n",
      "Looking for Rebecca Tushnet\n",
      "Scraping the page\n",
      "Done scraping for Rebecca Tushnet.\n",
      "Amanda Tyler\n",
      "Name list: ['Amanda L.']\n",
      "Looking for Amanda L. Tyler\n",
      "Scraping the page\n",
      "Done scraping for Amanda L. Tyler.\n",
      "Ryan Vacca\n",
      "Name list: ['Ryan', 'Ryan G.']\n",
      "Looking for Ryan Vacca\n",
      "Scraping the page\n",
      "Done scraping for Ryan Vacca.\n",
      "Looking for Ryan G. Vacca\n",
      "A file for Ryan G. Vacca already exists. Moving to the next name.\n",
      "Katharine Van Tassel\n",
      "Name list: ['Katharine']\n",
      "Looking for Katharine Van Tassel\n",
      "Scraping the page\n",
      "Done scraping for Katharine Van Tassel.\n",
      "Urska Velikonja\n",
      "Name list: ['Urska']\n",
      "Looking for Urska Velikonja\n",
      "Scraping the page\n",
      "Done scraping for Urska Velikonja.\n",
      "Rose Villazor\n",
      "Name list: ['Rose Cuison']\n",
      "Looking for Rose Cuison Villazor\n",
      "Scraping the page\n",
      "Done scraping for Rose Cuison Villazor.\n",
      "Steve Vladeck\n",
      "Name list: ['Steve', 'Stephen']\n",
      "Looking for Steve Vladeck\n",
      "Scraping the page\n",
      "Done scraping for Steve Vladeck.\n",
      "Looking for Stephen Vladeck\n",
      "A file for Stephen Vladeck already exists. Moving to the next name.\n",
      "Gina Warren\n",
      "Name list: ['Gina', 'Gina S.']\n",
      "Looking for Gina Warren\n",
      "Scraping the page\n",
      "Done scraping for Gina Warren.\n",
      "Looking for Gina S. Warren\n",
      "A file for Gina S. Warren already exists. Moving to the next name.\n",
      "Melissa Wasserman\n",
      "Name list: ['Melissa F.', 'Melissa Feeney']\n",
      "Looking for Melissa F. Wasserman\n",
      "Scraping the page\n",
      "Done scraping for Melissa F. Wasserman.\n",
      "Looking for Melissa Feeney Wasserman\n",
      "A file for Melissa Feeney Wasserman already exists. Moving to the next name.\n",
      "Nancy Welsh\n",
      "Name list: ['Nancy', 'Nancy A.']\n",
      "Looking for Nancy Welsh\n",
      "Scraping the page\n",
      "Done scraping for Nancy Welsh.\n",
      "Looking for Nancy A. Welsh\n",
      "A file for Nancy A. Welsh already exists. Moving to the next name.\n",
      "Robin Wilson\n",
      "Name list: ['Robin', 'Robin Fretwell']\n",
      "Looking for Robin Wilson\n",
      "Scraping the page\n",
      "Done scraping for Robin Wilson.\n",
      "Looking for Robin Fretwell Wilson\n",
      "A file for Robin Fretwell Wilson already exists. Moving to the next name.\n",
      "Andrew Woods\n",
      "Name list: ['Andrew Keane', 'Andrew K.']\n",
      "Looking for Andrew Keane Woods\n",
      "Scraping the page\n",
      "Done scraping for Andrew Keane Woods.\n",
      "Looking for Andrew K. Woods\n",
      "A file for Andrew K. Woods already exists. Moving to the next name.\n",
      "Kevin Woodson\n",
      "Name list: ['Kevin']\n",
      "Looking for Kevin Woodson\n",
      "Scraping the page\n",
      "Done scraping for Kevin Woodson.\n",
      "Del Wright\n",
      "Name list: ['Del Jr.']\n",
      "Looking for Del Jr. Wright\n",
      "Scraping the page\n",
      "Done scraping for Del Jr. Wright.\n",
      "Gideon Yaffe\n",
      "Name list: ['Gideon']\n",
      "Looking for Gideon Yaffe\n",
      "Scraping the page\n",
      "Done scraping for Gideon Yaffe.\n",
      "Ellen Yaroshefsky\n",
      "Name list: ['Ellen']\n",
      "Looking for Ellen Yaroshefsky\n",
      "Scraping the page\n",
      "Done scraping for Ellen Yaroshefsky.\n",
      "Ruqaiijah Yearby\n",
      "Name list: ['Ruqaiijah', 'Ruqaiijah A.']\n",
      "Looking for Ruqaiijah Yearby\n",
      "Scraping the page\n",
      "Done scraping for Ruqaiijah Yearby.\n",
      "Looking for Ruqaiijah A. Yearby\n",
      "A file for Ruqaiijah A. Yearby already exists. Moving to the next name.\n",
      "Peter Yu\n",
      "Name list: ['Peter K.']\n",
      "Looking for Peter K. Yu\n",
      "Scraping the page\n",
      "Done scraping for Peter K. Yu.\n",
      "Kathryn Zeiler\n",
      "Name list: ['Kathryn']\n",
      "Looking for Kathryn Zeiler\n",
      "Scraping the page\n",
      "Done scraping for Kathryn Zeiler.\n",
      "Sandi Zellmer\n",
      "Name list: ['Sandi B.', 'Sandra']\n",
      "Looking for Sandi B. Zellmer\n",
      "Scraping the page\n",
      "Done scraping for Sandi B. Zellmer.\n",
      "Looking for Sandra Zellmer\n",
      "A file for Sandra Zellmer already exists. Moving to the next name.\n"
     ]
    }
   ],
   "source": [
    "# Initilization\n",
    "# Page name is a list of the name for all of the pages that we have scraped.\n",
    "# This is the name that actually appears on the webpage. This helps prevent\n",
    "# us from having to rescrape pages multiple times.\n",
    "err_fm_names = []\n",
    "skip_df = pd.DataFrame()\n",
    "\n",
    "#This loop goes through each name\n",
    "for i in range(len(data)):\n",
    "    # Export the updated dataframe of skipped names and scraped pages\n",
    "    skip_df.to_excel(out_path / \"_skip_output.xlsx\", index = False)\n",
    "    df_scraped_pages.to_excel(scraped_pages_file, index = False)\n",
    "    #This section gets the professor's information from the dataframe \n",
    "    # Get variable values from the dataframe\n",
    "    prof_id = data['ID'][i]\n",
    "    mid_first_name = data['FirstName'][i]\n",
    "    last_name = data['LastName'][i]\n",
    "    full_name = mid_first_name + ' ' +  last_name\n",
    "    #This line gets the school URLs from the dataframe\n",
    "    if data_type == \"lateral\":\n",
    "        school_url = [data['Short URL Origin'][i], data['Short URL Destination'][i]]\n",
    "        school = data['Origin School'][i]\n",
    "        new_school = data['Destination School'][i]\n",
    "    elif data_type == \"control\":\n",
    "        school_url = [data['Short URL Origin'][i]]\n",
    "        school = data['Origin School'][i]\n",
    "\n",
    "    # Print the name that we are considering\n",
    "    print(full_name)\n",
    "\n",
    "    # If there were no matching names, the value is nan. This means that the value does not equal itself.\n",
    "    #  The name is added to the skipped names list and the loop moves onto the next name. \n",
    "    fm_names_str = data['fm_names'][i]\n",
    "    if fm_names_str != fm_names_str:\n",
    "        print('Name ' + full_name + ' was not found. Adding to the skipped names dataset.')\n",
    "        skip_df = pd.concat([skip_df, data.iloc[[i]]])\n",
    "        continue\n",
    "\n",
    "    fm_names = fm_names_str.split(\", \")\n",
    "    print(\"Name list: {}\".format(fm_names))   \n",
    "        \n",
    "    #This section loops through the list of alternative names and goes directly to their pages on Hein\n",
    "    for fm_name in fm_names:\n",
    "        # Create the full name\n",
    "        full_name = fm_name + ' ' +  last_name\n",
    "        print(\"Looking for {}\".format(full_name))\n",
    "        # Check if the file exists\n",
    "        file_name = '{}_{}_papers.xlsx'.format(full_name, prof_id)            \n",
    "\n",
    "        #Link to Hein page\n",
    "        link = 'https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=' + last_name +  '%2C ' + fm_name + '&collection=journals'\n",
    "\n",
    "        # CHECK DATA: This is the first spot where we check the data. We want to see if the link that we are\n",
    "        # going to has already been added to the list of scraped pages. This is helpful when rerunning the code.\n",
    "        if not df_scraped_pages.query('@link == links').empty:\n",
    "            print(\"The link {} has already been scraped. Moving to the next name.\".format(link))\n",
    "            continue\n",
    "        #Direct the webdriver to the page\n",
    "        driver.get(link)\n",
    "        #This function waits for the webpage to load\n",
    "        webpage_wait('//*[@id=\"page_content\"]/div[1]/div/div[1]/div[1]', driver)\n",
    "        #This gets the page HTML\n",
    "        soup=bs.BeautifulSoup(driver.page_source, 'lxml')\n",
    "        #This find the stat table at the top of the page\n",
    "        table_rows = soup.findAll('td', {'style': 'text-align:right;'})\n",
    "    \n",
    "        # This is the name for the professor that is used on the page.\n",
    "        cur_page = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[1]/div[1]').text\n",
    "\n",
    "        # CHECK DATA: This is the second spot where we check the data to see if the page has\n",
    "        # already been scraped. In order to check to see if the link has already been scraped, \n",
    "        # we look for the professor name on the page (which may be different from the name in our list) \n",
    "        # and the professor ID. This is helpful when two names point to the same page.\n",
    "        if not df_scraped_pages.query('@cur_page == professor_names and @prof_id == id').empty:\n",
    "            print(\"A file for {} already exists. Moving to the next name.\".format(full_name))\n",
    "            # Add the link to the data so that we know to skip it in future runs\n",
    "            values_scraped_pages = [link, file_name, cur_page, prof_id]\n",
    "            dict_values_scraped_pages = dict(zip(scraped_pages_columns, values_scraped_pages))\n",
    "            df_scraped_pages = df_scraped_pages.append([dict_values_scraped_pages])\n",
    "            continue\n",
    "        #If there is a table on the page and the page name has not already appeared in the scraped list.\n",
    "        if table_rows: \n",
    "            element = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[2]')\n",
    "            table_element = element.text.split('\\n')\n",
    "            #If the table is empty, there is no data to scrape\n",
    "            if len(table_element) < 5:\n",
    "                print('No data available on Hein for {} {}'.format(fm_name, last_name))\n",
    "                continue\n",
    "            #If the table is full, this section rearranges the data into a better format\n",
    "            print(\"Scraping the page\")                \n",
    "            #This section scrapes the paper data. The index values are based on the way the xpaths are incremented\n",
    "            #The scroll number tracks the number of times the page has scrolled. This is for pages with a large number of \n",
    "            #papers. The xpaths change when the page scrolls.\n",
    "            title_index = 3\n",
    "            stats_index = 4\n",
    "            topic_index = 0\n",
    "            scroll_num = 0\n",
    "            #This gets the page source\n",
    "            soup=bs.BeautifulSoup(driver.page_source, 'lxml')\n",
    "            #This section gets the paper topics\n",
    "            topic_array = soup.findAll('div', {'class': 'topics'})\n",
    "            element = title_index\n",
    "            df = pd.DataFrame(columns = ['Title', 'Author(s)', 'ID', 'Journal', 'BBCite', 'Topics', 'Cited (articles)', 'Cited (cases)', 'Accessed'])\n",
    "            #This while loop will continue until there are no more papers on the page\n",
    "            while element:\n",
    "                #Data stream is a list of the data in the paper data box (for example, authors, topics, journal)\n",
    "                data_stream = []\n",
    "                #This funciton returns a dictionary with various fields for each variable in the data box\n",
    "                #Sometimes some of the variables are missing (for example, there are papers without a journal listed)\n",
    "                #In this case, the dictionary returns an empty value for these variables\n",
    "                data_dict = get_paper_data(last_name, prof_id, title_index, scroll_num, driver)\n",
    "                #This section gets the paper stats box. This is the box that says how many citations the paper\n",
    "                #has received\n",
    "                if scroll_num == 0:\n",
    "                    element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(stats_index) + ']/div[2]/div')\n",
    "                elif scroll_num > 0:\n",
    "                    element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div[' + str(stats_index) + ']/div[2]/div')\n",
    "                #This section extracts the data from the paper stats box\n",
    "                for elm in element:\n",
    "                    cited_text = elm.text\n",
    "                article_citations = 'na'\n",
    "                case_citations = 'na'\n",
    "                accessed = 'na'\n",
    "                if not isinstance(cited_text, list):\n",
    "                    cited_text = cited_text.split('\\n')\n",
    "                    #This section finds the value for each paper stat\n",
    "                    for stat in cited_text:\n",
    "                        if 'Article' in stat:\n",
    "                            article_citations = int(re.search(r'\\d+', stat).group())\n",
    "                        if 'Case' in stat:\n",
    "                            case_citations = int(re.search(r'\\d+', stat).group())\n",
    "                        if 'Accessed' in stat:\n",
    "                            accessed = int(re.search(r'\\d+', stat).group())\n",
    "                #The values are appended to the data_stream list\n",
    "                data_stream.append(article_citations)\n",
    "                data_stream.append(case_citations)\n",
    "                data_stream.append(accessed)\n",
    "                #This line adds the output from the function get_paper_data to the data_stream list\n",
    "                data_stream = list(data_dict.values()) + data_stream\n",
    "                #The data_stream list is used to add a line of data to the overall paper dataframe for this author\n",
    "                df = df.append(pd.DataFrame([data_stream], columns = ['Title', 'Author(s)', 'ID', 'Journal', 'BBCite', 'Topics', 'Cited (articles)', 'Cited (cases)', 'Accessed']), sort=False)\n",
    "                #The indices are augmented to get the next paper\n",
    "                stats_index +=4\n",
    "                title_index += 4\n",
    "                #Check that next paper exists:\n",
    "                if scroll_num == 0:\n",
    "                    x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                #If the page has scrolled, the xpath we need to check has changed\n",
    "                if scroll_num > 0:\n",
    "                    x_path_title = '//*[@id=\"save_results\"]/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                element = driver.find_elements_by_xpath(x_path_title)\n",
    "                #If we can't find a next paper, it could be because we need to scroll again\n",
    "                #This section attempts to scroll the page. \n",
    "                if not element:\n",
    "                    scroll_num +=1\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    box_element = driver.find_elements_by_xpath('//*[@id=\"results_total\"]')\n",
    "                    num_papers = int(box_element[0].text.split(' ')[0])\n",
    "                    #If there are more than 100 papers, we know there are still paper left to scrape\n",
    "                    if num_papers > 100*scroll_num:\n",
    "                        time.sleep(15)\n",
    "                        title_index = 3\n",
    "                        stats_index = 4\n",
    "                        topic_index = 0\n",
    "                        x_path_title = '//*[@id=\"save_results\"]/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                        element = driver.find_elements_by_xpath(x_path_title)\n",
    "            #This line saves the Excel file of papers\n",
    "            df.to_excel(out_path / '{}_{}_papers.xlsx'.format(full_name, prof_id), index=False)\n",
    "            # We have created a file, so we need to append the link and the file name to the list of scraped pages\n",
    "            values_scraped_pages = [link, file_name, cur_page, prof_id]\n",
    "            dict_values_scraped_pages = dict(zip(scraped_pages_columns, values_scraped_pages))\n",
    "            df_scraped_pages = df_scraped_pages.append([dict_values_scraped_pages])\n",
    "            time.sleep(3)\n",
    "            #If we reach this point, all the pages for that author have been scraped\n",
    "            print('Done scraping for {}.'.format(fm_name + ' ' + last_name))\n",
    "        else:\n",
    "            print(\"No data was found for {}. Moving to the next name.\".format(full_name))"
   ]
  }
 ]
}