{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import nltk\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://proxy.its.virginia.edu/login?url=http://heinonline.org/HOL/Welcome\")\n",
    "g_driver = webdriver.Chrome()\n",
    "g_driver.get(\"http://google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this part to automatically login, but DUO two step authentication is still required. You will have to enter that manually. After entering the DUO code, you will be given a warning that the information you enter could be sent over an insecure connection. Click continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'meb2fv'\n",
    "password = '0ver In 2018!'\n",
    "driver.find_element_by_id(\"user\").send_keys(username);\n",
    "driver.find_element_by_id(\"pass\").send_keys(password);\n",
    "driver.find_element_by_xpath(\"/html/body/main/div[2]/fieldset/form/input\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have logged in, Selenium is able to navigate to any webpage. We will navigate to the pages on the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_names(mid_first_name, last_name, school_url):\n",
    "#     link = 'https://heinonline-org.proxy01.its.virginia.edu/HOL/LuceneSearch?typea=title&termsa=&operator=AND&typeb=creator&termsb=' + last_name + '+' + mid_first_name + '&operatorb=AND&typec=text&termsc=&operatorc=AND&typed=title&termsd=&operatord=AND&typee=title&termse=&operatore=AND&typef=title&termsf=&yearlo=&yearhi=&tabfrom=&searchtype=field&collection=all&submit=Go'\n",
    "#     driver.get(link)\n",
    "#     try: \n",
    "#         outer_element = driver.find_element_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[3]/div[2]')\n",
    "#     except:\n",
    "#         outer_element = []\n",
    "#     paper_index = 3\n",
    "#     alt_fm_names = []\n",
    "#     err_fm_names = []\n",
    "#     name_index = 1\n",
    "#     while outer_element:\n",
    "#         try:\n",
    "#             element = driver.find_element_by_xpath('//*[@id=\"save_results\"]/div[1]/div/div/div['+ str(paper_index) + ']/div[2]/dt[4]/a[' + str(name_index) + ']')\n",
    "#         except:\n",
    "#             element = []\n",
    "#         while element: \n",
    "#             new_name = element.text\n",
    "#             print(new_name)\n",
    "#             if last_name and mid_first_name in new_name:\n",
    "#                 new_fm = new_name.split(', ')[1]\n",
    "#                 if not new_fm in alt_fm_names and not new_fm in err_fm_names:\n",
    "#                         faculty = check_google(new_fm, last_name, school_url)\n",
    "#                         if faculty: \n",
    "#                             alt_fm_names.append(new_fm)\n",
    "#                             print(new_fm)\n",
    "#                         else: \n",
    "#                             err_fm_names.append(new_fm)\n",
    "#             print('In while loop')\n",
    "#             try:\n",
    "#                 name_index += 1\n",
    "#                 element = driver.find_element_by_xpath('//*[@id=\"save_results\"]/div[1]/div/div/div['+ str(paper_index) + ']/div[2]/dt[4]/a[' + str(name_index) + ']')\n",
    "#             except:\n",
    "#                 element = []\n",
    "#         print('Out while loop')\n",
    "#         try:\n",
    "#             name_index = 1\n",
    "#             paper_index += 4\n",
    "#             outer_element = driver.find_element_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(paper_index) + ']')\n",
    "#         except: \n",
    "#             outer_element = []\n",
    "#     return alt_fm_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_names(mid_first_name, last_name, school_url):\n",
    "    link = 'https://heinonline-org.proxy01.its.virginia.edu/HOL/LuceneSearch?typea=title&termsa=&operator=AND&typeb=creator&termsb=' + last_name + '+' + mid_first_name + '&operatorb=AND&typec=text&termsc=&operatorc=AND&typed=title&termsd=&operatord=AND&typee=title&termse=&operatore=AND&typef=title&termsf=&yearlo=&yearhi=&tabfrom=&searchtype=field&collection=all&submit=Go'\n",
    "    driver.get(link)\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"search_modify\"]/form/div/div/div/div/a[4]/i').click()\n",
    "    except:\n",
    "        driver.find_element_by_xpath('//*[@id=\"search_modify\"]/div')\n",
    "    element = driver.find_elements_by_tag_name('a')\n",
    "    full_name = mid_first_name + ' ' +  last_name\n",
    "    alt_fm_names = []\n",
    "    err_fm_names = []\n",
    "    if ' ' in mid_first_name.lower():\n",
    "        first_name = mid_first_name.split(' ')[0]\n",
    "    else: \n",
    "        first_name = mid_first_name\n",
    "#     print(mid_first_name.lower())\n",
    "#     print(last_name.lower())\n",
    "    page = 1\n",
    "    \n",
    "    while element:\n",
    "        for link in element:\n",
    "            link_text = link.text.lower()\n",
    "            if first_name.lower() in link_text.lower() and last_name.lower() in link_text.lower() and '[' not in link_text:\n",
    "                try:\n",
    "                    new_last = link_text.split(', ')[0]\n",
    "                    new_first_mid = link_text.split(', ')[1]\n",
    "                    if first_name.lower() in new_first_mid and last_name.lower() == new_last:\n",
    "#                         print(link_text)\n",
    "                        new_fm = link.text.split(', ')[1]\n",
    "                        if not new_fm in alt_fm_names and not new_fm in err_fm_names:\n",
    "                            faculty = check_google(new_fm, last_name, school_url)\n",
    "                            if faculty: \n",
    "                                alt_fm_names.append(new_fm)\n",
    "#                                 print(new_fm)\n",
    "                            else: \n",
    "                                err_fm_names.append(new_fm)\n",
    "                except:\n",
    "                    continue\n",
    "        if page < 2:\n",
    "            try:\n",
    "                driver.find_element_by_xpath('//*[@id=\"thenext\"]/span').click()\n",
    "                time.sleep(3)\n",
    "                element = driver.find_elements_by_tag_name('a') \n",
    "                page += 1\n",
    "                print('0k')\n",
    "            except:\n",
    "                element = []\n",
    "        else: \n",
    "            element = []\n",
    "    return alt_fm_names, err_fm_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_names(alt_name_list, err_fm_names, mid_first_name, last_name):\n",
    "#     try:\n",
    "    driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[2]/div/b/a').click()\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"simlist\"]/ul[1]')\n",
    "    similar_name_list = [a.strip() for a in element.text.split('\\n')]\n",
    "    print(similar_name_list)\n",
    "    middle_name = ''\n",
    "    if ' ' in mid_first_name.lower():\n",
    "        first_name = mid_first_name.split(' ')[0]\n",
    "        middle_name = mid_first_name.split(' ')[1]\n",
    "    else: \n",
    "        first_name = mid_first_name\n",
    "    for name in similar_name_list:\n",
    "        if first_name.lower() in name.lower() and last_name.lower() in name.lower():\n",
    "            new_fm = name.split(', ', 1)[1]            \n",
    "            new_last = name.split(', ', 1)[0]\n",
    "            print(new_fm + ' ' + new_last)\n",
    "            if new_fm not in alt_name_list and last_name.lower() == new_last.lower() and not new_fm in err_fm_names:\n",
    "                if ' ' in new_fm.lower() and middle_name != '':\n",
    "                    new_mi = new_fm.split(' ')[1][0].lower()\n",
    "                    if new_mi == middle_name[0].lower():\n",
    "                        alt_name_list.append(new_fm)\n",
    "                        continue\n",
    "                faculty = check_google(new_fm, last_name, school_url)\n",
    "                if faculty: \n",
    "                    alt_name_list.append(new_fm)\n",
    "                else: \n",
    "                    err_fm_names.append(new_fm)\n",
    "#     except:\n",
    "#         print('No similar names found.')\n",
    "    return alt_name_list, err_fm_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_google(mid_first_name, last_name, school_url):\n",
    "    faculty = False\n",
    "    g_driver.get(\"http://google.com\")\n",
    "    search = g_driver.find_element_by_name('q')\n",
    "    if not ' ' in mid_first_name:\n",
    "        search.send_keys(mid_first_name + ' ' + last_name + ' ' + school_url)\n",
    "    else: \n",
    "        search.send_keys(mid_first_name + ' ' + last_name + ' ')\n",
    "    search.send_keys(Keys.RETURN)\n",
    "    elems = g_driver.find_elements_by_xpath(\"//a[@href]\")\n",
    "    \n",
    "    for elem in elems:\n",
    "        if school_url in elem.text:\n",
    "            print(school_url + ' in: ' + elem.text)\n",
    "            faculty = True\n",
    "            break\n",
    "    return faculty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cornell in: Sheri Lynn Johnson - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Sheri_Johnson.cfm\n",
      "['Sheri Lynn']\n",
      "['Johnson, Sheri L.', 'Adler, Sheri P.', 'Ahl, Sheri A.', 'Allen, Sheri', 'Alpert, Sheri', 'Alpert, Sheri A.', 'Archidiacono, Sheri', 'Balsam, Sheri L.', 'Berman, Sheri', 'Berman, Sheri E.', 'Bienstock, Sheri L.', 'Bonstelle, Sheri', 'Byrne, Sheri A.', 'Cohen, Sheri', 'Coover, Sheri', 'Danz, Sheri M.', 'Dillon, Sheri', 'Dillon, Sheri A.', 'Engelken, Sheri J.', 'Falco, Sheri Lyn', 'Show more names']\n",
      "Sheri L. Johnson\n",
      "['Sheri Lynn', 'Sheri L.']\n",
      "['Johnson, Sheri Lynn', 'Adler, Sheri P.', 'Ahl, Sheri A.', 'Allen, Sheri', 'Alpert, Sheri', 'Alpert, Sheri A.', 'Archidiacono, Sheri', 'Balsam, Sheri L.', 'Berman, Sheri', 'Berman, Sheri E.', 'Bienstock, Sheri L.', 'Bonstelle, Sheri', 'Byrne, Sheri A.', 'Cohen, Sheri', 'Coover, Sheri', 'Danz, Sheri M.', 'Dillon, Sheri', 'Dillon, Sheri A.', 'Engelken, Sheri J.', 'Falco, Sheri Lyn', 'Show more names']\n",
      "Sheri Lynn Johnson\n",
      "['Sheri Lynn', 'Sheri L.']\n"
     ]
    }
   ],
   "source": [
    "fm_name = 'Sheri Lynn'\n",
    "last_name = 'Johnson'\n",
    "err_fm_names = []\n",
    "faculty, err_fm_names = search_names(fm_name, last_name, 'cornell')\n",
    "print(faculty)\n",
    "for fm_name in faculty:\n",
    "    link = 'https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=' + last_name +  '%2C ' + fm_name + '&collection=journals'\n",
    "    driver.get(link)\n",
    "    faculty, err_fm_names = similar_names(faculty, err_fm_names, fm_name, last_name)\n",
    "    print(faculty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sheri Lynn', 'Sheri L.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faculty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no middle name, a more famous person with the same first and last name will\n",
    "    be at the top of the search results, so we need to add the school name\n",
    "    In this case it will be ambiguous is another professor with the same first and last name \n",
    "    is in Hein anyway, so there is really no good way to tell if we are getting the wrong one.\n",
    "    If they have a middle initial, I assume there is not another professor using the same exact name\n",
    "    at a different school. Therefore, to avoid conflict with more famous people, I use the school name \n",
    "    in the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(*args):\n",
    "    cur_path = os.getcwd()\n",
    "    for value in args:\n",
    "        cur_path  = os.path.join(cur_path, value)\n",
    "    return cur_path\n",
    "\n",
    "def to_float_or_int(input_list):\n",
    "    new_list = []\n",
    "    for x in input_list:\n",
    "        x = x.replace(',','')\n",
    "        try:\n",
    "            value = int(x)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                value = float(x)\n",
    "            except:\n",
    "                value = ''\n",
    "        new_list.append(value)\n",
    "    return new_list\n",
    "\n",
    "def create_dataframe_dict(my_list):#, person, school, data_type):\n",
    "#     my_dict = {'Person': person, \n",
    "#               'School': school, \n",
    "#               'Type': data_type}\n",
    "    my_dict = {}\n",
    "    for stat in stats:\n",
    "        my_dict[stat] = ''\n",
    "        for item in my_list:   \n",
    "            if item[0] == stat:\n",
    "                my_dict[stat] = item[1]  \n",
    "    return my_dict\n",
    "\n",
    "def webpage_wait(xpath):\n",
    "    element = []\n",
    "    while not element:\n",
    "        try:\n",
    "            element = driver.find_element_by_xpath(xpath)\n",
    "        except:\n",
    "            print('Page has not loaded, sleeping for 3 seconds')\n",
    "            time.sleep(3)\n",
    "\n",
    "def remove_commas(df1):\n",
    "    for col in df1.columns:\n",
    "        df1[col] = df1[col].str.replace(',', '')\n",
    "    return df1\n",
    "\n",
    "def check_files(fm_name, last_name, current_files):\n",
    "    done = False\n",
    "    for cur_file in current_files:\n",
    "        if fm_name.lower() in cur_file.lower() and last_name.lower() in cur_file.lower():\n",
    "            done = True\n",
    "            break\n",
    "    return done\n",
    "\n",
    "def check_df(current_stats, school_name):\n",
    "    file = ''\n",
    "    for cur_stat in current_stats:\n",
    "        if school_name in cur_stat.lower():\n",
    "            file = cur_stat\n",
    "            break\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(create_path('Professor Names.xlsx'))\n",
    "urls = pd.read_csv(create_path('University and College Websites update.csv'))\n",
    "urls.head()\n",
    "\n",
    "name_tuple = list(zip(data.First, data.Middle, data.Last))\n",
    "fm_name = [x[0] + ' ' +  x[1]  if isinstance(x[1], str)  else x[0] for x in name_tuple ]\n",
    "last_name = [x[2] for x in name_tuple ]\n",
    "title = ['NA']*len(last_name)\n",
    "new_data = pd.DataFrame({'First Name': fm_name, 'Last Name': last_name, 'Title': title, 'School': data.Former, 'New School': data.Current})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school_urls(urls_df, school_list):\n",
    "    url_list = []\n",
    "    for school_name in school_list:\n",
    "        school_name = school_name.replace(',', '')\n",
    "        try: \n",
    "            index = urls_df[urls_df['School Name'] == school_name].index[0]\n",
    "            print(school_name)\n",
    "            url_name = urls_df['URL'][index]\n",
    "            print(url_name)\n",
    "            url_list.append(url_name)\n",
    "        except:\n",
    "            g_driver.get(\"http://google.com\")\n",
    "            search = g_driver.find_element_by_name('q')\n",
    "            search.send_keys(school_name)\n",
    "            search.send_keys(Keys.RETURN)\n",
    "            element = g_driver.find_elements_by_xpath('//*[@id=\"rso\"]/div[1]/div/div[1]/div/div/div[1]/a/div/cite')\n",
    "            for elm in element:\n",
    "                print(school_name)\n",
    "                url_name = elm.text\n",
    "                print(url_name)\n",
    "            url_list.append(url_name)\n",
    "            urls_df = urls.append(pd.DataFrame({'School Name': [school_name], 'URL': [url_name]}), ignore_index=True, sort = False)\n",
    "            g_driver.get(\"http://amazon.com\")\n",
    "            time.sleep(3)\n",
    "            g_driver.get(\"http://facebook.com\")    \n",
    "    urls.to_csv(create_path('University and College Websites update.csv'))\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston College\n",
      "http://bc.edu\n",
      "Suffolk University\n",
      "http://suffolk.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of Detroit Mercy School of Law\n",
      "www.law.udmercy.edu/\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Whittier Law School\n",
      "https://www.law.whittier.edu/\n",
      "University of Minnesota\n",
      "http://umn.edu\n",
      "Suffolk University\n",
      "http://suffolk.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of Washington Seattle\n",
      "https://www.washington.edu/\n",
      "West Virginia University\n",
      "http://wvu.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of San Francisco\n",
      "http://usfca.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "DePaul University\n",
      "http://depaul.edu\n",
      "Louisiana State University\n",
      "http://lsu.edu\n",
      "University of Missouri Kansas City\n",
      "http://umkc.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Connecticut\n",
      "http://uconn.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "Emory University\n",
      "http://emory.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Baylor University\n",
      "http://baylor.edu\n",
      "Catholic University\n",
      "https://www.catholic.edu/index.html\n",
      "University of Arizona\n",
      "http://arizona.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "Barry University\n",
      "http://barry.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Miami\n",
      "http://miami.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Florida Coastal Law School\n",
      "https://www.fcsl.edu/index.php\n",
      "Washington University St. Louis\n",
      "https://wustl.edu/\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Universities of Helsinki & Eastern Finland\n",
      "www.uef.fi/en/etusivu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "University of Kentucky\n",
      "www.uky.edu/\n",
      "Drexel University\n",
      "http://drexel.edu\n",
      "Case Western Reserve University\n",
      "http://case.edu\n",
      "University of Nebraska Lincoln\n",
      "https://www.unl.edu/\n",
      "Boston College\n",
      "http://bc.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Washington University St. Louis\n",
      "https://wustl.edu/\n",
      "University of Hawaii\n",
      "https://wustl.edu/\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of North Carolina Chapel Hill \n",
      "https://www.unc.edu/\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "Widener University Commonwealth\n",
      "https://commonwealthlaw.widener.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "Fordham University\n",
      "http://fordham.edu\n",
      "Cardozo Law School/Yeshiva University\n",
      "https://cardozo.yu.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "University of Idaho\n",
      "http://uidaho.edu\n",
      "University of Tulsa\n",
      "http://utulsa.edu\n",
      "Cumberland School of Law Samford University\n",
      "https://www.samford.edu/cumberlandlaw/\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Temple University\n",
      "http://temple.edu\n",
      "Southern Illinois University\n",
      "http://siu.edu\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "Louisiana State University\n",
      "http://lsu.edu\n",
      "Cleveland-Marshall College of Law\n",
      "https://www.law.csuohio.edu/\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "McGill University\n",
      "https://www.mcgill.ca/\n",
      "Creighton University\n",
      "http://creighton.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "Loyola Law School Los Angeles\n",
      "https://www.lls.edu/\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "University of Minnesota\n",
      "http://umn.edu\n",
      "Indiana University Indianapolis\n",
      "https://www.iupui.edu/\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "Universities of Helsinki & Eastern Finland\n",
      "www.uef.fi/en/etusivu\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "Emory University\n",
      "http://emory.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Pennsylvania State University Dickinson School of Law (Carlysle)\n",
      "https://dickinsonlaw.psu.edu/\n",
      "Valparaiso University\n",
      "http://valpo.edu\n",
      "Ava Maria School of Law\n",
      "https://www.avemarialaw.edu/\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "Brigham Young University\n",
      "http://byu.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of Minnesota\n",
      "http://umn.edu\n",
      "Southwestern Law School\n",
      "https://www.swlaw.edu/\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "Hofstra University\n",
      "http://hofstra.edu\n",
      "Hofstra University\n",
      "http://hofstra.edu\n",
      "University of Utah\n",
      "http://utah.edu\n",
      "University of Utah\n",
      "http://utah.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Marquette University\n",
      "http://marquette.edu\n",
      "Michigan State University\n",
      "http://msu.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Pace University\n",
      "http://pace.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "Harvard University \n",
      "https://www.harvard.edu/\n",
      "Cardozo Law School\n",
      "https://cardozo.yu.edu/\n",
      "Suffolk University\n",
      "http://suffolk.edu\n",
      "American University\n",
      "http://american.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Cardozo Law School\n",
      "https://cardozo.yu.edu/\n",
      "University of Oklahoma Norman\n",
      "www.ou.edu/\n",
      "Pace University\n",
      "http://pace.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Chicago-Kent College of Law\n",
      "www.uh.edu/\n",
      "Marquette University\n",
      "http://marquette.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "Hofstra University\n",
      "http://hofstra.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "Fordham University\n",
      "http://fordham.edu\n",
      "Michigan State University\n",
      "http://msu.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "Albany Law School\n",
      "https://www.albanylaw.edu/\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Indiana University Bloomington\n",
      "http://iub.edu\n",
      "University of Georgia\n",
      "http://uga.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of Maine\n",
      "http://umaine.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "Northwestern University \n",
      "https://www.northwestern.edu/\n",
      "Regent University\n",
      "http://regent.edu\n",
      "University of Oklahoma Norman\n",
      "www.ou.edu/\n",
      "Lewis & Clark College\n",
      "https://www.lclark.edu/\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Chicago-Kent College of Law\n",
      "www.uh.edu/\n",
      "Suffolk University\n",
      "http://suffolk.edu\n",
      "Boston University\n",
      "http://bu.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "American University\n",
      "http://american.edu\n",
      "Drake University\n",
      "http://drake.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Emory University\n",
      "http://emory.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "University of Kentucky\n",
      "www.uky.edu/\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "American University\n",
      "http://american.edu\n",
      "Ohio State University\n",
      "http://osu.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Rutgers University Camden\n",
      "https://www.camden.rutgers.edu/\n",
      "University of Minnesota Twin Cities\n",
      "https://twin-cities.umn.edu/\n",
      "University of Connecticut\n",
      "http://uconn.edu\n",
      "Wake Forest University\n",
      "http://wfu.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Santa Clara University\n",
      "http://scu.edu\n",
      "Texas Tech University\n",
      "http://ttu.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "University of Pittsburgh\n",
      "http://pitt.edu\n",
      "University of Notre Dame\n",
      "http://nd.edu\n",
      "Boston University\n",
      "http://bu.edu\n",
      "University of the Pacific McGeorge School of Law\n",
      "https://www.mcgeorge.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Connecticut\n",
      "http://uconn.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Columbia University \n",
      "https://www.columbia.edu/\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "Rutgers University Camden\n",
      "https://www.camden.rutgers.edu/\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "University of Missouri\n",
      "https://missouri.edu/\n",
      "University of Minnesota Twin Cities\n",
      "https://twin-cities.umn.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Melbourne\n",
      "https://www.unimelb.edu.au/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "DePaul University\n",
      "http://depaul.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Saint Louis University\n",
      "http://slu.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Yale University\n",
      "http://yale.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "College of William and Mary\n",
      "http://sandiego.edu\n",
      "University of Missouri Kansas City\n",
      "http://umkc.edu\n",
      "University of Cincinnati\n",
      "http://uc.edu\n",
      "University of Louisville\n",
      "louisville.edu/\n",
      "Creighton Universitiy\n",
      "https://www.creighton.edu/\n",
      "Pace University\n",
      "http://pace.edu\n",
      "University of Denver Sturm College of Law\n",
      "https://www.law.du.edu/\n",
      "Syracuse University\n",
      "http://syr.edu\n",
      "Vermont Law School\n",
      "http://vermontlaw.edu\n",
      "Ohio State University\n",
      "http://osu.edu\n",
      "Seattle University\n",
      "http://seattleu.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "Fordham University\n",
      "http://fordham.edu\n",
      "New York Law School\n",
      "http://fordham.edu\n",
      "Albany Law School\n",
      "https://www.albanylaw.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "American University\n",
      "http://american.edu\n",
      "John Marshall Law School (Atlanta) \n",
      "http://american.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of Richmond\n",
      "http://richmond.edu\n",
      "University of Connecticut\n",
      "http://uconn.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "University of Cincinnati\n",
      "http://uc.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "Loyola Law School Los Angeles\n",
      "https://www.lls.edu/\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Seton Hall University\n",
      "http://shu.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Amsterdam\n",
      "https://www.uva.nl/en\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "Seattle University\n",
      "http://seattleu.edu\n",
      "Ohio State University\n",
      "http://osu.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Rutgers University at Newark\n",
      "https://www.newark.rutgers.edu/\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "University of Mississippi\n",
      "https://olemiss.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "University of Wisconsin at Madison\n",
      "https://www.wisc.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "Southwestern Law School\n",
      "https://www.swlaw.edu/\n",
      "Albany Law School\n",
      "https://www.albanylaw.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "University of Tennessee\n",
      "https://www.utk.edu/\n",
      "University of Michigan\n",
      "http://umich.edu\n",
      "University of British Columbia\n",
      "https://www.ubc.ca/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Chapman University\n",
      "http://chapman.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "Case Western Reserve University\n",
      "http://case.edu\n",
      "McGeorge School of Law University of the Pacific\n",
      "https://www.mcgeorge.edu/\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Villanova University\n",
      "http://villanova.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Wisconsin Madison\n",
      "https://www.wisc.edu/\n",
      "University of Washington at Seattle\n",
      "https://www.washington.edu/\n",
      "University of Michigan\n",
      "http://umich.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "American University\n",
      "http://american.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "University of California at Los Angeles\n",
      "www.ucla.edu/\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Howard University\n",
      "http://howard.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "St. Thomas University (Florida) \n",
      "https://www.stu.edu/\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "American University\n",
      "http://american.edu\n",
      "Temple University\n",
      "http://temple.edu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University of Arkansas Fayetteville\n",
      "https://www.uark.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "University of Notre Dame\n",
      "http://nd.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Georgia\n",
      "http://uga.edu\n",
      "Marquette University\n",
      "http://marquette.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Golden Gate University\n",
      "https://www.ggu.edu/\n",
      "George Mason University\n",
      "http://gmu.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "University of Pittsburgh\n",
      "http://pitt.edu\n",
      "Drake University\n",
      "http://drake.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "George Mason University\n",
      "http://gmu.edu\n",
      "Fordham University\n",
      "http://fordham.edu\n",
      "University of Arkansas Fayetteville\n",
      "https://www.uark.edu/\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Indiana University Indianapolis\n",
      "https://www.iupui.edu/\n",
      "New York University\n",
      "http://nyu.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Dayton\n",
      "http://udayton.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "Rutgers University\n",
      "http://rutgers.edu\n",
      "University of Arizona\n",
      "http://arizona.edu\n",
      "University of Richmond\n",
      "http://richmond.edu\n",
      "Saint Louis University\n",
      "http://slu.edu\n",
      "University of Montana\n",
      "http://umt.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Rutgers University\n",
      "http://rutgers.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Northeastern University\n",
      "http://northeastern.edu\n",
      "Arizona State University\n",
      "http://asu.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "Pennsylvania State University University Park\n",
      "https://www.psu.edu/\n",
      "University of Georgia\n",
      "http://uga.edu\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Villanova University\n",
      "http://villanova.edu\n",
      "Indiana University Bloomington\n",
      "http://iub.edu\n",
      "Rutgers University\n",
      "http://rutgers.edu\n",
      "Washington & Lee University\n",
      "https://www.wlu.edu/\n",
      "University of Missouri Columbia\n",
      "https://missouri.edu/\n",
      "Northeastern University\n",
      "http://northeastern.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "University of Richmond\n",
      "http://richmond.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of Notre Dame\n",
      "http://nd.edu\n",
      "University of Hawaii\n",
      "https://wustl.edu/\n",
      "Yale University\n",
      "http://yale.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Yale University\n",
      "http://yale.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Arizona State University\n",
      "http://asu.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Tulane University\n",
      "http://tulane.edu\n",
      "University of Southern California\n",
      "http://usc.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Rutgers University\n",
      "http://rutgers.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Missouri Kansas City\n",
      "http://umkc.edu\n",
      "Georgia State University\n",
      "http://gsu.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Utah\n",
      "http://utah.edu\n",
      "Emory University\n",
      "http://emory.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "American University\n",
      "http://american.edu\n",
      "Syracuse University\n",
      "http://syr.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "Southern Methodist University\n",
      "http://smu.edu\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Chapman University\n",
      "http://chapman.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Villanova University\n",
      "http://villanova.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Loyola University Chicago\n",
      "http://luc.edu\n",
      "University of Georgia\n",
      "http://uga.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Missouri Columbia\n",
      "https://missouri.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Brooklyn Law School\n",
      "http://northwestern.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Hofstra University\n",
      "http://hofstra.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "Cardozo Law School\n",
      "https://cardozo.yu.edu/\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Missouri Columbia\n",
      "https://missouri.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Chicago-Kent College of Law\n",
      "www.uh.edu/\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Arizona State University\n",
      "http://asu.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Georgia State University\n",
      "http://gsu.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "University of North Carolina Chapel Hill\n",
      "https://www.unc.edu/\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Campbell University\n",
      "http://campbell.edu\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "Northeastern University\n",
      "http://northeastern.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Texas A&M University\n",
      "http://tamu.edu\n",
      "Boston University\n",
      "http://bu.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "University of Arkansas Fayetteville\n",
      "https://www.uark.edu/\n",
      "University of Arizona\n",
      "http://arizona.edu\n",
      "University of Utah\n",
      "http://utah.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Washington University St. Louis\n",
      "https://wustl.edu/\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "George Washington University\n",
      "https://www.gwu.edu/\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of Washington Seattle\n",
      "https://www.washington.edu/\n",
      "Brigham Young University\n",
      "http://byu.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "Florida International University\n",
      "http://fiu.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "Drexel University\n",
      "http://drexel.edu\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Boston College\n",
      "http://bc.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "Indiana University Indianapolis\n",
      "https://www.iupui.edu/\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Florida International University\n",
      "http://fiu.edu\n",
      "Arizona State University\n",
      "http://asu.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "Brigham Young University\n",
      "http://byu.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Tennessee\n",
      "https://www.utk.edu/\n",
      "McGill University\n",
      "https://www.mcgill.ca/\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "Chapman University\n",
      "http://chapman.edu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University of Minnesota Minneapolis-St. Paul\n",
      "https://twin-cities.umn.edu/\n",
      "Pepperdine University\n",
      "http://pepperdine.edu\n",
      "Michigan State University\n",
      "http://msu.edu\n",
      "Texas Tech University\n",
      "http://ttu.edu\n",
      "State University of New York Buffalo\n",
      "www.buffalo.edu/\n",
      "Vermont Law School\n",
      "http://vermontlaw.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "Pace University\n",
      "http://pace.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "Howard University\n",
      "http://howard.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "University of San Diego\n",
      "http://sandiego.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "University of Tennessee\n",
      "https://www.utk.edu/\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "University of Florida Gainesville\n",
      "www.ufl.edu/\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "University of Texas Austin\n",
      "https://www.utexas.edu/\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "University of Maryland\n",
      "http://umaryland.edu\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Stanford University\n",
      "http://stanford.edu\n",
      "University of North Texas\n",
      "http://unt.edu\n",
      "Yale University\n",
      "http://yale.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Northwestern University\n",
      "http://northwestern.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "University of Alabama\n",
      "http://ua.edu\n",
      "Georgia Institute of Technology\n",
      "http://gatech.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "University of California Davis\n",
      "http://ucdavis.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "Wayne State University\n",
      "https://wayne.edu/\n",
      "Harvard University\n",
      "http://harvard.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "McGill University\n",
      "https://www.mcgill.ca/\n",
      "University of Notre Dame\n",
      "http://nd.edu\n",
      "University of California Hastings\n",
      "https://www.uchastings.edu/\n",
      "Emory University\n",
      "http://emory.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "University of California Irvine\n",
      "http://uci.edu\n",
      "Loyola University Chicago\n",
      "http://luc.edu\n",
      "College of William & Mary\n",
      "https://wustl.edu/\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of Virginia\n",
      "http://virginia.edu\n",
      "University of Colorado Boulder\n",
      "http://colorado.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Florida State University\n",
      "http://fsu.edu\n",
      "Columbia University\n",
      "http://columbia.edu\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "Temple University\n",
      "http://temple.edu\n",
      "University of Houston\n",
      "www.uh.edu/\n",
      "University of Nevada Las Vegas\n",
      "http://unlv.edu\n",
      "University of New Hampshire\n",
      "http://unh.edu\n",
      "University of Illinois\n",
      "http://uillinois.edu\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "University of Chicago\n",
      "http://uchicago.edu\n",
      "Georgetown University\n",
      "http://georgetown.edu\n",
      "Emory University\n",
      "http://emory.edu\n",
      "University of California Los Angeles\n",
      "http://ucla.edu\n",
      "Duke University\n",
      "http://duke.edu\n",
      "Drexel University\n",
      "http://drexel.edu\n",
      "University of Iowa\n",
      "https://uiowa.edu/\n",
      "University of Pennsylvania\n",
      "http://upenn.edu\n",
      "Vanderbilt University\n",
      "http://vanderbilt.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "Cornell University\n",
      "http://cornell.edu\n",
      "New York University\n",
      "http://nyu.edu\n",
      "American University\n",
      "http://american.edu\n",
      "University of California Berkeley\n",
      "https://www.berkeley.edu/\n",
      "University of Akron\n",
      "https://www.uakron.edu/\n",
      "Yale University\n",
      "http://yale.edu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>School</th>\n",
       "      <th>School URL</th>\n",
       "      <th>New School</th>\n",
       "      <th>New School URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Albert</td>\n",
       "      <td>NA</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>http://bc.edu</td>\n",
       "      <td>University of Texas, Austin</td>\n",
       "      <td>https://www.utexas.edu/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hilary</td>\n",
       "      <td>Allen</td>\n",
       "      <td>NA</td>\n",
       "      <td>Suffolk University</td>\n",
       "      <td>http://suffolk.edu</td>\n",
       "      <td>American University</td>\n",
       "      <td>http://american.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Olufunmilayo</td>\n",
       "      <td>Arewa</td>\n",
       "      <td>NA</td>\n",
       "      <td>University of California, Irvine</td>\n",
       "      <td>http://uci.edu</td>\n",
       "      <td>Temple University</td>\n",
       "      <td>http://temple.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khaled A.</td>\n",
       "      <td>Beydoun</td>\n",
       "      <td>NA</td>\n",
       "      <td>University of Detroit Mercy School of Law</td>\n",
       "      <td>www.law.udmercy.edu/</td>\n",
       "      <td>University of Arkansas, Fayetteville</td>\n",
       "      <td>https://www.uark.edu/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joshua</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NA</td>\n",
       "      <td>New York University</td>\n",
       "      <td>http://nyu.edu</td>\n",
       "      <td>University of California, Irvine</td>\n",
       "      <td>http://uci.edu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     First Name Last Name Title                                     School  \\\n",
       "0       Richard    Albert    NA                             Boston College   \n",
       "1        Hilary     Allen    NA                         Suffolk University   \n",
       "2  Olufunmilayo     Arewa    NA           University of California, Irvine   \n",
       "3     Khaled A.   Beydoun    NA  University of Detroit Mercy School of Law   \n",
       "4        Joshua     Blank    NA                        New York University   \n",
       "\n",
       "             School URL                            New School  \\\n",
       "0         http://bc.edu           University of Texas, Austin   \n",
       "1    http://suffolk.edu                   American University   \n",
       "2        http://uci.edu                     Temple University   \n",
       "3  www.law.udmercy.edu/  University of Arkansas, Fayetteville   \n",
       "4        http://nyu.edu      University of California, Irvine   \n",
       "\n",
       "            New School URL  \n",
       "0  https://www.utexas.edu/  \n",
       "1      http://american.edu  \n",
       "2        http://temple.edu  \n",
       "3    https://www.uark.edu/  \n",
       "4           http://uci.edu  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list = get_school_urls(urls, new_data['School'])\n",
    "new_data.insert(4, \"School URL\", url_list) \n",
    "print('First half complete')\n",
    "url_list = get_school_urls(urls, new_data['New School'])\n",
    "new_data.insert(6, \"New School URL\", url_list) \n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornell Law School.csv\n",
      "File for Gregory Alexander has already been created.\n",
      "cornell in: John J. Barceló III - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_john_barcelo.cfm\n",
      "cornell in: John J. Barceló III - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_john_barcelo.cfm\n",
      "['']\n",
      "No remaining pages to scrape for John J. Barcelo.\n",
      "['Barcelo, John J.', 'Barcelo, Juliette', 'Barcelo, Maria Julia', 'Barcelo, Rafael Ramis', 'Barcelo, Rosa', 'Julia-Barcelo, Rosa', 'Ramis Barcelo, Rafael', 'Ramis-Barcelo, Rafael', 'Romero-Barcelo, Carlos', 'Acree, John Cabel III', 'Alden, John F. III', 'Astley, John III', 'Bailey, John H. III', 'Bales, John F. III', 'Banas, John S. III', 'Banzhaf, John F. III', 'Banzhaf, John R. III', 'Barnhardt, John J. III', 'Barrett, John J. III', 'Barry, John F. III', 'Show more names']\n",
      "John J. Barcelo\n",
      "No remaining pages to scrape for John J. III Barcelo.\n",
      "cornell in: John H. Blume - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_John_Blume.cfm\n",
      "['Blume, John', 'Blume, John H. III', 'Blume Fortini, Ernesto', 'Blume, Alan L.', 'Blume, Alexander', 'Blume, Benjamin A.', 'Blume, Daniel', 'Blume, Fred H.', 'Blume, George O.', 'Blume, Joshua D.', 'Blume, Judy', 'Blume, Lawrence', 'Blume, Lawrence E.', 'Blume, Lawrence J.', 'Blume, Marshall E.', 'Blume, Michael B.', 'Blume, Michael S.', 'Blume, Norman', 'Blume, Paul C.', 'Blume, Peter', 'Show more names']\n",
      "John Blume\n",
      "cornell in: John H. Blume - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_John_Blume.cfm\n",
      "John H. III Blume\n",
      "No remaining pages to scrape for John H. Blume.\n",
      "['Blume, John H.', 'Blume, John H. III', 'Blume Fortini, Ernesto', 'Blume, Alan L.', 'Blume, Alexander', 'Blume, Benjamin A.', 'Blume, Daniel', 'Blume, Fred H.', 'Blume, George O.', 'Blume, Joshua D.', 'Blume, Judy', 'Blume, Lawrence', 'Blume, Lawrence E.', 'Blume, Lawrence J.', 'Blume, Marshall E.', 'Blume, Michael B.', 'Blume, Michael S.', 'Blume, Norman', 'Blume, Paul C.', 'Blume, Peter', 'Show more names']\n",
      "John H. Blume\n",
      "John H. III Blume\n",
      "No remaining pages to scrape for John Blume.\n",
      "['']\n",
      "No remaining pages to scrape for John H. III Blume.\n",
      "cornell in: Cynthia Grant Bowman - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Cynthia_Bowman.cfm\n",
      "['Grant Bowman, Cynthia', 'Grant, Christopher Grant', 'Grant, Cynthia', 'Shoenberger, Cynthia Grant', 'Bowman', 'Bowman, Adddison M. III', 'Bowman, Addison M.', 'Bowman, Addison M. III', 'Bowman, Alana', 'Bowman, Alfred Connor', 'Bowman, Andrew', 'Bowman, Andy', \"Bowman, Ann O'M.\", 'Bowman, Austin', 'Bowman, Blair', 'Bowman, Blythe Alison', 'Bowman, Bradford', 'Bowman, Bradford Jay', 'Bowman, Brandt T.', 'Bowman, Brian M.', 'Show more names']\n",
      "Cynthia Grant Bowman\n",
      "No remaining pages to scrape for Cynthia Grant Bowman.\n",
      "cornell in: Josh Chafetz - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Josh_Chafetz.cfm\n",
      "['Chafetz, Eric', 'Chafetz, Janet S.', 'Chafetz, Janet Saltzman', 'Chafetz, Marc E.', 'Chafetz, Marc Edward', 'Adams, Josh', 'Albin, Josh', 'Andrews, Josh', 'Archambault, Josh', 'Ard Josh', 'Ard, Josh', 'Ard, W. Josh', 'Ard, William Josh', 'Ashley, Josh', 'Baker, Josh', 'Baskin, Josh', 'Bendor, Josh', 'Benson, Josh', 'Bernstein, Josh', 'Berry, Josh', 'Show more names']\n",
      "No remaining pages to scrape for Josh Chafetz.\n",
      "cornell in: Kevin M. Clermont - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Kevin_Clermont.cfm\n",
      "['Clermont, Andre J.', 'Clermont, Andre-J.', 'Clermont, Bernard-L', 'Clermont, Fabrizio', 'Clermont, Woody R.', 'Clermont, Yvan', 'Goldschmidt-Clermont, Luisella', 'Aalto, Kevin', 'Abbott, Kevin C.', 'Abel, Kevin', 'Abel, Kevin M.', 'Abernathy, Michael Kevin', 'Abikoff, Kevin T.', 'Abrams, Kevin G.', 'Abrams, Kevin R.', 'Acklin, Kevin B.', 'Adam, Kevin C.', 'Adams, Kevin', 'Afghani, Kevin', 'Ainsworth, Kevin N.', 'Show more names']\n",
      "No remaining pages to scrape for Kevin M. Clermont.\n",
      "cornell in: Sherry F. Colb - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Sherry_Colb.cfm\n",
      "['Aarons, Sherry A.', 'Atkinson, Sherry S.', 'Avery, Sherry', 'Barnash, Sherry M.', 'Bartley, Sherry Perkins', 'Bartz-Marvez, Sherry', 'Batzer, Sherry L.', 'Bawa, Sherry', 'Betts, Sherry C.', 'Bosse, Sherry L.', 'Bragg, Sherry L.', 'Brandt-Rauf, Sherry Iris', 'Broder, Sherry', 'Broder, Sherry P.', 'Brown, Sherry', 'Cable, Sherry', 'Caloia, Sherry A.', 'Cannon, Sherry Capps', 'Cermak, Sherry', 'Clegg, Sherry E.', 'Show more names']\n",
      "No remaining pages to scrape for Sherry F. Colb.\n",
      "cornell in: Michael C. Dorf - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_michael_dorf.cfm\n",
      "cornell in: Michael C. Dorf - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_michael_dorf.cfm\n",
      "['']\n",
      "No remaining pages to scrape for Michael Dorf.\n",
      "['Dorf, Michael', 'Dorf, Eric H.', 'Dorf, Nicholas', 'Dorf, Paul A.', 'Dorf, Robert C.', 'Michael, Michael', 'Michael, Michael L.', 'Aamodt, Michael G.', 'Aaron, Michael P.', 'Abaramowicz, Michael', 'Abate, Michael P.', 'Abatemarco, Michael J.', 'Abbell, Michael', 'Abbey, Michael H.', 'Abbott, C. Michael', 'Abbott, J. Michael', 'Abbott, Michael', 'Abbott, Michael P.', 'Abcarian, Michael', 'Abcarian, Michael V.', 'Show more names']\n",
      "Michael Dorf\n",
      "No remaining pages to scrape for Michael C. Dorf.\n",
      "cornell in: Cynthia R. Farina - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_cynthia_farina.cfm\n",
      "cornell in: Cynthia R. Farina - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Cynthia_Farina.cfm\n",
      "['Farina, Cynthia R.', 'Farina, Amerigo', 'Farina, Anne Judith', 'Farina, Elizabeth M. M. Q.', 'Farina, Hector', 'Farina, Joseph B.', 'Farina, Joseph P.', 'Farina, Marco', 'Farina, Margherita', 'Farina, Susan H.', 'Farina, Susan Hanmer', 'Gross-Farina, Sally', 'Mendelson, Farina', 'Pedraza-Farina, Laura', 'Pedraza-Farina, Laura G.', 'Abson, Cynthia', 'Acree, Cynthia L.', 'Adams, Cynthia', 'Adams, Cynthia Trimboli', 'Adcock, Cynthia F.', 'Show more names']\n",
      "Cynthia R. Farina\n",
      "No remaining pages to scrape for Cynthia Farina.\n",
      "['Farina, Cynthia', 'Farina, Amerigo', 'Farina, Anne Judith', 'Farina, Elizabeth M. M. Q.', 'Farina, Hector', 'Farina, Joseph B.', 'Farina, Joseph P.', 'Farina, Marco', 'Farina, Margherita', 'Farina, Susan H.', 'Farina, Susan Hanmer', 'Gross-Farina, Sally', 'Mendelson, Farina', 'Pedraza-Farina, Laura', 'Pedraza-Farina, Laura G.', 'Abson, Cynthia', 'Acree, Cynthia L.', 'Adams, Cynthia', 'Adams, Cynthia Trimboli', 'Adcock, Cynthia F.', 'Show more names']\n",
      "Cynthia Farina\n",
      "No remaining pages to scrape for Cynthia R. Farina.\n",
      "cornell in: Stephen P. Garvey - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Stephen_Garvey.cfm\n",
      "['Algero, Mary Garvey', 'Garvey, Ashleigh', 'Garvey, Bernard F.', 'Garvey, Caitlin', 'Garvey, Catherine', 'Garvey, Charlotte', 'Garvey, Daniel E.', 'Garvey, Denise P.', 'Garvey, Donald B.', 'Garvey, Ed', 'Garvey, Edward R.', 'Garvey, Elliot', 'Garvey, George E.', 'Garvey, Gerald', 'Garvey, Gregg', 'Garvey, Jack I.', 'Garvey, Jackson T.', 'Garvey, James V.', 'Garvey, Jane F.', 'Garvey, Joe', 'Show more names']\n",
      "No remaining pages to scrape for Stephen P. Garvey.\n",
      "cornell in: Robert A. Green - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_robert_green.cfm\n",
      "['Green, Robert A.', 'Green, Robert C.', 'Green, Robert E.', 'Green, Robert G.', 'Green, Robert H.', 'Green, Robert L.', 'Green, Robert M.', 'Green, Robert S.', 'Green, Robert W.', 'Ahmanson, Roberta Green', 'Bae, Green', 'Burnett, Catherine Green', 'Camden, Bonnie Green', 'Caplan, Emily Green', 'Carias-Green, Gabriela', 'Coleman, Llezlie Green', 'Connor-Green, Devon S.', 'Cumston, Charles Green', 'Davis, Jane Green', 'Denyer-Green, B. P. D.', 'Show more names']\n",
      "Robert A. Green\n",
      "cornell in: Robert A. Green - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_robert_green.cfm\n",
      "Robert C. Green\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert E. Green\n",
      "Robert G. Green\n",
      "Robert H. Green\n",
      "Robert L. Green\n",
      "Robert M. Green\n",
      "Robert S. Green\n",
      "Robert W. Green\n",
      "Roberta Green Ahmanson\n",
      "No remaining pages to scrape for Robert Green.\n",
      "['Green, Robert', 'Green, Robert C.', 'Green, Robert E.', 'Green, Robert G.', 'Green, Robert H.', 'Green, Robert L.', 'Green, Robert M.', 'Green, Robert S.', 'Green, Robert W.', 'Ahmanson, Roberta Green', 'Bae, Green', 'Burnett, Catherine Green', 'Camden, Bonnie Green', 'Caplan, Emily Green', 'Carias-Green, Gabriela', 'Coleman, Llezlie Green', 'Connor-Green, Devon S.', 'Cumston, Charles Green', 'Davis, Jane Green', 'Denyer-Green, B. P. D.', 'Show more names']\n",
      "Robert Green\n",
      "Robert C. Green\n",
      "Robert E. Green\n",
      "Robert G. Green\n",
      "Robert H. Green\n",
      "Robert L. Green\n",
      "Robert M. Green\n",
      "Robert S. Green\n",
      "Robert W. Green\n",
      "Roberta Green Ahmanson\n",
      "No remaining pages to scrape for Robert A. Green.\n",
      "cornell in: James Grimmelmann - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_james_grimmelmann.cfm\n",
      "['James, James B.', 'Aaron, James', 'Abadie, James F.', 'Abbo, James J.', 'Abbott, James', 'Abbott, James Putnam', 'Abbott, James W.', 'Abbott, James W. Jr.', 'Abdey, James S.', 'Abe, James', 'Abegglen, James C.', 'Abell, James', 'Abell, James E.', 'Abell, James E., III', 'Abeltin, James B.', 'Abernethy, James J.', 'Abourezk, James', 'Abourezk, James G.', 'Abrams, James D.', 'Abston, James B.', 'Show more names']\n",
      "No remaining pages to scrape for James Grimmelmann.\n",
      "cornell in: Valerie Hans - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Valerie_Hans.cfm\n",
      "0k\n",
      "['Acerra, Valerie', 'Acoff, Valerie L.', 'Adams, Valerie', 'Aggerbeck, Valerie', 'Alabanza, Valerie S.', 'Alter, Valerie', 'Alter, Valerie E.', 'Artzt, Valerie J.', 'Auger, Valerie', 'Aumage, Valerie', 'Baadh, Valerie', 'Baker, Valerie', 'Baker, Valerie L.', 'Barker, Valerie', 'Barney, Valerie', 'Barney, Valerie H.', 'Barth, Valerie L.', 'Barton, Valerie D.', 'Barton, Valerie L.', 'Beaudoin, Valerie', 'Show more names']\n",
      "No remaining pages to scrape for Valerie P. Hans.\n",
      "cornell in: George A. Hay - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_George_Hay.cfm\n",
      "['Hay, George', 'Kain, George Hay Jr.', 'Hay, A. G.', 'Hay, A.L. Baron', 'Hay, Alexandre', 'Hay, Andrew', 'Hay, Ashley E.', 'Hay, Brandin', 'Hay, Bruce', 'Hay, Bruce L.', 'Hay, Carter', 'Hay, Charles L.', 'Hay, Charles M.', 'Hay, Clarence T.', 'Hay, Colin', 'Hay, Daniel J.', 'Hay, Deborah', 'Hay, Derald J.', 'Hay, Diane', 'Hay, Donald G.', 'Show more names']\n",
      "George Hay\n",
      "cornell in: George A. Hay - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_George_Hay.cfm\n",
      "George Hay Jr. Kain\n",
      "No remaining pages to scrape for George A. Hay.\n",
      "['Hay, George A.', 'Kain, George Hay Jr.', 'Hay, A. G.', 'Hay, A.L. Baron', 'Hay, Alexandre', 'Hay, Andrew', 'Hay, Ashley E.', 'Hay, Brandin', 'Hay, Bruce', 'Hay, Bruce L.', 'Hay, Carter', 'Hay, Charles L.', 'Hay, Charles M.', 'Hay, Clarence T.', 'Hay, Colin', 'Hay, Daniel J.', 'Hay, Deborah', 'Hay, Derald J.', 'Hay, Diane', 'Hay, Donald G.', 'Show more names']\n",
      "George A. Hay\n",
      "George Hay Jr. Kain\n",
      "No remaining pages to scrape for George Hay.\n",
      "cornell in: Michael Heise - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Michael_Heise.cfm\n",
      "['Heise, Cathryn Mitchell', 'Heise, David', 'Heise, David R.', 'Heise, Herman A.', 'Heise, Jack', 'Heise, James Todd', 'Heise, John I. Jr.', 'Heise, Lori L.', 'Heise, Mary K.', 'Heise, Matthew C.', 'Heise, Miriam', 'Heise, Nicole A.', 'Heise, Steve', 'Michael, Michael', 'Michael, Michael L.', 'Aamodt, Michael G.', 'Aaron, Michael P.', 'Abaramowicz, Michael', 'Abate, Michael P.', 'Abatemarco, Michael J.', 'Show more names']\n",
      "No remaining pages to scrape for Michael Heise.\n",
      "cornell in: Robert A. Hillman - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Robert_Hillman.cfm\n",
      "cornell in: Robert A. Hillman - Cornell Law School - Cornell University\n",
      "https://www.lawschool.cornell.edu/faculty/bio_Robert_Hillman.cfm\n",
      "0k\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5f5ab00f0175>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mdf_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#Search by author to find potential alternative first and middle names:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mfm_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_fm_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmid_first_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschool_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfm_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Name '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfull_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' was not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a11f88671485>\u001b[0m in \u001b[0;36msearch_names\u001b[1;34m(mid_first_name, last_name, school_url)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mlink_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfirst_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlink_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlast_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlink_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'['\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlink_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mtext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;34m\"\"\"The text of the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_ELEMENT_TEXT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     66\u001b[0m             return self.request_encode_url(method, url, fields=fields,\n\u001b[0;32m     67\u001b[0m                                            \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                                            **urlopen_kw)\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             return self.request_encode_body(method, url, fields=fields,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'?'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     def request_encode_body(self, method, url, fields=None, headers=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1331\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "stats = ['Cited by Cases','Cited by Articles','Accessed (Past 12 Months)','Cited by Articles (Past 10 Years)', 'Cited by Articles (Past 1-2 years)', 'ScholarCheck Rank', 'Average Citations per Article', 'Average Citations per Document', 'Self-Citations']\n",
    "path = os.path.join(os.getcwd(), 'school_data')\n",
    "files = os.listdir(path)\n",
    "school_url = 'cornell'\n",
    "school_name = 'cornell'\n",
    "delay = 5\n",
    "current_papers = os.listdir(create_path('author_papers'))\n",
    "current_stats = os.listdir(create_path('school_stats'))\n",
    "current_skip = os.listdir(create_path('skipped_names'))\n",
    "for file in files[4:5]:\n",
    "    print(file)\n",
    "    main_df = pd.DataFrame()\n",
    "    file1 = check_df(current_stats, school_name)\n",
    "    if file1 != '':\n",
    "        main_df = pd.read_csv(create_path('school_stats', file1))\n",
    "    skip_df = pd.DataFrame(columns = ['Full Name', 'School'])\n",
    "    file2 = check_df(current_skip, school_name)\n",
    "    if file2 != '':\n",
    "        skip_df = pd.read_csv(create_path('skipped_names', file2))\n",
    "    data = pd.read_csv(os.path.join(os.getcwd(), 'school_data', file))   \n",
    "    for i in range(len(data)):\n",
    "        #Get name and information from the database\n",
    "        mid_first_name = data['First Name'][i]\n",
    "        last_name = data['Last Name'][i]\n",
    "        full_name = mid_first_name + ' ' +  last_name\n",
    "        done = check_files(mid_first_name, last_name, current_papers)\n",
    "        if done:\n",
    "            print('File for ' + full_name + ' has already been created.')\n",
    "            continue\n",
    "        school = data['School'][i]\n",
    "        title = data['Title'][i]\n",
    "        page_name = []\n",
    "        err_fm_names = []\n",
    "        df_sub = pd.DataFrame()\n",
    "        #Search by author to find potential alternative first and middle names:\n",
    "        fm_names, err_fm_names = search_names(mid_first_name, last_name, school_url)\n",
    "        if not fm_names:\n",
    "            print('Name ' + full_name + ' was not found')\n",
    "            skip_df = skip_df.append(pd.DataFrame([[full_name, school, title]], columns = ['Full Name', 'School', 'Title']))\n",
    "            \n",
    "        for fm_name in fm_names:\n",
    "            link = 'https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=' + last_name +  '%2C ' + fm_name + '&collection=journals'\n",
    "            driver.get(link)\n",
    "            soup=bs.BeautifulSoup(driver.page_source, 'lxml')\n",
    "            table_rows = soup.findAll('td', {'style': 'text-align:right;'})\n",
    "            full_name = fm_name + ' ' +  last_name\n",
    "            webpage_wait('//*[@id=\"page_content\"]/div[1]/div/div[1]/div[1]')\n",
    "            fm_names, err_fm_names = similar_names(fm_names, err_fm_names, fm_name, last_name)\n",
    "            cur_page = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[1]/div[1]').text\n",
    "            if not table_rows:\n",
    "                got_page = False\n",
    "                new_names = False\n",
    "                link_index = 1\n",
    "                while new_names == False:\n",
    "                    try:\n",
    "                        if link_index == 1:\n",
    "                            element =driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[2]/div/ul/li/a')\n",
    "                        else: \n",
    "                            element =driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[2]/div/ul/li[' + str(link_index) + ']/a')            \n",
    "                        new_fm_name = element.text.split(', ')[1]\n",
    "                        new_last_name = element.text.split(', ')[0]\n",
    "                        if last_name == new_last_name and mid_first_name in new_fm_name:\n",
    "                            if not new_fm_name in fm_names:\n",
    "                                check_google(new_fm_name, last_name, school_url)\n",
    "                                fm_names.append(new_fm_name)\n",
    "                            \n",
    "                    except: \n",
    "                        new_names = True\n",
    "                        got_page = True\n",
    "                        if not scraped_papers:\n",
    "                            print('Name ' + full_name + ' is not in the database. You may be missing a middle initial.')\n",
    "                            skip_df = skip_df.append(pd.DataFrame([[full_name, school, title]], columns = ['Full Name', 'School', 'Title']))\n",
    "                        else:\n",
    "                            print('No remaining pages to scrape from {}.'.format(full_name))\n",
    "                    link_index += 1\n",
    "                    \n",
    "            elif table_rows and cur_page not in page_name: \n",
    "                element = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[2]')\n",
    "                table_element = element.text.split('\\n')\n",
    "                number_list = []\n",
    "                rank_list = []\n",
    "                stat_list = []\n",
    "                for stat in stats:\n",
    "                    find_index = [table_element.index(s) for s in table_element if stat == s]\n",
    "                    if find_index:\n",
    "                        my_list = table_element[find_index[0]+1].split(' ')\n",
    "                        number_list.append(my_list[0])\n",
    "                        stat_list.append(stat)\n",
    "                        if len(my_list) > 1:\n",
    "                            rank_list.append(my_list[-1])\n",
    "                    if stat == 'Self-Citations':\n",
    "                        find_index = [table_element.index(s) for s in table_element if stat in s]\n",
    "                        if find_index:\n",
    "                            stat_list.append(stat)\n",
    "                            number_list.append(table_element[find_index[0]].split(' ')[1])\n",
    "                zip_number_list = list(zip(stat_list, number_list))\n",
    "                zip_rank_list = list(zip(stat_list, rank_list))\n",
    "                number_dict = create_dataframe_dict(zip_number_list)\n",
    "                rank_dict = create_dataframe_dict(zip_rank_list)\n",
    "                df_number = pd.DataFrame.from_dict(number_dict, orient='index').transpose()\n",
    "                df_rank = pd.DataFrame.from_dict(rank_dict, orient='index').transpose()\n",
    "                df_number = df_number.replace('na', '0')\n",
    "                df_number = df_number.replace('', '0')\n",
    "                df_number = df_number.replace(' ', '0')\n",
    "                df_number = remove_commas(df_number)\n",
    "                df_number = df_number.astype(float)\n",
    "                if df_sub.empty:\n",
    "                    df_sub = df_number\n",
    "                else: \n",
    "                    df_sub = df_sub.add(df_number)\n",
    "                \n",
    "                title_index = 3\n",
    "                stats_index = 4\n",
    "                topic_index = 0\n",
    "                topic_div_index = 0\n",
    "                topic_array = soup.findAll('div', {'class': 'topics'})\n",
    "                element = title_index\n",
    "                df = pd.DataFrame(columns = ['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics'])\n",
    "                while element:\n",
    "                    data_stream = []\n",
    "                    x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                    element = driver.find_elements_by_xpath(x_path_title)\n",
    "                    #Get title:\n",
    "                    if element:\n",
    "                        scraped_papers = True\n",
    "                        for elm in element:\n",
    "                            data_stream.append(elm.text)\n",
    "\n",
    "                        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]')\n",
    "                        for elm in element:\n",
    "                            my_list = elm.text\n",
    "                        if [a for a in my_list.split('\\n') if last_name in a]:   \n",
    "                            data_stream.append([a for a in my_list.split('\\n') if last_name in a][0])\n",
    "                        else:\n",
    "                            data_stream.append('na')\n",
    "                        if [a for a in my_list.split('\\n') if 'Vol.' in a]:\n",
    "                            data_stream.append([a for a in my_list.split('\\n') if 'Vol.' in a][0])\n",
    "                        else:\n",
    "                            data_stream.append('na')\n",
    "                        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(stats_index) + ']/div[2]/div')\n",
    "                        for elm in element:\n",
    "                            cited_text = elm.text\n",
    "                        article_citations = 'na'\n",
    "                        case_citations = 'na'\n",
    "                        accessed = 'na'\n",
    "                        if not isinstance(cited_text, list):\n",
    "                            cited_text = cited_text.split('\\n')\n",
    "                            cited_text\n",
    "                            for stat in cited_text:\n",
    "                                if 'Article' in stat:\n",
    "                                    article_citations = int(re.search(r'\\d+', stat).group())\n",
    "                                if 'Case' in stat:\n",
    "                                    case_citations = int(re.search(r'\\d+', stat).group())\n",
    "                                if 'Accessed' in stat:\n",
    "                                    accessed = int(re.search(r'\\d+', stat).group())\n",
    "                        data_stream.append(article_citations)\n",
    "                        data_stream.append(case_citations)\n",
    "                        data_stream.append(accessed)\n",
    "                        if 'Topics:' in my_list:\n",
    "                            data_stream.append(topic_array[topic_div_index].text.split(':')[1])\n",
    "                            topic_div_index +=1\n",
    "                        else:\n",
    "                            data_stream.append('na')\n",
    "                        df = df.append(pd.DataFrame([data_stream], columns = ['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']))\n",
    "                        stats_index +=4\n",
    "                        title_index += 4\n",
    "                        page_name.append(cur_page)\n",
    "                        #Check that next paper exists:\n",
    "                        x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "                        element = driver.find_elements_by_xpath(x_path_title)\n",
    "                df.to_csv(create_path('author_papers', '{}_{}_papers.csv'.format(full_name, school)))\n",
    "                time.sleep(3)\n",
    "            print('No remaining pages to scrape for {}.'.format(fm_name + ' ' + last_name))  \n",
    "        if not df_sub.empty:\n",
    "            my_dict = {'Person': [full_name], 'School': [school], 'Type': ['number']}\n",
    "            name_data = pd.DataFrame(my_dict)\n",
    "            df_sub = pd.concat([name_data, df_sub], sort = False, axis = 1)\n",
    "            main_df = pd.concat([main_df, df_sub], sort = False)\n",
    "            main_df.replace(0, 'na')\n",
    "            main_df.to_csv(create_path('school_stats', '{}_stats.csv'.format(school)))                \n",
    "        skip_df.to_csv(create_path('skipped_names', '{}_skipped.csv'.format(school)))\n",
    "                    \n",
    "skip_df.to_csv(create_path('skipped_names', '{}_skipped.csv'.format(school)))\n",
    "main_df.replace(0, 'na')\n",
    "main_df.to_csv(create_path('school_stats', '{}_stats.csv'.format(school)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Categoricalism and Balancing in First and Second Amendment Analysis [article]', 'Blocher, Joseph (Cited 581 times)', 'New York University Law Review , Vol. 84, Issue 2 (May 2009), pp. 375-439', 89, 16, 49, ' First Amendment, Second Amendment']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Institutions in the Marketplace of Ideas [article]', 'Blocher, Joseph (Cited 581 times)', 'Duke Law Journal , Vol. 57, Issue 4 (February 2008), pp. 821-890', 88, 'na', 26, ' Constitutional Law, Economics, Jurisprudence']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Viewpoint Neutrality and Government Speech [article]', 'Blocher, Joseph (Cited 581 times)', 'Boston College Law Review, Vol. 52, Issue 3 (May 2011), pp. 695-768', 57, 2, 22, ' First Amendment']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Firearm Localism [article]', 'Blocher, Joseph (Cited 581 times)', 'Yale Law Journal, Vol. 123, Issue 1 (October 2013), pp. 82-147', 49, 4, 55, ' Jurisdiction, Second Amendment, Technology, First Amendment']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Reverse Incorporation of State Constitutional Law [article]', 'Blocher, Joseph (Cited 581 times)', 'Southern California Law Review, Vol. 84, Issue 2 (January 2011), pp. 323-386', 36, 1, 30, ' Constitutional Law, Incorporation, State and Local Government Law, Constitutional Rights']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['The Right Not to Keep or Bear Arms [article]', 'Blocher, Joseph (Cited 581 times)', 'Stanford Law Review, Vol. 64, Issue 1 (January 2012), pp. 1-54', 33, 2, 43, ' Second Amendment, Judges']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "[\"School Naming Rights and the First Amendment's Perfect Storm [article]\", 'Blocher, Joseph (Cited 581 times)', 'Georgetown Law Journal, Vol. 96, Issue 1 (November 2007), pp. 1-58', 29, 'na', 26, ' Education, First Amendment, Contracts, Law and Society, Taxation-Federal Income']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Rights to and Not To [article]', 'Blocher, Joseph (Cited 581 times)', 'California Law Review, Vol. 100, Issue 4 (August 2012), pp. 761-816', 26, 'na', 30, ' Constitutional Law, Jurisprudence, First Amendment, Military Law']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Combatant Status Review Tribunals: Flawed Answers to the Wrong Question [comments]', 'Blocher, Joseph (Cited 581 times)', 'Yale Law Journal, Vol. 116, Issue 3 (December 2006), pp. 667-675', 24, 'na', 10, ' States, Due Process, National Security']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Popular Constitutionalism and the State Attorneys General [comments]', 'Blocher, Joseph (Cited 581 times)', 'Harvard Law Review Forum, Vol. 122, pp. 108-115', 17, 'na', 6, ' Attorneys, Attorneys General, General, Evidence, Health, Health Law, Legal Profession, Public Health, Tobacco']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Nonsense and the Freedom of Speech: What Meaning Means for the First Amendment [article]', 'Blocher, Joseph (Cited 581 times)', 'Duke Law Journal, Vol. 63, Issue 7 (April 2014), pp. 1423-1482', 15, 'na', 7, ' First Amendment, Freedom of Speech, Commercial Speech, History, Constitutional Law']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Amending the Exceptions Clause [article]', 'Blocher, Joseph (Cited 581 times)', 'Minnesota Law Review, Vol. 92, Issue 4 (April 2008), pp. 971-1030', 13, 'na', 1, ' Constitutional Law, Jurisdiction, Legal Profession, Courts, President/Executive Department']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Gun Rights Talk [article]', 'Blocher, Joseph (Cited 581 times)', 'Boston University Law Review, Vol. 94, Issue 3 (May 2014), pp. 813-834', 13, 'na', 199, ' Second Amendment']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['What Is Gun Control: Direct Burdens, Incidental Burdens, and the Boundaries of the Second Amendment [article]', 'Blocher, Joseph (Cited 581 times); Miller, Darrell A. H. (Cited 268 times)', 'University of Chicago Law Review, Vol. 83, Issue 1 (Winter 2016), pp. 295-356', 12, 'na', 141, ' Boundaries, Second Amendment, Judicial Review, Constitutional Law, Jurisprudence']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Government Property and Government Speech [article]', 'Blocher, Joseph (Cited 581 times)', 'William and Mary Law Review, Vol. 52, Issue 5 (April 2011), pp. 1413-1482', 11, 'na', 9, ' Government, Property']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Building on Custom: Land Tenure Policy and Economic Development in Ghana [notes]', 'Blocher, Joseph (Cited 581 times)', 'Yale Human Rights & Development Law Journal, Vol. 9, pp. 166-202', 8, 'na', 17, ' Comparative Law, Economic Development, Economics']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Selling State Borders [article]', 'Blocher, Joseph (Cited 581 times)', 'University of Pennsylvania Law Review, Vol. 162, Issue 2 (January 2014), pp. 241-306', 7, 'na', 8, ' International Law, Politics, Immigration Law, Military Law, Military, War and Peace']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Competing for Refugees: A Market-Based Solution to a Humanitarian Crisis [article]', 'Blocher, Joseph (Cited 581 times); Gulati, Mitu (Cited 1596 times)', 'Columbia Human Rights Law Review, Vol. 48, Issue 1 (Fall 2016), pp. 53-111', 5, 'na', 90, ' Immigration Law, Refugees, Human Rights Law, Military, War and Peace, Remedies, Photographs']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['From Theory to Doctrine: An Empirical Analysis of the Right to Keep and Bear Arms after Heller [article]', 'Ruben, Eric (Cited 5 times); Blocher, Joseph (Cited 581 times)', 'Duke Law Journal, Vol. 67, Issue 7 (April 2018), pp. 1433-1510', 5, 2, 87, ' Second Amendment, First Amendment']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Public Discourse, Expert Knowledge, and the Press [article]', 'Blocher, Joseph (Cited 581 times)', 'Washington Law Review, Vol. 87, Issue 2 (June 2012), pp. 409-444', 5, 'na', 5, ' Communications Law, First Amendment, Democracy']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['What State Constitutional Law Can Tell Us about the Federal Constitution [article]', 'Blocher, Joseph (Cited 581 times)', 'Penn State Law Review, Vol. 115, Issue 4 (Spring 2011), pp. 1035-1050', 5, 'na', 8, ' Constitutional Law, Incorporation, State and Local Government Law']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Good Cause Requirements for Carrying Guns in Public [article]', 'Blocher, Joseph (Cited 581 times)', 'Harvard Law Review Forum, Vol. 127, pp. 218-222', 4, 4, 8, ' Right to Bear Arms, States, Second Amendment, Constitutional Rights']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "[\"Second Things First: What Free Speech Can and Can't Say about Guns [comments]\", 'Blocher, Joseph (Cited 581 times)', 'Texas Law Review See Also, Vol. 91, pp. 37-48', 4, 'na', 3, ' Second Amendment, First Amendment, Regulation, Zoning']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "[\"Roberts' Rules: The Assertiveness of Rules-Based Jurisprudence [article]\", 'Blocher, Joseph (Cited 581 times)', 'Tulsa Law Review, Vol. 46, Issue 3 (Spring 2011), pp. 431-448', 3, 'na', 7, ' Jurisprudence, Admiralty, Jurisdiction, Water']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Forced Secessions [article]', 'Blocher, Joseph (Cited 581 times); Gulati, Mitu (Cited 1596 times)', 'Law and Contemporary Problems, Vol. 80, Issue 1 (2017), pp. 215-254', 3, 'na', 15, ' Human Rights Law, Constitutional Law, Emigration and Immigration, International Law, Politics']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['A Market for Sovereign Control [article]', 'Blocher, Joseph (Cited 581 times); Gulati, Mitu (Cited 1596 times)', 'Duke Law Journal, Vol. 66, Issue 4 (January 2017), pp. 797-844', 3, 'na', 28, ' International Law, Politics, Indian Law, Law of the Sea']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Lethality, Public Carry, and Adequate Alternatives [article]', 'Blocher, Joseph (Cited 581 times); Miller, Darrell A.H. (Cited 7 times)', 'Harvard Journal on Legislation, Vol. 53, Issue 1 (Winter 2016), pp. 279-302', 3, 'na', 23, ' Second Amendment, Supreme Court of the United States, International Law, Military Law, Weapons']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Hunting and the Second Amendment [article]', 'Blocher, Joseph (Cited 581 times)', 'Notre Dame Law Review, Vol. 91, Issue 1 (November 2015), pp. 133-176', 3, 'na', 34, ' Second Amendment, Legal History, Violence, Weapons']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['The Death Penalty and the Fifth Amendment [article]', 'Blocher, Joseph (Cited 581 times)', 'Northwestern University Law Review Online, Vol. 111, pp. 1-18', 3, 'na', 21, ' Criminal Law and Procedure, Sentencing, Sentencing and Punishment, Legal History']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['New Approaches to Old Questions in Gun Scholarship [reviews]', 'Blocher, Joseph (Cited 581 times)', 'Tulsa Law Review, Vol. 50, Issue 2 (Winter 2015), pp. 477-490', 2, 3, 10, ' Second Amendment, Gender, Self-Defense']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['New Problems for Subsidized Speech [article]', 'Blocher, Joseph (Cited 581 times)', 'William & Mary Law Review, Vol. 56, Issue 4 (March 2015), pp. 1083-1118', 1, 'na', 10, ' Supreme Court of the United States, Constitutional Law, Transportation Law, First Amendment']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['The Death Penalty and the Fifth Amendment [article]', 'Blocher, Joseph (Cited 581 times)', 'Northwestern University Law Review, Vol. 111, Issue 1 (2016), pp. 275-294', 1, 'na', 34, ' Criminal Law and Procedure, Sentencing, Legal History, Sentencing and Punishment']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Foreword: How to Think about Law and Markets [comments]', 'Blocher, Joseph (Cited 581 times); Krawiec, Kimberly D. (Cited 866 times)', 'Law and Contemporary Problems, Vol. 80, Issue 1 (2017), pp. 1-10', 1, 'na', 32, ' Banking, Bankruptcy Law, Consumer Protection Law, Economics, Legal History, Legislation, Politics, Second Amendment, Trade Regulation, International Trade']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Order without Judges: Customary Adjudication [article]', 'Blocher, Joseph (Cited 581 times)', 'Duke Law Journal, Vol. 62, Issue 3 (December 2012), pp. 579-606', 1, 'na', 6, ' Judges, Intellectual Property, Intellectual Property Law, Property, Jurisprudence, Municipalities']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Markets and Sovereignty [article]', 'Blocher, Joseph (Cited 581 times); Gulati, Mitu (Cited 1596 times)', 'Osgoode Hall Law Journal, Vol. 54, Issue 2 (2017), pp. 465-490', 1, 'na', 17, ' International Law, Politics, Banking, Bankruptcy Law, Consumer Protection Law, Economics, Legal History, Legislation, Second Amendment, Trade Regulation']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Reputation as Property in Virtual Economies', 'Blocher, Joseph (Cited 581 times)', 'na', 'na', 'na', 'na', 'na']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Reputation as Property in Virtual Economies', 'Blocher, Joseph (Cited 581 times)', 'na', 'na', 'na', 'na', 'na']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Guantanamo Three-Step, The', 'Blocher, Joseph (Cited 581 times)', 'na', 'na', 'na', 'na', 'na']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Puerto Rico and the Right of Accession [article]', 'Blocher, Joseph (Cited 581 times); Gulati, Mitu (Cited 1596 times)', 'Yale Journal of International Law, Vol. 43, Issue 2 (Summer 2018), pp. 229-272', 'na', 1, 87, ' Politics, Rico, Congress, Citizenship, Constitutional Law']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Implementing First Amendment Institutionalism [article]', 'Blocher, Joseph (Cited 581 times)', 'New England Law Review On Remand, Vol. 47, pp. 43-52', 'na', 'na', 4, ' First Amendment']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['What We Fret about When We Fret about Bootstsrapping [article]', 'Blocher, Joseph (Cited 581 times)', 'Law and Contemporary Problems , Vol. 75, Issue 3 (2012), pp. 145-156', 'na', 'na', 2, ' Legislation, Criminal Law and Procedure']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Practice and Precedent in Historical Gloss Games [article]', 'Blocher, Joseph (Cited 581 times); Lemos, Margaret H. (Cited 538 times)', 'Georgetown Law Journal Online, Vol. 105, pp. 1-15', 'na', 'na', 20, ' Constitutional Conventions, Judges, Jurisdiction, Separation, Separation of Powers, Legal History, Politics']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "[\"Schrodinger's Cross: The Quantum Mechanics of the Establishment Clause [article]\", 'Blocher, Joseph (Cited 581 times)', 'Virginia Law Review in Brief, Vol. 96, pp. 51-60', 'na', 'na', 2, ' Jurisprudence, First Amendment, Horses, Psychiatry and Psychology, Literature']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
      "['Property and Speech in Summum [article]', 'Blocher, Joseph (Cited 581 times)', 'Northwestern University Law Review Colloquy, Vol. 104, pp. 83-94', 'na', 'na', 'na', ' Property, Government, Religion']\n",
      "['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n"
     ]
    }
   ],
   "source": [
    "title_index = 3\n",
    "stats_index = 4\n",
    "topic_index = 0\n",
    "topic_div_index = 0\n",
    "topic_array = soup.findAll('div', {'class': 'topics'})\n",
    "element = title_index\n",
    "last_name = 'Blocher'\n",
    "page_name = []\n",
    "# df = pd.DataFrame(columns = ['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics'])\n",
    "while element:\n",
    "    data_stream = []\n",
    "    x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "    element = driver.find_elements_by_xpath(x_path_title)\n",
    "    #Get title:\n",
    "    if element:\n",
    "        scraped_papers = True\n",
    "        for elm in element:\n",
    "            data_stream.append(elm.text)\n",
    "\n",
    "        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]')\n",
    "        for elm in element:\n",
    "            my_list = elm.text\n",
    "        if [a for a in my_list.split('\\n') if last_name in a]:   \n",
    "            data_stream.append([a for a in my_list.split('\\n') if last_name in a][0])\n",
    "        else:\n",
    "            data_stream.append('na')\n",
    "        if [a for a in my_list.split('\\n') if 'Vol.' in a]:\n",
    "            data_stream.append([a for a in my_list.split('\\n') if 'Vol.' in a][0])\n",
    "        else:\n",
    "            data_stream.append('na')\n",
    "        element = driver.find_elements_by_xpath('//*[@id=\"save_results\"]/div/div/div/div[' + str(stats_index) + ']/div[2]/div')\n",
    "        for elm in element:\n",
    "            cited_text = elm.text\n",
    "        article_citations = 'na'\n",
    "        case_citations = 'na'\n",
    "        accessed = 'na'\n",
    "        if not isinstance(cited_text, list):\n",
    "            cited_text = cited_text.split('\\n')\n",
    "            cited_text\n",
    "            for stat in cited_text:\n",
    "                if 'Article' in stat:\n",
    "                    article_citations = int(re.search(r'\\d+', stat).group())\n",
    "                if 'Case' in stat:\n",
    "                    case_citations = int(re.search(r'\\d+', stat).group())\n",
    "                if 'Accessed' in stat:\n",
    "                    accessed = int(re.search(r'\\d+', stat).group())\n",
    "        data_stream.append(article_citations)\n",
    "        data_stream.append(case_citations)\n",
    "        data_stream.append(accessed)\n",
    "        if 'Topics:' in my_list:\n",
    "            data_stream.append(topic_array[topic_div_index].text.split(':')[1])\n",
    "            topic_div_index +=1\n",
    "        else:\n",
    "            data_stream.append('na')\n",
    "        print(data_stream)\n",
    "        columns = ['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']\n",
    "        print(columns)\n",
    "#         df = df.append(pd.DataFrame([data_stream], columns = ['Title', 'Author(s)', 'Journal', 'Cited (articles)', 'Cited (cases)', 'Accessed', 'Topics']))\n",
    "        stats_index +=4\n",
    "        title_index += 4\n",
    "#         page_name.append(cur_page)\n",
    "        #Check that next paper exists:\n",
    "        x_path_title = '//*[@id=\"save_results\"]/div/div/div/div[' + str(title_index) + ']/div[2]/dt[1]/div'\n",
    "        element = driver.find_elements_by_xpath(x_path_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub = pd.DataFrame()\n",
    "# main_df = pd.DataFrame()\n",
    "stats = ['Cited by Cases','Cited by Articles','Accessed (Past 12 Months)','Cited by Articles (Past 10 Years)', 'Cited by Articles (Past 1-2 years)', 'ScholarCheck Rank', 'Average Citations per Article', 'Average Citations per Document', 'Self-Citations']\n",
    "last_name = 'Dauber'\n",
    "mid_first_name = 'Michele Landis'\n",
    "full_name = mid_first_name + ' ' + last_name\n",
    "school = 'Arizona'\n",
    "link = 'https://heinonline-org.proxy01.its.virginia.edu/HOL/AuthorProfile?action=edit&search_name=' + last_name +  '%2C ' + mid_first_name + '&collection=journals'\n",
    "driver.get(link)\n",
    "element = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[2]/div[1]')\n",
    "table_element = element.text.split('\\n')\n",
    "number_list = []\n",
    "rank_list = []\n",
    "stat_list = []\n",
    "for stat in stats:\n",
    "#     print(stat)\n",
    "    find_index = [table_element.index(s) for s in table_element if stat == s]\n",
    "    if find_index:\n",
    "        my_list = table_element[find_index[0]+1].split(' ')\n",
    "        number_list.append(my_list[0])\n",
    "        stat_list.append(stat)\n",
    "        if len(my_list) > 1:\n",
    "            rank_list.append(my_list[-1])\n",
    "    if stat == 'Self-Citations':\n",
    "        find_index = [table_element.index(s) for s in table_element if stat in s]\n",
    "        if find_index:\n",
    "            stat_list.append(stat)\n",
    "            number_list.append(table_element[find_index[0]].split(' ')[1])\n",
    "zip_number_list = list(zip(stat_list, number_list))\n",
    "zip_rank_list = list(zip(stat_list, rank_list))\n",
    "number_dict = create_dataframe_dict(zip_number_list)\n",
    "rank_dict = create_dataframe_dict(zip_rank_list)\n",
    "df_number = pd.DataFrame.from_dict(number_dict, orient='index').transpose()\n",
    "df_rank = pd.DataFrame.from_dict(rank_dict, orient='index').transpose()\n",
    "df_number = df_number.replace('na', '0')\n",
    "df_number = df_number.replace('', '0')\n",
    "df_number = df_number.replace(' ', '0')\n",
    "df_number = df_number.astype(float)\n",
    "if df_sub.empty:\n",
    "    df_sub = df_number\n",
    "else: \n",
    "    df_sub = df_sub.add(df_number)\n",
    "df_sub\n",
    "my_dict = {'Person': [full_name], 'School': [school], 'Type': ['number']}\n",
    "name_data = pd.DataFrame(my_dict)\n",
    "df_sub = pd.concat([name_data, df_sub], sort = False, axis = 1)\n",
    "main_df = pd.concat([main_df, df_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>School</th>\n",
       "      <th>Type</th>\n",
       "      <th>Cited by Cases</th>\n",
       "      <th>Cited by Articles</th>\n",
       "      <th>Accessed (Past 12 Months)</th>\n",
       "      <th>Cited by Articles (Past 10 Years)</th>\n",
       "      <th>Cited by Articles (Past 1-2 years)</th>\n",
       "      <th>ScholarCheck Rank</th>\n",
       "      <th>Average Citations per Article</th>\n",
       "      <th>Average Citations per Document</th>\n",
       "      <th>Self-Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michele Landis Dauber</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>number</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>24.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Person   School    Type  Cited by Cases  Cited by Articles  \\\n",
       "0  Michele Landis Dauber  Arizona  number             0.0               97.0   \n",
       "\n",
       "   Accessed (Past 12 Months)  Cited by Articles (Past 10 Years)  \\\n",
       "0                       38.0                               45.0   \n",
       "\n",
       "   Cited by Articles (Past 1-2 years)  ScholarCheck Rank  \\\n",
       "0                                 2.0                0.0   \n",
       "\n",
       "   Average Citations per Article  Average Citations per Document  \\\n",
       "0                           97.0                           24.25   \n",
       "\n",
       "   Self-Citations  \n",
       "0             0.0  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_number = df_number.replace('na', '0')\n",
    "df_number = df_number.replace(' ', '0')\n",
    "df_number = df_number.astype(float)\n",
    "df_number.add(df_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>School</th>\n",
       "      <th>Type</th>\n",
       "      <th>Cited by Cases</th>\n",
       "      <th>Cited by Articles</th>\n",
       "      <th>Accessed (Past 12 Months)</th>\n",
       "      <th>Cited by Articles (Past 10 Years)</th>\n",
       "      <th>Cited by Articles (Past 1-2 years)</th>\n",
       "      <th>ScholarCheck Rank</th>\n",
       "      <th>Average Citations per Article</th>\n",
       "      <th>Average Citations per Document</th>\n",
       "      <th>Self-Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adsfdsa</td>\n",
       "      <td>dsafdsa</td>\n",
       "      <td>sdafdsaf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.41</td>\n",
       "      <td>15.9</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Person   School      Type  Cited by Cases  Cited by Articles  \\\n",
       "0  adsfdsa  dsafdsa  sdafdsaf             3.0              493.0   \n",
       "\n",
       "   Accessed (Past 12 Months)  Cited by Articles (Past 10 Years)  \\\n",
       "0                      645.0                              296.0   \n",
       "\n",
       "   Cited by Articles (Past 1-2 years)  ScholarCheck Rank  \\\n",
       "0                                36.0                0.0   \n",
       "\n",
       "   Average Citations per Article  Average Citations per Document  \\\n",
       "0                          22.41                            15.9   \n",
       "\n",
       "   Self-Citations  \n",
       "0            80.0  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {'Person': ['adsfdsa'], 'School': ['dsafdsa'], 'Type': ['sdafdsaf']}\n",
    "name_data = pd.DataFrame(my_dict)\n",
    "pd.concat([name_data, df_number], sort = False, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cited by Articles', 'Accessed (Past 12 Months)', 'Cited by Articles (Past 10 Years)', 'Cited by Articles (Past 1-2 years)', 'ScholarCheck Rank', 'Average Citations per Article', 'Average Citations per Document', 'Self-Citations']\n",
      "['99', '212', '99', '18', '', '9.90', '9.00', '6']\n",
      "['10,679', '8,754', '4,126', '1,898', '7,876']\n"
     ]
    }
   ],
   "source": [
    "element = driver.find_element_by_xpath('//*[@id=\"page_content\"]/div[1]/div/div[2]/div[1]')\n",
    "stats = ['Cited by Cases','Cited by Articles','Accessed (Past 12 Months)','Cited by Articles (Past 10 Years)', 'Cited by Articles (Past 1-2 years)', 'ScholarCheck Rank', 'Average Citations per Article', 'Average Citations per Document', 'Self-Citations']\n",
    "table_element = element.text.split('\\n')\n",
    "number_list = []\n",
    "rank_list = []\n",
    "stat_list = []\n",
    "for stat in stats:\n",
    "#     print(stat)\n",
    "    find_index = [table_element.index(s) for s in table_element if stat == s]\n",
    "    if find_index:\n",
    "        my_list = table_element[find_index[0]+1].split(' ')\n",
    "        number_list.append(my_list[0])\n",
    "        stat_list.append(stat)\n",
    "        if len(my_list) > 1:\n",
    "            rank_list.append(my_list[-1])\n",
    "    if stat == 'Self-Citations':\n",
    "        find_index = [table_element.index(s) for s in table_element if stat in s]\n",
    "        stat_list.append(stat)\n",
    "        number_list.append(table_element[find_index[0]].split(' ')[1])\n",
    "\n",
    "print(stat_list)\n",
    "print(number_list)\n",
    "print(rank_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': ['1342'], 'b':['na'], 'c':['2']})\n",
    "df1 = df1.replace('na', '0')\n",
    "df1 = df1.astype(float)\n",
    "df2 = pd.DataFrame({'a': ['1'], 'b': ['2'], 'd':['na']})\n",
    "df2 = df2.replace('na', '0')\n",
    "df2 = df2.astype(float)\n",
    "df_out = df1.add(df2, fill_value=0)\n",
    "# # df_out.replace(0, 'na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1343.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a    b    c    d\n",
       "0  1343.0  2.0  2.0  0.0"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a  b  c\n",
       "0  1342  0  2"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1342'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1,342'.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraping",
   "language": "python",
   "name": "webscraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
